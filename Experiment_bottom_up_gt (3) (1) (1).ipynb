{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All packages to import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "\n",
    "from feature_engine import encoding as ce\n",
    "from feature_engine import transformation as tran\n",
    "from feature_engine import outliers as out\n",
    "from feature_engine import selection as select\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing as prep\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from regressors import stats\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratified - 2\n",
    "df=df.sample(frac=0.2, weights='sold',random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with \"cy\"\n",
    "'''If you are using bottoms_up, make remove = []'''\n",
    "def RemoveCY(df,keep=[\"sold\"]): # keep is the variable that have cy, but you want to keep\n",
    "    remove=[] # cat is also a cy variable\n",
    "    for col in df.columns:\n",
    "        if (col.find('_cy')>=0 or col.find('cy_')>=0) and col not in keep:\n",
    "            remove.append(col)\n",
    "    return df.drop(columns=remove)\n",
    "# prep.FunctionTransformer(RemoveCY,kw_args={\"keep\":keep})\n",
    "\n",
    "#Remove non-unique columns\n",
    "def dropSingles(df):\n",
    "    drops = []\n",
    "    for col in df.columns:\n",
    "        if len(df[col].unique())==1:\n",
    "            drops.append(col)\n",
    "    df = df.drop(columns=drops)\n",
    "    return df\n",
    "# prep.FunctionTransformer(dropSingles)\n",
    "\n",
    "df = RemoveCY(dropSingles(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['sold']\n",
    "predictors = df.drop(columns = ['columns'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    predictors, # predictors\n",
    "    target,  # target\n",
    "    test_size=0.3,  # percentage of obs in test set\n",
    "    random_state=0)  # seed to ensure reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = []\n",
    "discrete = []\n",
    "PosContinuous = []\n",
    "NegContinuous = [#undisclosed] # These will change\n",
    "continuous = []\n",
    "for col in X_train.columns:\n",
    "    if col in NegContinuous:\n",
    "        continuous.append(col)\n",
    "    elif X_train[col].dtype.name ==\"object\":\n",
    "        categories.append(col)\n",
    "    elif X_train[col].dtype.name == \"int64\":\n",
    "        discrete.append(col)\n",
    "    else:\n",
    "        PosContinuous.append(col)\n",
    "        continuous.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove high correlation\n",
    "def highCorr(df,keep,cutOff):\n",
    "    '''df is the dataframe\n",
    "        keep is a list of variables to not include in removing correlation\n",
    "            probably a single target variable, but still put in list\n",
    "        cutOff is the correlation cut off to remove'''\n",
    "    df = df.drop(columns=keep)\n",
    "    corr = df.corr()\n",
    "    variables = corr.columns\n",
    "    correlated_features = set()\n",
    "    for r in range(len(variables)):\n",
    "        for c in range(r):\n",
    "            if abs(corr.iloc[r,c])>cutOff:\n",
    "                colname = variables[r]\n",
    "                correlated_features.add(colname)\n",
    "    return df.drop(columns = correlated_features)\n",
    "# prep.FunctionTransformer(highCorr,kw_args={\"keep\":keep,\"cutOff\":0.95})\n",
    "\n",
    "# Less than zero\n",
    "def MakePos(df,negs = None): #negs is the list of numeric columns to retain negative values\n",
    "    for col in df. columns:\n",
    "        if df[col].dtype.name ==\"category\" or df[col].dtype.name ==\"object\":\n",
    "            continue\n",
    "        if col in negs:\n",
    "            continue\n",
    "        if np.min(df[col])<0:\n",
    "            d = df[col].copy()\n",
    "            d = np.where(d < 0,0,d)\n",
    "            df[col]=d\n",
    "    return df\n",
    "# prep.FunctionTransformer(MakePos, kw_args={\"negs\": NegContinuous})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform(X,variables): #Works, only pass variables >=0\n",
    "    result = X.copy()\n",
    "    for col in result.columns:\n",
    "        if col in variables:\n",
    "            result[col] = np.log(result[col]+1)\n",
    "    return result\n",
    "# prep.FunctionTransformer(log_transform, kw_args={\"variables\":var})\n",
    "\n",
    "def ratios(X, variables, tuples = False): # Works\n",
    "    result = X.copy()\n",
    "    if tuples:\n",
    "        for n,d in variables:\n",
    "            denom = np.where(result[d]==0,0.001,result[d])\n",
    "            result[n+\"/\"+d] = result[n]/denom\n",
    "    else:\n",
    "        for d in variables:\n",
    "            denom = np.where(X[d]==0,0.001,X[d])\n",
    "            for n in variables:\n",
    "                if n!=d:\n",
    "                    result[n+\"/\"+d] = result[n]/denom\n",
    "    return result\n",
    "# prep.FunctionTransformer(ratios, kw_args={\"variables\" : var, \"tuples\" : False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "def MAPE(y_true,y_pred):\n",
    "    y_true = np.where(y_true==0,0.001,y_true)\n",
    "    return mean_absolute_percentage_error(y_true,y_pred)\n",
    "def SMAPE(A, F):\n",
    "    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 215.77513124837398\n",
      "MAE: 52.859421292826596\n",
      "R^2: 0.32030268127507444\n"
     ]
    }
   ],
   "source": [
    "#naive forecast\n",
    "\n",
    "y_actual= df.qty_sold_cy # replace with y_train or y_test as needed\n",
    "y_prediction = df.qty_sold_py # replace with y_pred_tr or y_pred_te as needed\n",
    "\n",
    "print(\"RMSE:\",math.sqrt(mean_squared_error(y_actual,y_prediction)))\n",
    "#print(\"MAPE:\",mean_absolute_percentage_error(y_actual,y_prediction))\n",
    "print(\"MAE:\",mean_absolute_error(y_actual, y_prediction))\n",
    "print(\"R^2:\",r2_score(y_actual, y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.3s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.1s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.0s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('makePos',\n",
       "                 FunctionTransformer(func=<function MakePos at 0x0000024843228B80>,\n",
       "                                     kw_args={'negs': ['unit_sales',\n",
       "                                                       'other_unit_pls_lost_sales',\n",
       "                                                       'adjusted_avg_cluster_sales',\n",
       "                                                       'other_unit_pls_lost_sales_py',\n",
       "                                                       'avg_cluster_unit_sales',\n",
       "                                                       'ntrans_wt0_py',\n",
       "                                                       'ntrans_wt0_ppy',\n",
       "                                                       'weighted_lookup_cnt',\n",
       "                                                       'avg_cluster_total_sales',\n",
       "                                                       'adj_avg_cluster_total_sales']})),\n",
       "                ('...\n",
       "                                                   'adj_avg_cluster_total_sales',\n",
       "                                                   'unit_sales',\n",
       "                                                   'projected_growth_pct',\n",
       "                                                   'other_unit_pls_lost_sales_py',\n",
       "                                                   'other_unit_pls_lost_sales',\n",
       "                                                   'lookup_cnt',\n",
       "                                                   'weighted_lookup_cnt',\n",
       "                                                   'qty_wt0_ppy',\n",
       "                                                   'ntrans_wt0_ppy',\n",
       "                                                   'qty_wt0_py',\n",
       "                                                   'ntrans_wt0_py',\n",
       "                                                   'ntrans_wt0',\n",
       "                                                   'unadjusted_total_vio',\n",
       "                                                   'vio_compared_to_cluster',\n",
       "                                                   'bpg', 'qty_wt0',\n",
       "                                                   'store_number', 'sku_number', ...])),\n",
       "                ('model', Ridge())],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pipeline Test\n",
    "\n",
    "#Some notes about pipes. They can take a variable that mapes to a function\n",
    "# To skip a step, put None for the function.\n",
    "# If an arguement that I made requires a list, but you don't want one, put []\n",
    "# If you want to do all variables removing in the pipeline, it must happen\n",
    "# after any of the general variable lists are called. (category,NegContiuous,etc.)\n",
    "mod = Ridge()\n",
    "pipe = Pipeline([\n",
    "    (\"makePos\", prep.FunctionTransformer(MakePos, kw_args={\"negs\": NegContinuous})),\n",
    "    (\"rare\", ce.RareLabelEncoder(tol=0.01,n_categories=7,variables=categories)),\n",
    "    (\"cat_encode\",ce.CountFrequencyEncoder(encoding_method = \"count\")),\n",
    "    (\"num_encode\",prep.FunctionTransformer(log_transform, kw_args={\"variables\":PosContinuous})),\n",
    "    (\"outlier\", out.Winsorizer(capping_method = \"iqr\", tail = \"left\",fold=3,variables= continuous)),\n",
    "    #(\"scaling\",prep.StandardScaler()),\n",
    "    #(\"nzv\", select.DropConstantFeatures(tol=0.95)),\n",
    "    (\"filter_corr\", select.DropCorrelatedFeatures(threshold=0.95)),\n",
    "    #(\"drop_dup\", select.DropDuplicateFeatures()),\n",
    "    #(\"feature_select\", select.SelectByShuffling(estimator = Ridge() , scoring = \"r2\", cv=5,random_state=0)),\n",
    "    (\"model\",mod)\n",
    "],verbose=True)\n",
    "\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE TR: 198.06102934984654\n",
      "MAE TR: 66.27519854645193\n",
      "R2 TR: 0.44650961839490144\n",
      "MAPE TR: 275.63872849645986\n",
      "RMSE TE: 178.3452895570488\n",
      "MAE TE: 65.75975759495205\n",
      "R2 TE: 0.4947936570886662\n",
      "MAPE TE: 270.40613520043996\n"
     ]
    }
   ],
   "source": [
    "y_tr_pred = pipe.predict(X_train)\n",
    "y_te_pred = pipe.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"RMSE TR:\",math.sqrt(mean_squared_error(y_train,y_tr_pred)))\n",
    "print(\"MAE TR:\",mean_absolute_error(y_train,y_tr_pred))\n",
    "print(\"R2 TR:\",r2_score(y_train,y_tr_pred))\n",
    "print(\"MAPE TR:\",MAPE(y_train,y_tr_pred))\n",
    "print(\"RMSE TE:\",math.sqrt(mean_squared_error(y_test,y_te_pred)))\n",
    "print(\"MAE TE:\",mean_absolute_error(y_test,y_te_pred))\n",
    "print(\"R2 TE:\",r2_score(y_test,y_te_pred))\n",
    "print(\"MAPE TE:\",MAPE(y_test,y_te_pred))\n",
    "\n",
    "\n",
    "#importance = model.feature_importance_\n",
    "#IMPORTANCE.append(importance)\n",
    "      \n",
    "#pvalue_array = stats.coef_pval(model, X_test, y_test)\n",
    "#pvalue_array = np.delete(pvalue_array, 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing before the loop\n",
    "pipe=Pipeline([(\"makePos\", prep.FunctionTransformer(MakePos, kw_args={\"negs\": NegContinuous})),\n",
    "               (\"rare\", ce.RareLabelEncoder(tol=0.01,n_categories=7)),\n",
    "               #(\"nzv\", select.DropConstantFeatures(tol=0.95)),\n",
    "               (\"filter_corr\", select.DropCorrelatedFeatures(threshold=0.84)),])\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "X_train = pipe.transform(X_train)\n",
    "X_test = pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asd25\\anaconda3\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:157: UserWarning: The number of unique categories for variable bpg is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.9s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.7s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=   0.3s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   1.3s\n",
      "[Pipeline] ............... (step 6 of 8) Processing nzv, total=   1.1s\n",
      "[Pipeline] ....... (step 7 of 8) Processing filter_corr, total=   2.4s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.2s\n",
      "OneHotEncoder(drop_last=True,\n",
      "              variables=['bpg', 'store_number', 'sku_number', 'mpog_id'])\n",
      "Train MSE 208.03852121267693\n",
      "Train MAE 64.66301795819514\n",
      "Train SMAPE 219.97196734032727\n",
      "Train R2 0.3893399193829694\n",
      "Test MSE 188.27132869205263\n",
      "Test MAE 64.1413538339882\n",
      "Train SMAPE 215.95050884863744\n",
      "Test R2 0.43699288519530166\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asd25\\anaconda3\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:157: UserWarning: The number of unique categories for variable bpg is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   1.1s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.7s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=   0.4s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   1.6s\n",
      "[Pipeline] ............... (step 6 of 8) Processing nzv, total=   1.6s\n",
      "[Pipeline] ....... (step 7 of 8) Processing filter_corr, total=   2.0s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.2s\n",
      "CountFrequencyEncoder(variables=['bpg', 'store_number', 'sku_number',\n",
      "                                 'mpog_id'])\n",
      "Train MSE 207.99975941796285\n",
      "Train MAE 64.67346298616464\n",
      "Train SMAPE 219.6179934929367\n",
      "Train R2 0.38956745489341593\n",
      "Test MSE 188.2199360270775\n",
      "Test MAE 64.1356264361981\n",
      "Train SMAPE 215.61162914555192\n",
      "Test R2 0.4373002127857084\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asd25\\anaconda3\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:157: UserWarning: The number of unique categories for variable bpg is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   1.2s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.8s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=   0.4s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   1.9s\n",
      "[Pipeline] ............... (step 6 of 8) Processing nzv, total=   1.0s\n",
      "[Pipeline] ....... (step 7 of 8) Processing filter_corr, total=   2.0s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.2s\n",
      "MeanEncoder(variables=['bpg', 'store_number', 'sku_number', 'mpog_id'])\n",
      "Train MSE 207.996889888849\n",
      "Train MAE 64.68316021754893\n",
      "Train SMAPE 219.73460841159337\n",
      "Train R2 0.3895842976232573\n",
      "Test MSE 188.21715792208786\n",
      "Test MAE 64.1433492863226\n",
      "Train SMAPE 215.70895557140477\n",
      "Test R2 0.4373168234336867\n"
     ]
    }
   ],
   "source": [
    "#Test cat for loop\n",
    "cat = [ce.OneHotEncoder(top_categories=None, variables = categories,drop_last=True),\n",
    "       ce.CountFrequencyEncoder(encoding_method = \"count\",variables = categories),\n",
    "       ce.MeanEncoder(variables = categories)]\n",
    "\n",
    "\n",
    "for i in range(len(cat)):\n",
    "\n",
    "    c= cat[i]\n",
    "       \n",
    "    pipe = Pipeline([\n",
    "        (\"makePos\", prep.FunctionTransformer(MakePos, kw_args={\"negs\": NegContinuous})),\n",
    "        (\"rare\", ce.RareLabelEncoder(tol=0.01,n_categories=7,variables=categories)),\n",
    "        (\"cat_encode\",c),\n",
    "        (\"num_encode\",prep.FunctionTransformer(log_transform, kw_args={\"variables\":PosContinuous})),\n",
    "        (\"outlier\", out.Winsorizer(capping_method = \"quantiles\", tail = \"both\",fold=0.01,variables=continuous)),\n",
    "        (\"filter_corr\", prep.FunctionTransformer(highCorr,kw_args={\"keep\":[],\"cutOff\":0.9})),\n",
    "        #(\"drop_dup\", select.DropDuplicateFeatures()),\n",
    "        (\"feature_select\", select.SelectByShuffling(estimator = m , scoring = \"r2\", cv=5,random_state=0)),\n",
    "        (\"model\",Ridge())\n",
    "    ],verbose=True)\n",
    "    \n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_tr_pred = pipe.predict(X_train)\n",
    "    y_te_pred = pipe.predict(X_test)\n",
    "    \n",
    "    print(c)\n",
    "    print(\"Train MSE\", math.sqrt(mean_squared_error(y_train,y_tr_pred)))\n",
    "    print(\"Train MAE\", mean_absolute_error(y_train,y_tr_pred))\n",
    "    print(\"Train SMAPE\", SMAPE(y_train,y_tr_pred))\n",
    "    print(\"Train R2\", r2_score(y_train,y_tr_pred))\n",
    "    print(\"Test MSE\", math.sqrt(mean_squared_error(y_test,y_te_pred)))\n",
    "    print(\"Test MAE\", mean_absolute_error(y_test,y_te_pred))\n",
    "    print(\"Train SMAPE\", SMAPE(y_test,y_te_pred))\n",
    "    print(\"Test R2\", r2_score(y_test,y_te_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = pd.DataFrame({\"MODEL\":MODEL,\n",
    "                       \"CATEGORICAL\":CATEGORICAL,\n",
    "                       \"NUMERIC\":NUMERIC,\n",
    "                        \"OUTLIER\":OUTLIER,\n",
    "                        #\"SCALER\":SCALER,\n",
    "                        #\"FEATURE_SELECTION\":FEATURE_SELECTION,\n",
    "                       \"RMSE_TR\":RMSE_TR,\n",
    "                       \"MAE_TR\":MAE_TR,\n",
    "                       \"R2_TR\":R2_TR,\n",
    "                       \"MAPE_TR\":MAPE_TR,\n",
    "                       \"SMAPE_TR\":SMAPE_TR,\n",
    "                       \"RMSE_TE\":RMSE_TE,\n",
    "                       \"MAE_TE\":MAE_TE,\n",
    "                       \"R2_TE\":R2_TE,\n",
    "                       \"MAPE_TE\":MAPE_TE,\n",
    "                       \"SMAPE_TE\":SMAPE_TE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1.to_csv('results1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()\n",
      "None\n",
      "OneHotEncoder(drop_last=True)\n",
      "None\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.0s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.0s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.4s\n",
      "Fit\n",
      "Winsorizer(tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.7s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.8s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.6s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.9s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.8s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.6s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   3.1s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.4s\n",
      "Fit\n",
      "Winsorizer(tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.8s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.7s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.4s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr', tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   2.1s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.7s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.4s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.2s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.7s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.6s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr', tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.3s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   3.8s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.4s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.7s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.9s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.2s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.4s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05,\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.6s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.6s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.6s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.4s\n",
      "Fit\n",
      "CountFrequencyEncoder()\n",
      "None\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.1s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.0s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.6s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   1.0s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   1.2s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.7s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   3.1s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.4s\n",
      "Fit\n",
      "Winsorizer(variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.5s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.5s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.5s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.8s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.4s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr', tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.9s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   2.4s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.9s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.4s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.3s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.0s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.5s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr', tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.1s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.9s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.7s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.7s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   3.1s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.4s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.1s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   2.1s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   1.0s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   2.2s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   4.2s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.5s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05,\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   1.1s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.9s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.6s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.4s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.1s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   1.0s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.7s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.9s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   3.6s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.5s\n",
      "Fit\n",
      "MeanEncoder(variables=['bpg', 'store_number', 'sku_number', 'mpog_id'])\n",
      "None\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   1.0s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.8s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.0s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.1s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.9s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.7s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.9s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.0s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.7s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.6s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.1s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   1.1s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.9s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.7s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.1s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr', tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.1s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   2.1s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.6s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.3s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.9s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr', tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.4s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.7s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.9s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.7s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.4s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   3.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.6s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05,\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.9s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.6s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.0s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.1s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   1.2s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.8s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.7s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.6s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.4s\n",
      "Fit\n",
      "YeoJohnsonTransformer(variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                 'avg_cluster_unit_sales',\n",
      "                                 'adjusted_avg_cluster_sales',\n",
      "                                 'avg_cluster_total_sales', 'sales_signal',\n",
      "                                 'failure_sales', 'lifecycle',\n",
      "                                 'adjusted_lifecycle',\n",
      "                                 'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                                 'projected_growth_pct',\n",
      "                                 'other_unit_pls_lost_sales_py',\n",
      "                                 'other_unit_pls_lost_sales',\n",
      "                                 'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                 'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                 'unadjusted_total_vio',\n",
      "                                 'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                 'pct_white', 'age', 'pct_college',\n",
      "                                 'pct_blue_collar', 'median_household_income',\n",
      "                                 'establishments', ...])\n",
      "OneHotEncoder(drop_last=True,\n",
      "              variables=['bpg', 'store_number', 'sku_number', 'mpog_id'])\n",
      "None\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   1.4s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   1.0s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  23.4s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.0s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.6s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.6s\n",
      "Fit\n",
      "Winsorizer(tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  23.9s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.8s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   3.1s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.5s\n",
      "Fit\n",
      "Winsorizer(variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.9s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  22.7s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.5s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   3.6s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.4s\n",
      "Fit\n",
      "Winsorizer(tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.9s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.7s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  25.6s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.5s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   5.0s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.5s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr', tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  19.1s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   2.2s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   3.1s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  21.8s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.8s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.4s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr', tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  19.1s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.1s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.1s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.4s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  17.6s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.9s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.2s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.4s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05,\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  18.7s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.6s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  17.8s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.6s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "CountFrequencyEncoder(variables=['bpg', 'store_number', 'sku_number',\n",
      "                                 'mpog_id'])\n",
      "None\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  17.6s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.0s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.5s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  20.4s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.6s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n",
      "Winsorizer(variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  17.3s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.4s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.5s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  17.7s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.4s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr', tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  16.7s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.8s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.5s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  17.1s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.0s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr', tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.1s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   1.6s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.7s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  30.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.2s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.1s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.9s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  18.6s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.9s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05,\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  16.7s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.5s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.3s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  16.7s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.5s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n",
      "MeanEncoder(variables=['bpg', 'store_number', 'sku_number', 'mpog_id'])\n",
      "None\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  17.0s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.0s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n",
      "Winsorizer(tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  16.5s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.6s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  17.6s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.4s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n",
      "Winsorizer(tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  17.8s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.4s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr', tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  17.5s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.8s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.6s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.4s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  16.8s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.0s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr', tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  16.8s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.0s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.3s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  16.7s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.9s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05,\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.9s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  17.9s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.6s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=  16.7s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.5s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n",
      "FunctionTransformer(func=<function log_transform at 0x0000024157369B80>,\n",
      "                    kw_args={'variables': ['pop_est', 'pop_density',\n",
      "                                           'total_vio', 'sales_signal',\n",
      "                                           'failure_sales', 'lifecycle',\n",
      "                                           'adjusted_lifecycle',\n",
      "                                           'projected_growth_pct',\n",
      "                                           'qty_wt0_ppy', 'qty_wt0_py',\n",
      "                                           'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                                           'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                           'pct_white', 'age', 'pct_college',\n",
      "                                           'pct_blue_collar',\n",
      "                                           'median_household_income',\n",
      "                                           'establishments',\n",
      "                                           'road_quality_index',\n",
      "                                           'pct_of_lifecycle_remaining',\n",
      "                                           'trend']})\n",
      "OneHotEncoder(drop_last=True,\n",
      "              variables=['bpg', 'store_number', 'sku_number', 'mpog_id'])\n",
      "None\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.0s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.3s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.7s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.2s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.5s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.0s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.5s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.1s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr', tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.8s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.0s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.1s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.0s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr', tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.1s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.1s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.9s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.2s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05,\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.6s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.0s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.6s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   2.1s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "CountFrequencyEncoder(variables=['bpg', 'store_number', 'sku_number',\n",
      "                                 'mpog_id'])\n",
      "None\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.0s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.7s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n",
      "Winsorizer(tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.7s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n",
      "Winsorizer(variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.4s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.5s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr', tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.8s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.3s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.1s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr', tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.1s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.3s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.9s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05,\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.6s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.6s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.5s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "MeanEncoder(variables=['bpg', 'store_number', 'sku_number', 'mpog_id'])\n",
      "None\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.0s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n",
      "Winsorizer(tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.7s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n",
      "Winsorizer(variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.4s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n",
      "Winsorizer(tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.5s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr', tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.9s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.0s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr', tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   1.0s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.9s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.7s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05,\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.6s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.3s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 7) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 7) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 7) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 7) Processing num_encode, total=   0.2s\n",
      "[Pipeline] ........... (step 5 of 7) Processing outlier, total=   0.6s\n",
      "[Pipeline] ....... (step 6 of 7) Processing filter_corr, total=   1.3s\n",
      "[Pipeline] ............. (step 7 of 7) Processing model, total=   0.2s\n",
      "Fit\n"
     ]
    }
   ],
   "source": [
    "cat = [ce.OneHotEncoder(top_categories=None,drop_last=True),\n",
    "      ce.CountFrequencyEncoder(encoding_method = \"count\"),\n",
    "      ce.MeanEncoder(variables = categories)\n",
    "      ]\n",
    "num = [None,\n",
    "       tran.YeoJohnsonTransformer(variables= continuous),\n",
    "       #prep.FunctionTransformer(ratios, kw_args={\"variables\" : continuous, \"tuples\" : False}),\n",
    "       #tran.LogTransformer(base=\"10\", variables = continuous),\n",
    "       prep.FunctionTransformer(log_transform, kw_args={\"variables\":PosContinuous})\n",
    "      ]\n",
    "mod = [LinearRegression()]\n",
    "outlier = [None,\n",
    "           out.Winsorizer(capping_method = \"gaussian\", tail = \"both\",fold=3,variables= continuous),\n",
    "           out.Winsorizer(capping_method = \"gaussian\", tail = \"right\",fold=3,variables= continuous),\n",
    "           out.Winsorizer(capping_method = \"gaussian\", tail = \"left\",fold=3,variables= continuous),\n",
    "           out.Winsorizer(capping_method = \"iqr\", tail = \"both\",fold=3,variables= continuous),\n",
    "           out.Winsorizer(capping_method = \"iqr\", tail = \"right\",fold=3,variables= continuous),\n",
    "           out.Winsorizer(capping_method = \"iqr\", tail = \"left\",fold=3,variables= continuous),\n",
    "           out.Winsorizer(capping_method = \"quantiles\", tail = \"both\",fold=.05,variables= continuous),\n",
    "           out.Winsorizer(capping_method = \"quantiles\", tail = \"right\",fold=.05,variables= continuous),\n",
    "           out.Winsorizer(capping_method = \"quantiles\", tail = \"left\",fold=.05,variables= continuous),\n",
    "          ]\n",
    "\n",
    "#scale = [prep.StandardScaler(),None]\n",
    "\n",
    "MODEL = []\n",
    "CATEGORICAL = []\n",
    "NUMERIC = []\n",
    "OUTLIER = []\n",
    "SCALER = []\n",
    "FEATURE_SELECTION = []\n",
    "\n",
    "RMSE_TR = []\n",
    "MAE_TR = []\n",
    "R2_TR = []\n",
    "MAPE_TR = []\n",
    "SMAPE_TR= []\n",
    "\n",
    "RMSE_TE = []\n",
    "MAE_TE = []\n",
    "R2_TE = []\n",
    "MAPE_TE = []\n",
    "SMAPE_TE= []\n",
    "\n",
    "for m in mod: # loop through the models\n",
    "    print(m)\n",
    "    #feat_select = [select.SelectByShuffling(estimator = m , scoring = \"r2\", cv=5,random_state=0),\n",
    "     #         select.SelectBySingleFeaturePerformance(estimator = m , scoring = \"r2\", cv=5),\n",
    "     #         select.RecursiveFeatureElimination(estimator = m , scoring = \"r2\", cv=5,threshold=0.01),\n",
    "     #        select.RecursiveFeatureAddition(estimator = m , scoring = \"r2\", cv=5,threshold=0.01),\n",
    "     #         None]\n",
    "    for n in num: # loop through the numeric transformations\n",
    "        print(n)\n",
    "        for c in cat: # loop through the categorical encoding\n",
    "            print(c)\n",
    "            for o in outlier:\n",
    "                print(o)\n",
    "                #for s in scale:\n",
    "                    #print(s)\n",
    "                #for f in feat_select:\n",
    "                    #print(f)\n",
    "                pipe = Pipeline([\n",
    "                        (\"makePos\", prep.FunctionTransformer(MakePos, kw_args={\"negs\": NegContinuous})),\n",
    "                        (\"rare\", ce.RareLabelEncoder(tol=0.01,n_categories=7)),\n",
    "                        (\"cat_encode\",c),\n",
    "                        (\"num_encode\",n),\n",
    "                        (\"outlier\", o),\n",
    "                        #(\"nzv\", select.DropConstantFeatures(tol=0.95)),\n",
    "                        (\"filter_corr\", select.DropCorrelatedFeatures(threshold=0.84)),\n",
    "                        #(\"feature_select\", f),\n",
    "                        #(\"scaling\",s),\n",
    "                        (\"model\",m)\n",
    "                    ],verbose=True)\n",
    "                try:\n",
    "                    pipe.fit(X_train,y_train)\n",
    "                    print(\"Fit\")\n",
    "                    y_tr_pred = pipe.predict(X_train)\n",
    "                    y_te_pred = pipe.predict(X_test)\n",
    "\n",
    "                    MODEL.append(m)\n",
    "                    CATEGORICAL.append(c)\n",
    "                    NUMERIC.append(n)\n",
    "                    OUTLIER.append(o)\n",
    "                    #SCALER.append(s)\n",
    "                    #FEATURE_SELECTION.append(f)\n",
    "                    RMSE_TR.append(math.sqrt(mean_squared_error(y_train,y_tr_pred)))\n",
    "                    MAE_TR.append(mean_absolute_error(y_train,y_tr_pred))\n",
    "                    R2_TR.append(r2_score(y_train,y_tr_pred))\n",
    "                    MAPE_TR.append(MAPE(y_train,y_tr_pred))\n",
    "                    SMAPE_TR.append(SMAPE(y_train,y_tr_pred))\n",
    "                    RMSE_TE.append(math.sqrt(mean_squared_error(y_test,y_te_pred)))\n",
    "                    MAE_TE.append(mean_absolute_error(y_test,y_te_pred))\n",
    "                    R2_TE.append(r2_score(y_test,y_te_pred))\n",
    "                    MAPE_TE.append(MAPE(y_test,y_te_pred))\n",
    "                    SMAPE_TE.append(SMAPE(y_test,y_te_pred))\n",
    "                except:\n",
    "                    MODEL.append(m)\n",
    "                    CATEGORICAL.append(c)\n",
    "                    NUMERIC.append(n)\n",
    "                    OUTLIER.append(o)\n",
    "                    #SCALER.append(s)\n",
    "                    #FEATURE_SELECTION.append(f)\n",
    "                    RMSE_TR.append(\".\")\n",
    "                    MAE_TR.append(\".\")\n",
    "                    R2_TR.append(\".\")\n",
    "                    MAPE_TR.append(\".\")\n",
    "                    SMAPE_TR.append(\".\")\n",
    "                    RMSE_TE.append(\".\")\n",
    "                    MAE_TE.append(\".\")\n",
    "                    R2_TE.append(\".\")\n",
    "                    MAPE_TE.append(\".\")\n",
    "                    SMAPE_TE.append(\".\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = pd.DataFrame({\"MODEL\":MODEL,\n",
    "                       \"CATEGORICAL\":CATEGORICAL,\n",
    "                       \"NUMERIC\":NUMERIC,\n",
    "                        \"OUTLIER\":OUTLIER,\n",
    "                        #\"SCALER\":SCALER,\n",
    "                        #\"FEATURE_SELECTION\":FEATURE_SELECTION,\n",
    "                       \"RMSE_TR\":RMSE_TR,\n",
    "                       \"MAE_TR\":MAE_TR,\n",
    "                       \"R2_TR\":R2_TR,\n",
    "                       \"MAPE_TR\":MAPE_TR,\n",
    "                       \"SMAPE_TR\":SMAPE_TR,\n",
    "                       \"RMSE_TE\":RMSE_TE,\n",
    "                       \"MAE_TE\":MAE_TE,\n",
    "                       \"R2_TE\":R2_TE,\n",
    "                       \"MAPE_TE\":MAPE_TE,\n",
    "                       \"SMAPE_TE\":SMAPE_TE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>CATEGORICAL</th>\n",
       "      <th>NUMERIC</th>\n",
       "      <th>OUTLIER</th>\n",
       "      <th>RMSE_TR</th>\n",
       "      <th>MAE_TR</th>\n",
       "      <th>R2_TR</th>\n",
       "      <th>MAPE_TR</th>\n",
       "      <th>SMAPE_TR</th>\n",
       "      <th>RMSE_TE</th>\n",
       "      <th>MAE_TE</th>\n",
       "      <th>R2_TE</th>\n",
       "      <th>MAPE_TE</th>\n",
       "      <th>SMAPE_TE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>OneHotEncoder(drop_last=True,\\n              v...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>109.955282</td>\n",
       "      <td>30.374202</td>\n",
       "      <td>0.829414</td>\n",
       "      <td>49.010042</td>\n",
       "      <td>36.746117</td>\n",
       "      <td>135.515370</td>\n",
       "      <td>30.550626</td>\n",
       "      <td>0.708309</td>\n",
       "      <td>48.401044</td>\n",
       "      <td>36.546024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>OneHotEncoder(drop_last=True,\\n              v...</td>\n",
       "      <td>None</td>\n",
       "      <td>Winsorizer(tail='both',\\n           variables=...</td>\n",
       "      <td>183.717858</td>\n",
       "      <td>43.115816</td>\n",
       "      <td>0.523772</td>\n",
       "      <td>59.360881</td>\n",
       "      <td>59.691290</td>\n",
       "      <td>163.047841</td>\n",
       "      <td>42.388496</td>\n",
       "      <td>0.577744</td>\n",
       "      <td>58.745559</td>\n",
       "      <td>59.438631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>OneHotEncoder(drop_last=True,\\n              v...</td>\n",
       "      <td>None</td>\n",
       "      <td>Winsorizer(variables=['pop_est', 'pop_density'...</td>\n",
       "      <td>183.717808</td>\n",
       "      <td>43.115909</td>\n",
       "      <td>0.523772</td>\n",
       "      <td>59.361494</td>\n",
       "      <td>59.691988</td>\n",
       "      <td>163.048121</td>\n",
       "      <td>42.388744</td>\n",
       "      <td>0.577743</td>\n",
       "      <td>58.746248</td>\n",
       "      <td>59.439458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>OneHotEncoder(drop_last=True,\\n              v...</td>\n",
       "      <td>None</td>\n",
       "      <td>Winsorizer(tail='left',\\n           variables=...</td>\n",
       "      <td>109.955419</td>\n",
       "      <td>30.374272</td>\n",
       "      <td>0.829413</td>\n",
       "      <td>49.010061</td>\n",
       "      <td>36.746096</td>\n",
       "      <td>135.515070</td>\n",
       "      <td>30.550545</td>\n",
       "      <td>0.708311</td>\n",
       "      <td>48.401130</td>\n",
       "      <td>36.546025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>OneHotEncoder(drop_last=True,\\n              v...</td>\n",
       "      <td>None</td>\n",
       "      <td>Winsorizer(capping_method='iqr', tail='both',\\...</td>\n",
       "      <td>218.539292</td>\n",
       "      <td>60.519828</td>\n",
       "      <td>0.326138</td>\n",
       "      <td>101.731953</td>\n",
       "      <td>80.374363</td>\n",
       "      <td>199.297261</td>\n",
       "      <td>60.280919</td>\n",
       "      <td>0.369118</td>\n",
       "      <td>100.870807</td>\n",
       "      <td>80.046572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function log_transfo...</td>\n",
       "      <td>Winsorizer(capping_method='iqr',\\n           v...</td>\n",
       "      <td>214.485727</td>\n",
       "      <td>78.027135</td>\n",
       "      <td>0.350904</td>\n",
       "      <td>235.194473</td>\n",
       "      <td>96.785368</td>\n",
       "      <td>195.557157</td>\n",
       "      <td>77.762680</td>\n",
       "      <td>0.392575</td>\n",
       "      <td>234.212992</td>\n",
       "      <td>96.408545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function log_transfo...</td>\n",
       "      <td>Winsorizer(capping_method='iqr', tail='left',\\...</td>\n",
       "      <td>204.206880</td>\n",
       "      <td>66.490494</td>\n",
       "      <td>0.411627</td>\n",
       "      <td>180.653389</td>\n",
       "      <td>89.532037</td>\n",
       "      <td>184.911592</td>\n",
       "      <td>66.047890</td>\n",
       "      <td>0.456908</td>\n",
       "      <td>179.379251</td>\n",
       "      <td>89.000924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function log_transfo...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>220.360900</td>\n",
       "      <td>62.721903</td>\n",
       "      <td>0.314857</td>\n",
       "      <td>125.487235</td>\n",
       "      <td>79.991052</td>\n",
       "      <td>201.310367</td>\n",
       "      <td>62.367232</td>\n",
       "      <td>0.356308</td>\n",
       "      <td>124.695113</td>\n",
       "      <td>79.774827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function log_transfo...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>220.365562</td>\n",
       "      <td>62.906612</td>\n",
       "      <td>0.314828</td>\n",
       "      <td>127.147266</td>\n",
       "      <td>79.725769</td>\n",
       "      <td>201.425108</td>\n",
       "      <td>62.600949</td>\n",
       "      <td>0.355574</td>\n",
       "      <td>126.324473</td>\n",
       "      <td>79.583671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function log_transfo...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>204.137437</td>\n",
       "      <td>66.574881</td>\n",
       "      <td>0.412027</td>\n",
       "      <td>177.975153</td>\n",
       "      <td>90.103980</td>\n",
       "      <td>184.862998</td>\n",
       "      <td>66.138834</td>\n",
       "      <td>0.457193</td>\n",
       "      <td>176.950204</td>\n",
       "      <td>89.681593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 MODEL                                        CATEGORICAL  \\\n",
       "0   LinearRegression()  OneHotEncoder(drop_last=True,\\n              v...   \n",
       "1   LinearRegression()  OneHotEncoder(drop_last=True,\\n              v...   \n",
       "2   LinearRegression()  OneHotEncoder(drop_last=True,\\n              v...   \n",
       "3   LinearRegression()  OneHotEncoder(drop_last=True,\\n              v...   \n",
       "4   LinearRegression()  OneHotEncoder(drop_last=True,\\n              v...   \n",
       "..                 ...                                                ...   \n",
       "85  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "86  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "87  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "88  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "89  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "\n",
       "                                              NUMERIC  \\\n",
       "0                                                None   \n",
       "1                                                None   \n",
       "2                                                None   \n",
       "3                                                None   \n",
       "4                                                None   \n",
       "..                                                ...   \n",
       "85  FunctionTransformer(func=<function log_transfo...   \n",
       "86  FunctionTransformer(func=<function log_transfo...   \n",
       "87  FunctionTransformer(func=<function log_transfo...   \n",
       "88  FunctionTransformer(func=<function log_transfo...   \n",
       "89  FunctionTransformer(func=<function log_transfo...   \n",
       "\n",
       "                                              OUTLIER     RMSE_TR     MAE_TR  \\\n",
       "0                                                None  109.955282  30.374202   \n",
       "1   Winsorizer(tail='both',\\n           variables=...  183.717858  43.115816   \n",
       "2   Winsorizer(variables=['pop_est', 'pop_density'...  183.717808  43.115909   \n",
       "3   Winsorizer(tail='left',\\n           variables=...  109.955419  30.374272   \n",
       "4   Winsorizer(capping_method='iqr', tail='both',\\...  218.539292  60.519828   \n",
       "..                                                ...         ...        ...   \n",
       "85  Winsorizer(capping_method='iqr',\\n           v...  214.485727  78.027135   \n",
       "86  Winsorizer(capping_method='iqr', tail='left',\\...  204.206880  66.490494   \n",
       "87  Winsorizer(capping_method='quantiles', fold=0....  220.360900  62.721903   \n",
       "88  Winsorizer(capping_method='quantiles', fold=0....  220.365562  62.906612   \n",
       "89  Winsorizer(capping_method='quantiles', fold=0....  204.137437  66.574881   \n",
       "\n",
       "       R2_TR     MAPE_TR   SMAPE_TR     RMSE_TE     MAE_TE     R2_TE  \\\n",
       "0   0.829414   49.010042  36.746117  135.515370  30.550626  0.708309   \n",
       "1   0.523772   59.360881  59.691290  163.047841  42.388496  0.577744   \n",
       "2   0.523772   59.361494  59.691988  163.048121  42.388744  0.577743   \n",
       "3   0.829413   49.010061  36.746096  135.515070  30.550545  0.708311   \n",
       "4   0.326138  101.731953  80.374363  199.297261  60.280919  0.369118   \n",
       "..       ...         ...        ...         ...        ...       ...   \n",
       "85  0.350904  235.194473  96.785368  195.557157  77.762680  0.392575   \n",
       "86  0.411627  180.653389  89.532037  184.911592  66.047890  0.456908   \n",
       "87  0.314857  125.487235  79.991052  201.310367  62.367232  0.356308   \n",
       "88  0.314828  127.147266  79.725769  201.425108  62.600949  0.355574   \n",
       "89  0.412027  177.975153  90.103980  184.862998  66.138834  0.457193   \n",
       "\n",
       "       MAPE_TE   SMAPE_TE  \n",
       "0    48.401044  36.546024  \n",
       "1    58.745559  59.438631  \n",
       "2    58.746248  59.439458  \n",
       "3    48.401130  36.546025  \n",
       "4   100.870807  80.046572  \n",
       "..         ...        ...  \n",
       "85  234.212992  96.408545  \n",
       "86  179.379251  89.000924  \n",
       "87  124.695113  79.774827  \n",
       "88  126.324473  79.583671  \n",
       "89  176.950204  89.681593  \n",
       "\n",
       "[90 rows x 14 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2.to_csv('result4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()\n",
      "YeoJohnsonTransformer(variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                 'avg_cluster_unit_sales',\n",
      "                                 'adjusted_avg_cluster_sales',\n",
      "                                 'avg_cluster_total_sales', 'sales_signal',\n",
      "                                 'failure_sales', 'lifecycle',\n",
      "                                 'adjusted_lifecycle',\n",
      "                                 'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                                 'projected_growth_pct',\n",
      "                                 'other_unit_pls_lost_sales_py',\n",
      "                                 'other_unit_pls_lost_sales',\n",
      "                                 'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                 'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                 'unadjusted_total_vio',\n",
      "                                 'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                 'pct_white', 'age', 'pct_college',\n",
      "                                 'pct_blue_collar', 'median_household_income',\n",
      "                                 'establishments', ...])\n",
      "CountFrequencyEncoder()\n",
      "Winsorizer(tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "RecursiveFeatureElimination(cv=5, estimator=LinearRegression(), scoring='r2')\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   1.1s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  24.8s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.9s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.8s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total= 2.2min\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "RecursiveFeatureAddition(cv=5, estimator=LinearRegression(), scoring='r2')\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   1.0s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  25.4s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   1.0s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.7s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total=  24.4s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "Winsorizer(variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "RecursiveFeatureElimination(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                            variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                       'lost_qty', 'ss_sales',\n",
      "                                       'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                       'failure_sales', 'lifecycle',\n",
      "                                       'unit_sales', 'projected_growth_pct',\n",
      "                                       'other_unit_pls_lost_sales_py',\n",
      "                                       'other_unit_pls_lost_sales',\n",
      "                                       'lookup_cnt', 'weighted_lookup_cnt',\n",
      "                                       'qty_wt0_ppy', 'ntrans_wt0_ppy',\n",
      "                                       'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                       'vio_compared_to_cluster', 'bpg',\n",
      "                                       'qty_wt0', 'store_number', 'sku_number',\n",
      "                                       'application_count', 'pct_white', 'age',\n",
      "                                       'pct_college', 'pct_blue_collar',\n",
      "                                       'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  22.8s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.5s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.5s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total= 1.8min\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "RecursiveFeatureAddition(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                         variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                    'lost_qty', 'ss_sales',\n",
      "                                    'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                    'failure_sales', 'lifecycle', 'unit_sales',\n",
      "                                    'projected_growth_pct',\n",
      "                                    'other_unit_pls_lost_sales_py',\n",
      "                                    'other_unit_pls_lost_sales', 'lookup_cnt',\n",
      "                                    'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                    'ntrans_wt0_ppy', 'ntrans_wt0_py',\n",
      "                                    'ntrans_wt0', 'vio_compared_to_cluster',\n",
      "                                    'bpg', 'qty_wt0', 'store_number',\n",
      "                                    'sku_number', 'application_count',\n",
      "                                    'pct_white', 'age', 'pct_college',\n",
      "                                    'pct_blue_collar',\n",
      "                                    'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  18.6s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.5s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.5s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total=  18.9s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "Winsorizer(tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "RecursiveFeatureElimination(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                            variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                       'lost_qty', 'ss_sales',\n",
      "                                       'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                       'failure_sales', 'lifecycle',\n",
      "                                       'unit_sales', 'projected_growth_pct',\n",
      "                                       'other_unit_pls_lost_sales_py',\n",
      "                                       'other_unit_pls_lost_sales',\n",
      "                                       'lookup_cnt', 'weighted_lookup_cnt',\n",
      "                                       'qty_wt0_ppy', 'ntrans_wt0_ppy',\n",
      "                                       'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                       'vio_compared_to_cluster', 'bpg',\n",
      "                                       'qty_wt0', 'store_number', 'sku_number',\n",
      "                                       'application_count', 'pct_white', 'age',\n",
      "                                       'pct_college', 'pct_blue_collar',\n",
      "                                       'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  18.1s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.5s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.3s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total= 1.7min\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "RecursiveFeatureAddition(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                         variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                    'lost_qty', 'ss_sales',\n",
      "                                    'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                    'failure_sales', 'lifecycle', 'unit_sales',\n",
      "                                    'projected_growth_pct',\n",
      "                                    'other_unit_pls_lost_sales_py',\n",
      "                                    'other_unit_pls_lost_sales', 'lookup_cnt',\n",
      "                                    'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                    'ntrans_wt0_ppy', 'ntrans_wt0_py',\n",
      "                                    'ntrans_wt0', 'vio_compared_to_cluster',\n",
      "                                    'bpg', 'qty_wt0', 'store_number',\n",
      "                                    'sku_number', 'application_count',\n",
      "                                    'pct_white', 'age', 'pct_college',\n",
      "                                    'pct_blue_collar',\n",
      "                                    'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  19.4s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.5s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.3s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total=  24.4s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr', tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "RecursiveFeatureElimination(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                            variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                       'lost_qty', 'ss_sales',\n",
      "                                       'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                       'failure_sales', 'lifecycle',\n",
      "                                       'unit_sales', 'projected_growth_pct',\n",
      "                                       'other_unit_pls_lost_sales_py',\n",
      "                                       'other_unit_pls_lost_sales',\n",
      "                                       'lookup_cnt', 'weighted_lookup_cnt',\n",
      "                                       'qty_wt0_ppy', 'ntrans_wt0_ppy',\n",
      "                                       'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                       'vio_compared_to_cluster', 'bpg',\n",
      "                                       'qty_wt0', 'store_number', 'sku_number',\n",
      "                                       'application_count', 'pct_white', 'age',\n",
      "                                       'pct_college', 'pct_blue_collar',\n",
      "                                       'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  18.3s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   2.0s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.5s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total= 1.6min\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "RecursiveFeatureAddition(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                         variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                    'lost_qty', 'ss_sales',\n",
      "                                    'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                    'failure_sales', 'lifecycle', 'unit_sales',\n",
      "                                    'projected_growth_pct',\n",
      "                                    'other_unit_pls_lost_sales_py',\n",
      "                                    'other_unit_pls_lost_sales', 'lookup_cnt',\n",
      "                                    'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                    'ntrans_wt0_ppy', 'ntrans_wt0_py',\n",
      "                                    'ntrans_wt0', 'vio_compared_to_cluster',\n",
      "                                    'bpg', 'qty_wt0', 'store_number',\n",
      "                                    'sku_number', 'application_count',\n",
      "                                    'pct_white', 'age', 'pct_college',\n",
      "                                    'pct_blue_collar',\n",
      "                                    'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  18.6s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   2.0s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total=  20.3s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "RecursiveFeatureElimination(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                            variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                       'lost_qty', 'ss_sales',\n",
      "                                       'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                       'failure_sales', 'lifecycle',\n",
      "                                       'unit_sales', 'projected_growth_pct',\n",
      "                                       'other_unit_pls_lost_sales_py',\n",
      "                                       'other_unit_pls_lost_sales',\n",
      "                                       'lookup_cnt', 'weighted_lookup_cnt',\n",
      "                                       'qty_wt0_ppy', 'ntrans_wt0_ppy',\n",
      "                                       'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                       'vio_compared_to_cluster', 'bpg',\n",
      "                                       'qty_wt0', 'store_number', 'sku_number',\n",
      "                                       'application_count', 'pct_white', 'age',\n",
      "                                       'pct_college', 'pct_blue_collar',\n",
      "                                       'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  19.2s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   1.1s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total= 1.6min\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "RecursiveFeatureAddition(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                         variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                    'lost_qty', 'ss_sales',\n",
      "                                    'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                    'failure_sales', 'lifecycle', 'unit_sales',\n",
      "                                    'projected_growth_pct',\n",
      "                                    'other_unit_pls_lost_sales_py',\n",
      "                                    'other_unit_pls_lost_sales', 'lookup_cnt',\n",
      "                                    'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                    'ntrans_wt0_ppy', 'ntrans_wt0_py',\n",
      "                                    'ntrans_wt0', 'vio_compared_to_cluster',\n",
      "                                    'bpg', 'qty_wt0', 'store_number',\n",
      "                                    'sku_number', 'application_count',\n",
      "                                    'pct_white', 'age', 'pct_college',\n",
      "                                    'pct_blue_collar',\n",
      "                                    'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  19.2s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   1.1s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.3s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total=  16.7s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr', tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "RecursiveFeatureElimination(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                            variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                       'lost_qty', 'ss_sales',\n",
      "                                       'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                       'failure_sales', 'lifecycle',\n",
      "                                       'unit_sales', 'projected_growth_pct',\n",
      "                                       'other_unit_pls_lost_sales_py',\n",
      "                                       'other_unit_pls_lost_sales',\n",
      "                                       'lookup_cnt', 'weighted_lookup_cnt',\n",
      "                                       'qty_wt0_ppy', 'ntrans_wt0_ppy',\n",
      "                                       'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                       'vio_compared_to_cluster', 'bpg',\n",
      "                                       'qty_wt0', 'store_number', 'sku_number',\n",
      "                                       'application_count', 'pct_white', 'age',\n",
      "                                       'pct_college', 'pct_blue_collar',\n",
      "                                       'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  19.1s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   1.1s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.5s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total= 1.7min\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "RecursiveFeatureAddition(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                         variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                    'lost_qty', 'ss_sales',\n",
      "                                    'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                    'failure_sales', 'lifecycle', 'unit_sales',\n",
      "                                    'projected_growth_pct',\n",
      "                                    'other_unit_pls_lost_sales_py',\n",
      "                                    'other_unit_pls_lost_sales', 'lookup_cnt',\n",
      "                                    'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                    'ntrans_wt0_ppy', 'ntrans_wt0_py',\n",
      "                                    'ntrans_wt0', 'vio_compared_to_cluster',\n",
      "                                    'bpg', 'qty_wt0', 'store_number',\n",
      "                                    'sku_number', 'application_count',\n",
      "                                    'pct_white', 'age', 'pct_college',\n",
      "                                    'pct_blue_collar',\n",
      "                                    'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  21.3s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   1.5s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.7s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total=  27.3s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "RecursiveFeatureElimination(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                            variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                       'lost_qty', 'ss_sales',\n",
      "                                       'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                       'failure_sales', 'lifecycle',\n",
      "                                       'unit_sales', 'projected_growth_pct',\n",
      "                                       'other_unit_pls_lost_sales_py',\n",
      "                                       'other_unit_pls_lost_sales',\n",
      "                                       'lookup_cnt', 'weighted_lookup_cnt',\n",
      "                                       'qty_wt0_ppy', 'ntrans_wt0_ppy',\n",
      "                                       'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                       'vio_compared_to_cluster', 'bpg',\n",
      "                                       'qty_wt0', 'store_number', 'sku_number',\n",
      "                                       'application_count', 'pct_white', 'age',\n",
      "                                       'pct_college', 'pct_blue_collar',\n",
      "                                       'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  28.6s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   1.2s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.9s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total= 2.0min\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "RecursiveFeatureAddition(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                         variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                    'lost_qty', 'ss_sales',\n",
      "                                    'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                    'failure_sales', 'lifecycle', 'unit_sales',\n",
      "                                    'projected_growth_pct',\n",
      "                                    'other_unit_pls_lost_sales_py',\n",
      "                                    'other_unit_pls_lost_sales', 'lookup_cnt',\n",
      "                                    'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                    'ntrans_wt0_ppy', 'ntrans_wt0_py',\n",
      "                                    'ntrans_wt0', 'vio_compared_to_cluster',\n",
      "                                    'bpg', 'qty_wt0', 'store_number',\n",
      "                                    'sku_number', 'application_count',\n",
      "                                    'pct_white', 'age', 'pct_college',\n",
      "                                    'pct_blue_collar',\n",
      "                                    'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.1s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.9s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  20.3s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   1.0s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.6s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total=  21.1s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05,\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "RecursiveFeatureElimination(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                            variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                       'lost_qty', 'ss_sales',\n",
      "                                       'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                       'failure_sales', 'lifecycle',\n",
      "                                       'unit_sales', 'projected_growth_pct',\n",
      "                                       'other_unit_pls_lost_sales_py',\n",
      "                                       'other_unit_pls_lost_sales',\n",
      "                                       'lookup_cnt', 'weighted_lookup_cnt',\n",
      "                                       'qty_wt0_ppy', 'ntrans_wt0_ppy',\n",
      "                                       'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                       'vio_compared_to_cluster', 'bpg',\n",
      "                                       'qty_wt0', 'store_number', 'sku_number',\n",
      "                                       'application_count', 'pct_white', 'age',\n",
      "                                       'pct_college', 'pct_blue_collar',\n",
      "                                       'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  20.0s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.6s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.5s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total= 1.8min\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "RecursiveFeatureAddition(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                         variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                    'lost_qty', 'ss_sales',\n",
      "                                    'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                    'failure_sales', 'lifecycle', 'unit_sales',\n",
      "                                    'projected_growth_pct',\n",
      "                                    'other_unit_pls_lost_sales_py',\n",
      "                                    'other_unit_pls_lost_sales', 'lookup_cnt',\n",
      "                                    'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                    'ntrans_wt0_ppy', 'ntrans_wt0_py',\n",
      "                                    'ntrans_wt0', 'vio_compared_to_cluster',\n",
      "                                    'bpg', 'qty_wt0', 'store_number',\n",
      "                                    'sku_number', 'application_count',\n",
      "                                    'pct_white', 'age', 'pct_college',\n",
      "                                    'pct_blue_collar',\n",
      "                                    'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.9s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  22.5s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.8s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.8s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total=  21.9s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "RecursiveFeatureElimination(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                            variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                       'lost_qty', 'ss_sales',\n",
      "                                       'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                       'failure_sales', 'lifecycle',\n",
      "                                       'unit_sales', 'projected_growth_pct',\n",
      "                                       'other_unit_pls_lost_sales_py',\n",
      "                                       'other_unit_pls_lost_sales',\n",
      "                                       'lookup_cnt', 'weighted_lookup_cnt',\n",
      "                                       'qty_wt0_ppy', 'ntrans_wt0_ppy',\n",
      "                                       'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                       'vio_compared_to_cluster', 'bpg',\n",
      "                                       'qty_wt0', 'store_number', 'sku_number',\n",
      "                                       'application_count', 'pct_white', 'age',\n",
      "                                       'pct_college', 'pct_blue_collar',\n",
      "                                       'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.9s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  26.0s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.7s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.7s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total= 1.9min\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "RecursiveFeatureAddition(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                         variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                    'lost_qty', 'ss_sales',\n",
      "                                    'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                    'failure_sales', 'lifecycle', 'unit_sales',\n",
      "                                    'projected_growth_pct',\n",
      "                                    'other_unit_pls_lost_sales_py',\n",
      "                                    'other_unit_pls_lost_sales', 'lookup_cnt',\n",
      "                                    'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                    'ntrans_wt0_ppy', 'ntrans_wt0_py',\n",
      "                                    'ntrans_wt0', 'vio_compared_to_cluster',\n",
      "                                    'bpg', 'qty_wt0', 'store_number',\n",
      "                                    'sku_number', 'application_count',\n",
      "                                    'pct_white', 'age', 'pct_college',\n",
      "                                    'pct_blue_collar',\n",
      "                                    'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.1s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   1.1s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  29.4s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.8s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.7s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total=  27.9s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "None\n",
      "RecursiveFeatureElimination(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                            variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                       'lost_qty', 'ss_sales',\n",
      "                                       'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                       'failure_sales', 'lifecycle',\n",
      "                                       'unit_sales', 'projected_growth_pct',\n",
      "                                       'other_unit_pls_lost_sales_py',\n",
      "                                       'other_unit_pls_lost_sales',\n",
      "                                       'lookup_cnt', 'weighted_lookup_cnt',\n",
      "                                       'qty_wt0_ppy', 'ntrans_wt0_ppy',\n",
      "                                       'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                       'vio_compared_to_cluster', 'bpg',\n",
      "                                       'qty_wt0', 'store_number', 'sku_number',\n",
      "                                       'application_count', 'pct_white', 'age',\n",
      "                                       'pct_college', 'pct_blue_collar',\n",
      "                                       'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.9s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  25.4s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.0s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.8s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total= 1.9min\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "RecursiveFeatureAddition(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                         variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                    'lost_qty', 'ss_sales',\n",
      "                                    'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                    'failure_sales', 'lifecycle', 'unit_sales',\n",
      "                                    'projected_growth_pct',\n",
      "                                    'other_unit_pls_lost_sales_py',\n",
      "                                    'other_unit_pls_lost_sales', 'lookup_cnt',\n",
      "                                    'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                    'ntrans_wt0_ppy', 'ntrans_wt0_py',\n",
      "                                    'ntrans_wt0', 'vio_compared_to_cluster',\n",
      "                                    'bpg', 'qty_wt0', 'store_number',\n",
      "                                    'sku_number', 'application_count',\n",
      "                                    'pct_white', 'age', 'pct_college',\n",
      "                                    'pct_blue_collar',\n",
      "                                    'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   1.1s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.7s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  24.3s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.0s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   2.0s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total=  30.4s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "MeanEncoder(variables=['bpg', 'store_number', 'sku_number', 'mpog_id'])\n",
      "Winsorizer(tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "RecursiveFeatureElimination(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                            variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                       'lost_qty', 'ss_sales',\n",
      "                                       'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                       'failure_sales', 'lifecycle',\n",
      "                                       'unit_sales', 'projected_growth_pct',\n",
      "                                       'other_unit_pls_lost_sales_py',\n",
      "                                       'other_unit_pls_lost_sales',\n",
      "                                       'lookup_cnt', 'weighted_lookup_cnt',\n",
      "                                       'qty_wt0_ppy', 'ntrans_wt0_ppy',\n",
      "                                       'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                       'vio_compared_to_cluster', 'bpg',\n",
      "                                       'qty_wt0', 'store_number', 'sku_number',\n",
      "                                       'application_count', 'pct_white', 'age',\n",
      "                                       'pct_college', 'pct_blue_collar',\n",
      "                                       'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  31.8s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.7s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.3s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total= 1.5min\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.0s\n",
      "Fit\n",
      "RecursiveFeatureAddition(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                         variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                    'lost_qty', 'ss_sales',\n",
      "                                    'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                    'failure_sales', 'lifecycle', 'unit_sales',\n",
      "                                    'projected_growth_pct',\n",
      "                                    'other_unit_pls_lost_sales_py',\n",
      "                                    'other_unit_pls_lost_sales', 'lookup_cnt',\n",
      "                                    'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                    'ntrans_wt0_ppy', 'ntrans_wt0_py',\n",
      "                                    'ntrans_wt0', 'vio_compared_to_cluster',\n",
      "                                    'bpg', 'qty_wt0', 'store_number',\n",
      "                                    'sku_number', 'application_count',\n",
      "                                    'pct_white', 'age', 'pct_college',\n",
      "                                    'pct_blue_collar',\n",
      "                                    'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  16.9s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.7s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.2s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total=  16.5s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "Winsorizer(variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "RecursiveFeatureElimination(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                            variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                       'lost_qty', 'ss_sales',\n",
      "                                       'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                       'failure_sales', 'lifecycle',\n",
      "                                       'unit_sales', 'projected_growth_pct',\n",
      "                                       'other_unit_pls_lost_sales_py',\n",
      "                                       'other_unit_pls_lost_sales',\n",
      "                                       'lookup_cnt', 'weighted_lookup_cnt',\n",
      "                                       'qty_wt0_ppy', 'ntrans_wt0_ppy',\n",
      "                                       'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                       'vio_compared_to_cluster', 'bpg',\n",
      "                                       'qty_wt0', 'store_number', 'sku_number',\n",
      "                                       'application_count', 'pct_white', 'age',\n",
      "                                       'pct_college', 'pct_blue_collar',\n",
      "                                       'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  17.0s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.4s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.3s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total= 1.4min\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.0s\n",
      "Fit\n",
      "RecursiveFeatureAddition(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                         variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                    'lost_qty', 'ss_sales',\n",
      "                                    'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                    'failure_sales', 'lifecycle', 'unit_sales',\n",
      "                                    'projected_growth_pct',\n",
      "                                    'other_unit_pls_lost_sales_py',\n",
      "                                    'other_unit_pls_lost_sales', 'lookup_cnt',\n",
      "                                    'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                    'ntrans_wt0_ppy', 'ntrans_wt0_py',\n",
      "                                    'ntrans_wt0', 'vio_compared_to_cluster',\n",
      "                                    'bpg', 'qty_wt0', 'store_number',\n",
      "                                    'sku_number', 'application_count',\n",
      "                                    'pct_white', 'age', 'pct_college',\n",
      "                                    'pct_blue_collar',\n",
      "                                    'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  17.2s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.5s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.3s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total=  14.6s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "Winsorizer(tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "RecursiveFeatureElimination(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                            variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                       'lost_qty', 'ss_sales',\n",
      "                                       'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                       'failure_sales', 'lifecycle',\n",
      "                                       'unit_sales', 'projected_growth_pct',\n",
      "                                       'other_unit_pls_lost_sales_py',\n",
      "                                       'other_unit_pls_lost_sales',\n",
      "                                       'lookup_cnt', 'weighted_lookup_cnt',\n",
      "                                       'qty_wt0_ppy', 'ntrans_wt0_ppy',\n",
      "                                       'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                       'vio_compared_to_cluster', 'bpg',\n",
      "                                       'qty_wt0', 'store_number', 'sku_number',\n",
      "                                       'application_count', 'pct_white', 'age',\n",
      "                                       'pct_college', 'pct_blue_collar',\n",
      "                                       'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  16.4s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.4s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.2s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total= 1.4min\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "RecursiveFeatureAddition(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                         variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                    'lost_qty', 'ss_sales',\n",
      "                                    'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                    'failure_sales', 'lifecycle', 'unit_sales',\n",
      "                                    'projected_growth_pct',\n",
      "                                    'other_unit_pls_lost_sales_py',\n",
      "                                    'other_unit_pls_lost_sales', 'lookup_cnt',\n",
      "                                    'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                    'ntrans_wt0_ppy', 'ntrans_wt0_py',\n",
      "                                    'ntrans_wt0', 'vio_compared_to_cluster',\n",
      "                                    'bpg', 'qty_wt0', 'store_number',\n",
      "                                    'sku_number', 'application_count',\n",
      "                                    'pct_white', 'age', 'pct_college',\n",
      "                                    'pct_blue_collar',\n",
      "                                    'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  17.1s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.4s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.2s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total=  18.6s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr', tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "RecursiveFeatureElimination(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                            variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                       'lost_qty', 'ss_sales',\n",
      "                                       'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                       'failure_sales', 'lifecycle',\n",
      "                                       'unit_sales', 'projected_growth_pct',\n",
      "                                       'other_unit_pls_lost_sales_py',\n",
      "                                       'other_unit_pls_lost_sales',\n",
      "                                       'lookup_cnt', 'weighted_lookup_cnt',\n",
      "                                       'qty_wt0_ppy', 'ntrans_wt0_ppy',\n",
      "                                       'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                       'vio_compared_to_cluster', 'bpg',\n",
      "                                       'qty_wt0', 'store_number', 'sku_number',\n",
      "                                       'application_count', 'pct_white', 'age',\n",
      "                                       'pct_college', 'pct_blue_collar',\n",
      "                                       'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  16.2s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   1.7s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total= 1.4min\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.0s\n",
      "Fit\n",
      "RecursiveFeatureAddition(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                         variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                    'lost_qty', 'ss_sales',\n",
      "                                    'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                    'failure_sales', 'lifecycle', 'unit_sales',\n",
      "                                    'projected_growth_pct',\n",
      "                                    'other_unit_pls_lost_sales_py',\n",
      "                                    'other_unit_pls_lost_sales', 'lookup_cnt',\n",
      "                                    'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                    'ntrans_wt0_ppy', 'ntrans_wt0_py',\n",
      "                                    'ntrans_wt0', 'vio_compared_to_cluster',\n",
      "                                    'bpg', 'qty_wt0', 'store_number',\n",
      "                                    'sku_number', 'application_count',\n",
      "                                    'pct_white', 'age', 'pct_college',\n",
      "                                    'pct_blue_collar',\n",
      "                                    'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  16.6s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   1.8s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.2s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total=  16.3s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "RecursiveFeatureElimination(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                            variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                       'lost_qty', 'ss_sales',\n",
      "                                       'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                       'failure_sales', 'lifecycle',\n",
      "                                       'unit_sales', 'projected_growth_pct',\n",
      "                                       'other_unit_pls_lost_sales_py',\n",
      "                                       'other_unit_pls_lost_sales',\n",
      "                                       'lookup_cnt', 'weighted_lookup_cnt',\n",
      "                                       'qty_wt0_ppy', 'ntrans_wt0_ppy',\n",
      "                                       'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                       'vio_compared_to_cluster', 'bpg',\n",
      "                                       'qty_wt0', 'store_number', 'sku_number',\n",
      "                                       'application_count', 'pct_white', 'age',\n",
      "                                       'pct_college', 'pct_blue_collar',\n",
      "                                       'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  16.6s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   1.0s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.2s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total= 1.4min\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.0s\n",
      "Fit\n",
      "RecursiveFeatureAddition(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                         variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                    'lost_qty', 'ss_sales',\n",
      "                                    'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                    'failure_sales', 'lifecycle', 'unit_sales',\n",
      "                                    'projected_growth_pct',\n",
      "                                    'other_unit_pls_lost_sales_py',\n",
      "                                    'other_unit_pls_lost_sales', 'lookup_cnt',\n",
      "                                    'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                    'ntrans_wt0_ppy', 'ntrans_wt0_py',\n",
      "                                    'ntrans_wt0', 'vio_compared_to_cluster',\n",
      "                                    'bpg', 'qty_wt0', 'store_number',\n",
      "                                    'sku_number', 'application_count',\n",
      "                                    'pct_white', 'age', 'pct_college',\n",
      "                                    'pct_blue_collar',\n",
      "                                    'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  16.7s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   1.1s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.3s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total=  13.4s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.0s\n",
      "Fit\n",
      "Winsorizer(capping_method='iqr', tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "RecursiveFeatureElimination(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                            variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                       'lost_qty', 'ss_sales',\n",
      "                                       'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                       'failure_sales', 'lifecycle',\n",
      "                                       'unit_sales', 'projected_growth_pct',\n",
      "                                       'other_unit_pls_lost_sales_py',\n",
      "                                       'other_unit_pls_lost_sales',\n",
      "                                       'lookup_cnt', 'weighted_lookup_cnt',\n",
      "                                       'qty_wt0_ppy', 'ntrans_wt0_ppy',\n",
      "                                       'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                       'vio_compared_to_cluster', 'bpg',\n",
      "                                       'qty_wt0', 'store_number', 'sku_number',\n",
      "                                       'application_count', 'pct_white', 'age',\n",
      "                                       'pct_college', 'pct_blue_collar',\n",
      "                                       'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.6s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  16.7s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   1.0s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.2s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total= 1.4min\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "RecursiveFeatureAddition(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                         variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                    'lost_qty', 'ss_sales',\n",
      "                                    'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                    'failure_sales', 'lifecycle', 'unit_sales',\n",
      "                                    'projected_growth_pct',\n",
      "                                    'other_unit_pls_lost_sales_py',\n",
      "                                    'other_unit_pls_lost_sales', 'lookup_cnt',\n",
      "                                    'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                    'ntrans_wt0_ppy', 'ntrans_wt0_py',\n",
      "                                    'ntrans_wt0', 'vio_compared_to_cluster',\n",
      "                                    'bpg', 'qty_wt0', 'store_number',\n",
      "                                    'sku_number', 'application_count',\n",
      "                                    'pct_white', 'age', 'pct_college',\n",
      "                                    'pct_blue_collar',\n",
      "                                    'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  16.7s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   1.0s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.3s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total=  20.3s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "RecursiveFeatureElimination(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                            variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                       'lost_qty', 'ss_sales',\n",
      "                                       'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                       'failure_sales', 'lifecycle',\n",
      "                                       'unit_sales', 'projected_growth_pct',\n",
      "                                       'other_unit_pls_lost_sales_py',\n",
      "                                       'other_unit_pls_lost_sales',\n",
      "                                       'lookup_cnt', 'weighted_lookup_cnt',\n",
      "                                       'qty_wt0_ppy', 'ntrans_wt0_ppy',\n",
      "                                       'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                       'vio_compared_to_cluster', 'bpg',\n",
      "                                       'qty_wt0', 'store_number', 'sku_number',\n",
      "                                       'application_count', 'pct_white', 'age',\n",
      "                                       'pct_college', 'pct_blue_collar',\n",
      "                                       'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  16.4s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.9s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.2s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total= 1.4min\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.0s\n",
      "Fit\n",
      "RecursiveFeatureAddition(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                         variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                    'lost_qty', 'ss_sales',\n",
      "                                    'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                    'failure_sales', 'lifecycle', 'unit_sales',\n",
      "                                    'projected_growth_pct',\n",
      "                                    'other_unit_pls_lost_sales_py',\n",
      "                                    'other_unit_pls_lost_sales', 'lookup_cnt',\n",
      "                                    'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                    'ntrans_wt0_ppy', 'ntrans_wt0_py',\n",
      "                                    'ntrans_wt0', 'vio_compared_to_cluster',\n",
      "                                    'bpg', 'qty_wt0', 'store_number',\n",
      "                                    'sku_number', 'application_count',\n",
      "                                    'pct_white', 'age', 'pct_college',\n",
      "                                    'pct_blue_collar',\n",
      "                                    'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  16.7s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.8s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total=  14.8s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.0s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05,\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "RecursiveFeatureElimination(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                            variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                       'lost_qty', 'ss_sales',\n",
      "                                       'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                       'failure_sales', 'lifecycle',\n",
      "                                       'unit_sales', 'projected_growth_pct',\n",
      "                                       'other_unit_pls_lost_sales_py',\n",
      "                                       'other_unit_pls_lost_sales',\n",
      "                                       'lookup_cnt', 'weighted_lookup_cnt',\n",
      "                                       'qty_wt0_ppy', 'ntrans_wt0_ppy',\n",
      "                                       'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                       'vio_compared_to_cluster', 'bpg',\n",
      "                                       'qty_wt0', 'store_number', 'sku_number',\n",
      "                                       'application_count', 'pct_white', 'age',\n",
      "                                       'pct_college', 'pct_blue_collar',\n",
      "                                       'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  16.2s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.5s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.2s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total= 1.4min\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.0s\n",
      "Fit\n",
      "RecursiveFeatureAddition(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                         variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                    'lost_qty', 'ss_sales',\n",
      "                                    'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                    'failure_sales', 'lifecycle', 'unit_sales',\n",
      "                                    'projected_growth_pct',\n",
      "                                    'other_unit_pls_lost_sales_py',\n",
      "                                    'other_unit_pls_lost_sales', 'lookup_cnt',\n",
      "                                    'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                    'ntrans_wt0_ppy', 'ntrans_wt0_py',\n",
      "                                    'ntrans_wt0', 'vio_compared_to_cluster',\n",
      "                                    'bpg', 'qty_wt0', 'store_number',\n",
      "                                    'sku_number', 'application_count',\n",
      "                                    'pct_white', 'age', 'pct_college',\n",
      "                                    'pct_blue_collar',\n",
      "                                    'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  16.6s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.5s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.3s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total=  14.5s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.0s\n",
      "Fit\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "RecursiveFeatureElimination(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                            variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                       'lost_qty', 'ss_sales',\n",
      "                                       'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                       'failure_sales', 'lifecycle',\n",
      "                                       'unit_sales', 'projected_growth_pct',\n",
      "                                       'other_unit_pls_lost_sales_py',\n",
      "                                       'other_unit_pls_lost_sales',\n",
      "                                       'lookup_cnt', 'weighted_lookup_cnt',\n",
      "                                       'qty_wt0_ppy', 'ntrans_wt0_ppy',\n",
      "                                       'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                       'vio_compared_to_cluster', 'bpg',\n",
      "                                       'qty_wt0', 'store_number', 'sku_number',\n",
      "                                       'application_count', 'pct_white', 'age',\n",
      "                                       'pct_college', 'pct_blue_collar',\n",
      "                                       'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  16.6s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.6s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.4s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total= 1.4min\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "RecursiveFeatureAddition(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                         variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                    'lost_qty', 'ss_sales',\n",
      "                                    'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                    'failure_sales', 'lifecycle', 'unit_sales',\n",
      "                                    'projected_growth_pct',\n",
      "                                    'other_unit_pls_lost_sales_py',\n",
      "                                    'other_unit_pls_lost_sales', 'lookup_cnt',\n",
      "                                    'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                    'ntrans_wt0_ppy', 'ntrans_wt0_py',\n",
      "                                    'ntrans_wt0', 'vio_compared_to_cluster',\n",
      "                                    'bpg', 'qty_wt0', 'store_number',\n",
      "                                    'sku_number', 'application_count',\n",
      "                                    'pct_white', 'age', 'pct_college',\n",
      "                                    'pct_blue_collar',\n",
      "                                    'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  16.3s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.5s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.3s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total=  17.2s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.1s\n",
      "Fit\n",
      "None\n",
      "RecursiveFeatureElimination(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                            variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                       'lost_qty', 'ss_sales',\n",
      "                                       'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                       'failure_sales', 'lifecycle',\n",
      "                                       'unit_sales', 'projected_growth_pct',\n",
      "                                       'other_unit_pls_lost_sales_py',\n",
      "                                       'other_unit_pls_lost_sales',\n",
      "                                       'lookup_cnt', 'weighted_lookup_cnt',\n",
      "                                       'qty_wt0_ppy', 'ntrans_wt0_ppy',\n",
      "                                       'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                       'vio_compared_to_cluster', 'bpg',\n",
      "                                       'qty_wt0', 'store_number', 'sku_number',\n",
      "                                       'application_count', 'pct_white', 'age',\n",
      "                                       'pct_college', 'pct_blue_collar',\n",
      "                                       'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  20.5s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.0s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.9s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total= 1.4min\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.0s\n",
      "Fit\n",
      "RecursiveFeatureAddition(cv=5, estimator=LinearRegression(), scoring='r2',\n",
      "                         variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                    'lost_qty', 'ss_sales',\n",
      "                                    'avg_cluster_unit_sales', 'sales_signal',\n",
      "                                    'failure_sales', 'lifecycle', 'unit_sales',\n",
      "                                    'projected_growth_pct',\n",
      "                                    'other_unit_pls_lost_sales_py',\n",
      "                                    'other_unit_pls_lost_sales', 'lookup_cnt',\n",
      "                                    'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                    'ntrans_wt0_ppy', 'ntrans_wt0_py',\n",
      "                                    'ntrans_wt0', 'vio_compared_to_cluster',\n",
      "                                    'bpg', 'qty_wt0', 'store_number',\n",
      "                                    'sku_number', 'application_count',\n",
      "                                    'pct_white', 'age', 'pct_college',\n",
      "                                    'pct_blue_collar',\n",
      "                                    'median_household_income', ...])\n",
      "[Pipeline] ........... (step 1 of 8) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 8) Processing rare, total=   0.8s\n",
      "[Pipeline] ........ (step 3 of 8) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 8) Processing num_encode, total=  19.3s\n",
      "[Pipeline] ........... (step 5 of 8) Processing outlier, total=   0.0s\n",
      "[Pipeline] ....... (step 6 of 8) Processing filter_corr, total=   1.5s\n",
      "[Pipeline] .... (step 7 of 8) Processing feature_select, total=  20.4s\n",
      "[Pipeline] ............. (step 8 of 8) Processing model, total=   0.2s\n",
      "Fit\n"
     ]
    }
   ],
   "source": [
    "cat = [#ce.OneHotEncoder(top_categories=None,drop_last=True),\n",
    "       ce.CountFrequencyEncoder(encoding_method = \"count\"),\n",
    "      ce.MeanEncoder(variables = categories)\n",
    "      ]\n",
    "num = [#None,\n",
    "       tran.YeoJohnsonTransformer(variables= continuous),\n",
    "       #prep.FunctionTransformer(log_transform, kw_args={\"variables\":PosContinuous}),\n",
    "       #prep.FunctionTransformer(ratios, kw_args={\"variables\" : continuous, \"tuples\" : False}),\n",
    "       #prep.LogTransformer(base='10',variables=continuous)\n",
    "      ]\n",
    "mod = [#Ridge(),\n",
    "       LinearRegression()\n",
    "      ]\n",
    "outlier = [out.Winsorizer(capping_method = \"gaussian\", tail = \"both\",fold=3,variables=continuous),\n",
    "           out.Winsorizer(capping_method = \"gaussian\", tail = \"right\",fold=3,variables=continuous),\n",
    "           out.Winsorizer(capping_method = \"gaussian\", tail = \"left\",fold=3,variables=continuous),\n",
    "           out.Winsorizer(capping_method = \"iqr\", tail = \"both\",fold=3,variables=continuous),\n",
    "           out.Winsorizer(capping_method = \"iqr\", tail = \"right\",fold=3,variables=continuous),\n",
    "           out.Winsorizer(capping_method = \"iqr\", tail = \"left\",fold=3,variables=continuous),\n",
    "           out.Winsorizer(capping_method = \"quantiles\", tail = \"both\",fold=.05,variables=continuous),\n",
    "           out.Winsorizer(capping_method = \"quantiles\", tail = \"right\",fold=.05,variables=continuous),\n",
    "           out.Winsorizer(capping_method = \"quantiles\", tail = \"left\",fold=.05,variables=continuous),\n",
    "           None\n",
    "          ]\n",
    "#scale = [prep.StandardScaler(),None]\n",
    "\n",
    "MODEL = []\n",
    "CATEGORICAL = []\n",
    "NUMERIC = []\n",
    "OUTLIER = []\n",
    "SCALER = []\n",
    "FEATURE_SELECTION = []\n",
    "\n",
    "RMSE_TR = []\n",
    "MAE_TR = []\n",
    "R2_TR = []\n",
    "MAPE_TR = []\n",
    "SMAPE_TR = []\n",
    "\n",
    "RMSE_TE = []\n",
    "MAE_TE = []\n",
    "R2_TE = []\n",
    "MAPE_TE = []\n",
    "SMAPE_TE = []\n",
    "\n",
    "for m in mod: # loop through the models\n",
    "    print(m)\n",
    "    feat_select = [\n",
    "              #select.SelectByShuffling(estimator = m , scoring = \"r2\", cv=5,random_state=0),\n",
    "              #select.SelectBySingleFeaturePerformance(estimator = m , scoring = \"r2\", cv=5),\n",
    "             select.RecursiveFeatureElimination(estimator = m , scoring = \"r2\", cv=5,threshold=0.01),\n",
    "             select.RecursiveFeatureAddition(estimator = m , scoring = \"r2\", cv=5,threshold=0.01),\n",
    "             #None\n",
    "                  ]\n",
    "    for n in num: # loop through the numeric transformations\n",
    "        print(n)\n",
    "        for c in cat: # loop through the categorical encoding\n",
    "            print(c)\n",
    "            for o in outlier:\n",
    "                print(o)\n",
    "                #for s in scale:\n",
    "                    #print(s)\n",
    "                for f in feat_select:\n",
    "                    print(f)\n",
    "                    pipe = Pipeline([\n",
    "                            (\"makePos\", prep.FunctionTransformer(MakePos, kw_args={\"negs\": NegContinuous})),\n",
    "                            (\"rare\", ce.RareLabelEncoder(tol=0.01, n_categories=7, max_n_categories = 6, variables= categories, replace_with='Rare')),\n",
    "                            (\"cat_encode\",c),\n",
    "                            (\"num_encode\",n),\n",
    "                            (\"outlier\", o),\n",
    "                            (\"filter_corr\", prep.FunctionTransformer(highCorr,kw_args={\"keep\":[],\"cutOff\":0.95})),\n",
    "                            (\"feature_select\", f),\n",
    "                            #(\"scaling\",s),\n",
    "                            (\"model\",m)\n",
    "                        ],verbose=True)\n",
    "                    try:\n",
    "                        pipe.fit(X_train,y_train)\n",
    "                        print(\"Fit\")\n",
    "                        y_tr_pred = pipe.predict(X_train)\n",
    "                        y_te_pred = pipe.predict(X_test)\n",
    "\n",
    "                        MODEL.append(m)\n",
    "                        CATEGORICAL.append(c)\n",
    "                        NUMERIC.append(n)\n",
    "                        OUTLIER.append(o)\n",
    "                        #SCALER.append(s)\n",
    "                        FEATURE_SELECTION.append(f)\n",
    "                        RMSE_TR.append(math.sqrt(mean_squared_error(y_train,y_tr_pred)))\n",
    "                        MAE_TR.append(mean_absolute_error(y_train,y_tr_pred))\n",
    "                        R2_TR.append(r2_score(y_train,y_tr_pred))\n",
    "                        MAPE_TR.append(MAPE(y_train,y_tr_pred))\n",
    "                        SMAPE_TR.append(SMAPE(y_train,y_tr_pred))\n",
    "                        RMSE_TE.append(math.sqrt(mean_squared_error(y_test,y_te_pred)))\n",
    "                        MAE_TE.append(mean_absolute_error(y_test,y_te_pred))\n",
    "                        R2_TE.append(r2_score(y_test,y_te_pred))\n",
    "                        MAPE_TE.append(MAPE(y_test,y_te_pred))\n",
    "                        SMAPE_TE.append(SMAPE(y_test,y_te_pred))\n",
    "                    except:\n",
    "                        MODEL.append(m)\n",
    "                        CATEGORICAL.append(c)\n",
    "                        NUMERIC.append(n)\n",
    "                        OUTLIER.append(o)\n",
    "                        #SCALER.append(s)\n",
    "                        FEATURE_SELECTION.append(f)\n",
    "                        RMSE_TR.append(\".\")\n",
    "                        MAE_TR.append(\".\")\n",
    "                        R2_TR.append(\".\")\n",
    "                        MAPE_TR.append(\".\")\n",
    "                        SMAPE_TR.append(\".\")\n",
    "                        RMSE_TE.append(\".\")\n",
    "                        MAE_TE.append(\".\")\n",
    "                        R2_TE.append(\".\")\n",
    "                        MAPE_TE.append(\".\")\n",
    "                        SMAPE_TE.append(\".\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 = pd.DataFrame({\"MODEL\":MODEL,\n",
    "                       \"CATEGORICAL\":CATEGORICAL,\n",
    "                       \"NUMERIC\":NUMERIC,\n",
    "                        \"OUTLIER\":OUTLIER,\n",
    "                        #\"SCALER\":SCALER,\n",
    "                        \"FEATURE_SELECTION\":FEATURE_SELECTION,\n",
    "                       \"RMSE_TR\":RMSE_TR,\n",
    "                       \"MAE_TR\":MAE_TR,\n",
    "                       \"R2_TR\":R2_TR,\n",
    "                       \"MAPE_TR\":MAPE_TR,\n",
    "                       \"SMAPE_TR\":SMAPE_TR,\n",
    "                       \"RMSE_TE\":RMSE_TE,\n",
    "                       \"MAE_TE\":MAE_TE,\n",
    "                       \"R2_TE\":R2_TE,\n",
    "                       \"MAPE_TE\":MAPE_TE,\n",
    "                       \"SMAPE_TE\":SMAPE_TE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>CATEGORICAL</th>\n",
       "      <th>NUMERIC</th>\n",
       "      <th>OUTLIER</th>\n",
       "      <th>FEATURE_SELECTION</th>\n",
       "      <th>RMSE_TR</th>\n",
       "      <th>MAE_TR</th>\n",
       "      <th>R2_TR</th>\n",
       "      <th>MAPE_TR</th>\n",
       "      <th>SMAPE_TR</th>\n",
       "      <th>RMSE_TE</th>\n",
       "      <th>MAE_TE</th>\n",
       "      <th>R2_TE</th>\n",
       "      <th>MAPE_TE</th>\n",
       "      <th>SMAPE_TE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(tail='both',\\n           variables=...</td>\n",
       "      <td>RecursiveFeatureElimination(cv=5, estimator=Li...</td>\n",
       "      <td>213.333805</td>\n",
       "      <td>69.097560</td>\n",
       "      <td>0.357858</td>\n",
       "      <td>266.012896</td>\n",
       "      <td>84.084324</td>\n",
       "      <td>194.077180</td>\n",
       "      <td>68.487129</td>\n",
       "      <td>0.401734</td>\n",
       "      <td>260.469342</td>\n",
       "      <td>83.636146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(tail='both',\\n           variables=...</td>\n",
       "      <td>RecursiveFeatureAddition(cv=5, estimator=Linea...</td>\n",
       "      <td>214.589194</td>\n",
       "      <td>66.131919</td>\n",
       "      <td>0.350278</td>\n",
       "      <td>254.369999</td>\n",
       "      <td>80.478846</td>\n",
       "      <td>195.442140</td>\n",
       "      <td>65.678253</td>\n",
       "      <td>0.393289</td>\n",
       "      <td>249.832034</td>\n",
       "      <td>80.029183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(variables=['pop_est', 'pop_density'...</td>\n",
       "      <td>RecursiveFeatureElimination(cv=5, estimator=Li...</td>\n",
       "      <td>219.067884</td>\n",
       "      <td>74.578850</td>\n",
       "      <td>0.322874</td>\n",
       "      <td>297.981860</td>\n",
       "      <td>88.272291</td>\n",
       "      <td>200.365389</td>\n",
       "      <td>74.495753</td>\n",
       "      <td>0.362337</td>\n",
       "      <td>293.688644</td>\n",
       "      <td>88.052591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(variables=['pop_est', 'pop_density'...</td>\n",
       "      <td>RecursiveFeatureAddition(cv=5, estimator=Linea...</td>\n",
       "      <td>218.046758</td>\n",
       "      <td>71.042300</td>\n",
       "      <td>0.329172</td>\n",
       "      <td>285.672029</td>\n",
       "      <td>84.286898</td>\n",
       "      <td>199.206524</td>\n",
       "      <td>70.785163</td>\n",
       "      <td>0.369692</td>\n",
       "      <td>280.282836</td>\n",
       "      <td>83.875966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(tail='left',\\n           variables=...</td>\n",
       "      <td>RecursiveFeatureElimination(cv=5, estimator=Li...</td>\n",
       "      <td>205.661587</td>\n",
       "      <td>71.765056</td>\n",
       "      <td>0.403214</td>\n",
       "      <td>272.092041</td>\n",
       "      <td>87.935817</td>\n",
       "      <td>185.660075</td>\n",
       "      <td>70.886692</td>\n",
       "      <td>0.452502</td>\n",
       "      <td>265.120055</td>\n",
       "      <td>87.235720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(tail='left',\\n           variables=...</td>\n",
       "      <td>RecursiveFeatureAddition(cv=5, estimator=Linea...</td>\n",
       "      <td>208.042839</td>\n",
       "      <td>72.078063</td>\n",
       "      <td>0.389315</td>\n",
       "      <td>276.327756</td>\n",
       "      <td>88.241395</td>\n",
       "      <td>188.758327</td>\n",
       "      <td>71.333312</td>\n",
       "      <td>0.434076</td>\n",
       "      <td>270.067993</td>\n",
       "      <td>87.716027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='iqr', tail='both',\\...</td>\n",
       "      <td>RecursiveFeatureElimination(cv=5, estimator=Li...</td>\n",
       "      <td>212.391621</td>\n",
       "      <td>76.656155</td>\n",
       "      <td>0.363517</td>\n",
       "      <td>304.456783</td>\n",
       "      <td>91.611917</td>\n",
       "      <td>193.496035</td>\n",
       "      <td>76.274386</td>\n",
       "      <td>0.405311</td>\n",
       "      <td>296.313589</td>\n",
       "      <td>91.011127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='iqr', tail='both',\\...</td>\n",
       "      <td>RecursiveFeatureAddition(cv=5, estimator=Linea...</td>\n",
       "      <td>214.365600</td>\n",
       "      <td>76.469467</td>\n",
       "      <td>0.351631</td>\n",
       "      <td>317.083079</td>\n",
       "      <td>89.834068</td>\n",
       "      <td>195.516399</td>\n",
       "      <td>76.120018</td>\n",
       "      <td>0.392828</td>\n",
       "      <td>309.972563</td>\n",
       "      <td>89.421973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='iqr',\\n           v...</td>\n",
       "      <td>RecursiveFeatureElimination(cv=5, estimator=Li...</td>\n",
       "      <td>214.636951</td>\n",
       "      <td>77.265728</td>\n",
       "      <td>0.349989</td>\n",
       "      <td>323.954089</td>\n",
       "      <td>89.927583</td>\n",
       "      <td>195.780377</td>\n",
       "      <td>76.919811</td>\n",
       "      <td>0.391187</td>\n",
       "      <td>316.755502</td>\n",
       "      <td>89.512926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='iqr',\\n           v...</td>\n",
       "      <td>RecursiveFeatureAddition(cv=5, estimator=Linea...</td>\n",
       "      <td>217.806657</td>\n",
       "      <td>75.834448</td>\n",
       "      <td>0.330648</td>\n",
       "      <td>319.313053</td>\n",
       "      <td>88.442508</td>\n",
       "      <td>199.233025</td>\n",
       "      <td>75.656892</td>\n",
       "      <td>0.369525</td>\n",
       "      <td>314.180914</td>\n",
       "      <td>88.028608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='iqr', tail='left',\\...</td>\n",
       "      <td>RecursiveFeatureElimination(cv=5, estimator=Li...</td>\n",
       "      <td>205.401630</td>\n",
       "      <td>71.351985</td>\n",
       "      <td>0.404722</td>\n",
       "      <td>275.323701</td>\n",
       "      <td>87.920568</td>\n",
       "      <td>185.342831</td>\n",
       "      <td>70.468037</td>\n",
       "      <td>0.454371</td>\n",
       "      <td>267.841519</td>\n",
       "      <td>87.225063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='iqr', tail='left',\\...</td>\n",
       "      <td>RecursiveFeatureAddition(cv=5, estimator=Linea...</td>\n",
       "      <td>208.095652</td>\n",
       "      <td>71.696693</td>\n",
       "      <td>0.389004</td>\n",
       "      <td>280.654110</td>\n",
       "      <td>87.994709</td>\n",
       "      <td>188.760614</td>\n",
       "      <td>70.937885</td>\n",
       "      <td>0.434063</td>\n",
       "      <td>273.800577</td>\n",
       "      <td>87.473176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>RecursiveFeatureElimination(cv=5, estimator=Li...</td>\n",
       "      <td>225.901098</td>\n",
       "      <td>63.440737</td>\n",
       "      <td>0.279973</td>\n",
       "      <td>170.437941</td>\n",
       "      <td>74.708390</td>\n",
       "      <td>207.566746</td>\n",
       "      <td>63.284543</td>\n",
       "      <td>0.315677</td>\n",
       "      <td>168.980106</td>\n",
       "      <td>74.352128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>RecursiveFeatureAddition(cv=5, estimator=Linea...</td>\n",
       "      <td>222.565546</td>\n",
       "      <td>61.189326</td>\n",
       "      <td>0.301079</td>\n",
       "      <td>159.238636</td>\n",
       "      <td>73.347522</td>\n",
       "      <td>203.972490</td>\n",
       "      <td>60.794477</td>\n",
       "      <td>0.339172</td>\n",
       "      <td>157.596471</td>\n",
       "      <td>72.889620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>RecursiveFeatureElimination(cv=5, estimator=Li...</td>\n",
       "      <td>228.102432</td>\n",
       "      <td>65.346828</td>\n",
       "      <td>0.265872</td>\n",
       "      <td>221.726607</td>\n",
       "      <td>73.279170</td>\n",
       "      <td>209.895194</td>\n",
       "      <td>65.117390</td>\n",
       "      <td>0.300238</td>\n",
       "      <td>216.683302</td>\n",
       "      <td>72.748307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>RecursiveFeatureAddition(cv=5, estimator=Linea...</td>\n",
       "      <td>226.263348</td>\n",
       "      <td>64.281400</td>\n",
       "      <td>0.277662</td>\n",
       "      <td>199.472727</td>\n",
       "      <td>73.548395</td>\n",
       "      <td>207.962877</td>\n",
       "      <td>64.032941</td>\n",
       "      <td>0.313063</td>\n",
       "      <td>195.528333</td>\n",
       "      <td>73.093050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>RecursiveFeatureElimination(cv=5, estimator=Li...</td>\n",
       "      <td>204.186094</td>\n",
       "      <td>72.449690</td>\n",
       "      <td>0.411747</td>\n",
       "      <td>241.849609</td>\n",
       "      <td>91.509391</td>\n",
       "      <td>184.085227</td>\n",
       "      <td>71.531291</td>\n",
       "      <td>0.461751</td>\n",
       "      <td>236.197084</td>\n",
       "      <td>90.729653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>RecursiveFeatureAddition(cv=5, estimator=Linea...</td>\n",
       "      <td>206.715031</td>\n",
       "      <td>73.126736</td>\n",
       "      <td>0.397085</td>\n",
       "      <td>248.361274</td>\n",
       "      <td>91.157006</td>\n",
       "      <td>187.377139</td>\n",
       "      <td>72.381267</td>\n",
       "      <td>0.442328</td>\n",
       "      <td>244.003248</td>\n",
       "      <td>90.613138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>None</td>\n",
       "      <td>RecursiveFeatureElimination(cv=5, estimator=Li...</td>\n",
       "      <td>210.644282</td>\n",
       "      <td>75.626690</td>\n",
       "      <td>0.373947</td>\n",
       "      <td>299.279907</td>\n",
       "      <td>90.303215</td>\n",
       "      <td>191.433689</td>\n",
       "      <td>75.088070</td>\n",
       "      <td>0.417921</td>\n",
       "      <td>291.088843</td>\n",
       "      <td>89.602850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>None</td>\n",
       "      <td>RecursiveFeatureAddition(cv=5, estimator=Linea...</td>\n",
       "      <td>210.047230</td>\n",
       "      <td>72.731595</td>\n",
       "      <td>0.377491</td>\n",
       "      <td>291.566255</td>\n",
       "      <td>87.775410</td>\n",
       "      <td>189.910923</td>\n",
       "      <td>72.039263</td>\n",
       "      <td>0.427144</td>\n",
       "      <td>284.374571</td>\n",
       "      <td>87.221678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(tail='both',\\n           variables=...</td>\n",
       "      <td>RecursiveFeatureElimination(cv=5, estimator=Li...</td>\n",
       "      <td>212.804796</td>\n",
       "      <td>69.376900</td>\n",
       "      <td>0.361038</td>\n",
       "      <td>271.710889</td>\n",
       "      <td>83.908912</td>\n",
       "      <td>193.263364</td>\n",
       "      <td>68.771062</td>\n",
       "      <td>0.406741</td>\n",
       "      <td>265.808330</td>\n",
       "      <td>83.361267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(tail='both',\\n           variables=...</td>\n",
       "      <td>RecursiveFeatureAddition(cv=5, estimator=Linea...</td>\n",
       "      <td>213.837169</td>\n",
       "      <td>66.205877</td>\n",
       "      <td>0.354824</td>\n",
       "      <td>258.091440</td>\n",
       "      <td>80.414687</td>\n",
       "      <td>194.364187</td>\n",
       "      <td>65.765404</td>\n",
       "      <td>0.399963</td>\n",
       "      <td>253.266379</td>\n",
       "      <td>79.895396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(variables=['pop_est', 'pop_density'...</td>\n",
       "      <td>RecursiveFeatureElimination(cv=5, estimator=Li...</td>\n",
       "      <td>217.828343</td>\n",
       "      <td>73.531749</td>\n",
       "      <td>0.330515</td>\n",
       "      <td>293.287664</td>\n",
       "      <td>87.534241</td>\n",
       "      <td>198.694969</td>\n",
       "      <td>73.392149</td>\n",
       "      <td>0.372925</td>\n",
       "      <td>289.023115</td>\n",
       "      <td>87.320458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(variables=['pop_est', 'pop_density'...</td>\n",
       "      <td>RecursiveFeatureAddition(cv=5, estimator=Linea...</td>\n",
       "      <td>217.609992</td>\n",
       "      <td>71.759175</td>\n",
       "      <td>0.331857</td>\n",
       "      <td>294.153707</td>\n",
       "      <td>85.023646</td>\n",
       "      <td>198.440215</td>\n",
       "      <td>71.454400</td>\n",
       "      <td>0.374532</td>\n",
       "      <td>288.277307</td>\n",
       "      <td>84.544084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(tail='left',\\n           variables=...</td>\n",
       "      <td>RecursiveFeatureElimination(cv=5, estimator=Li...</td>\n",
       "      <td>205.661587</td>\n",
       "      <td>71.765056</td>\n",
       "      <td>0.403214</td>\n",
       "      <td>272.092041</td>\n",
       "      <td>87.935817</td>\n",
       "      <td>185.660075</td>\n",
       "      <td>70.886692</td>\n",
       "      <td>0.452502</td>\n",
       "      <td>265.120055</td>\n",
       "      <td>87.235720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(tail='left',\\n           variables=...</td>\n",
       "      <td>RecursiveFeatureAddition(cv=5, estimator=Linea...</td>\n",
       "      <td>206.458801</td>\n",
       "      <td>70.061941</td>\n",
       "      <td>0.398579</td>\n",
       "      <td>274.301510</td>\n",
       "      <td>85.779317</td>\n",
       "      <td>186.891324</td>\n",
       "      <td>69.349257</td>\n",
       "      <td>0.445216</td>\n",
       "      <td>267.538467</td>\n",
       "      <td>85.178178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='iqr', tail='both',\\...</td>\n",
       "      <td>RecursiveFeatureElimination(cv=5, estimator=Li...</td>\n",
       "      <td>211.124682</td>\n",
       "      <td>75.796379</td>\n",
       "      <td>0.371088</td>\n",
       "      <td>300.085617</td>\n",
       "      <td>91.227241</td>\n",
       "      <td>191.787065</td>\n",
       "      <td>75.351922</td>\n",
       "      <td>0.415770</td>\n",
       "      <td>291.999421</td>\n",
       "      <td>90.611007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='iqr', tail='both',\\...</td>\n",
       "      <td>RecursiveFeatureAddition(cv=5, estimator=Linea...</td>\n",
       "      <td>213.510390</td>\n",
       "      <td>76.261198</td>\n",
       "      <td>0.356794</td>\n",
       "      <td>319.255116</td>\n",
       "      <td>89.328931</td>\n",
       "      <td>194.236554</td>\n",
       "      <td>75.846501</td>\n",
       "      <td>0.400751</td>\n",
       "      <td>311.911579</td>\n",
       "      <td>88.888430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='iqr',\\n           v...</td>\n",
       "      <td>RecursiveFeatureElimination(cv=5, estimator=Li...</td>\n",
       "      <td>213.522597</td>\n",
       "      <td>76.250809</td>\n",
       "      <td>0.356721</td>\n",
       "      <td>319.283858</td>\n",
       "      <td>89.315218</td>\n",
       "      <td>194.247602</td>\n",
       "      <td>75.843067</td>\n",
       "      <td>0.400683</td>\n",
       "      <td>312.153142</td>\n",
       "      <td>88.889631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='iqr',\\n           v...</td>\n",
       "      <td>RecursiveFeatureAddition(cv=5, estimator=Linea...</td>\n",
       "      <td>217.270727</td>\n",
       "      <td>74.748543</td>\n",
       "      <td>0.333938</td>\n",
       "      <td>315.932673</td>\n",
       "      <td>87.247586</td>\n",
       "      <td>198.314869</td>\n",
       "      <td>74.517953</td>\n",
       "      <td>0.375322</td>\n",
       "      <td>310.512044</td>\n",
       "      <td>86.762415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='iqr', tail='left',\\...</td>\n",
       "      <td>RecursiveFeatureElimination(cv=5, estimator=Li...</td>\n",
       "      <td>205.401630</td>\n",
       "      <td>71.351985</td>\n",
       "      <td>0.404722</td>\n",
       "      <td>275.323701</td>\n",
       "      <td>87.920568</td>\n",
       "      <td>185.342831</td>\n",
       "      <td>70.468037</td>\n",
       "      <td>0.454371</td>\n",
       "      <td>267.841519</td>\n",
       "      <td>87.225063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='iqr', tail='left',\\...</td>\n",
       "      <td>RecursiveFeatureAddition(cv=5, estimator=Linea...</td>\n",
       "      <td>206.605164</td>\n",
       "      <td>69.833968</td>\n",
       "      <td>0.397726</td>\n",
       "      <td>279.757666</td>\n",
       "      <td>85.434851</td>\n",
       "      <td>186.999500</td>\n",
       "      <td>69.110885</td>\n",
       "      <td>0.444574</td>\n",
       "      <td>272.362794</td>\n",
       "      <td>84.829498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>RecursiveFeatureElimination(cv=5, estimator=Li...</td>\n",
       "      <td>224.578538</td>\n",
       "      <td>62.643086</td>\n",
       "      <td>0.288379</td>\n",
       "      <td>167.508266</td>\n",
       "      <td>74.079120</td>\n",
       "      <td>205.848124</td>\n",
       "      <td>62.452469</td>\n",
       "      <td>0.326962</td>\n",
       "      <td>166.039783</td>\n",
       "      <td>73.712066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>RecursiveFeatureAddition(cv=5, estimator=Linea...</td>\n",
       "      <td>222.463897</td>\n",
       "      <td>61.714371</td>\n",
       "      <td>0.301718</td>\n",
       "      <td>169.385409</td>\n",
       "      <td>73.213921</td>\n",
       "      <td>203.492689</td>\n",
       "      <td>61.305884</td>\n",
       "      <td>0.342277</td>\n",
       "      <td>167.060599</td>\n",
       "      <td>72.637089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>RecursiveFeatureElimination(cv=5, estimator=Li...</td>\n",
       "      <td>226.587668</td>\n",
       "      <td>64.591762</td>\n",
       "      <td>0.275590</td>\n",
       "      <td>218.743233</td>\n",
       "      <td>72.786353</td>\n",
       "      <td>207.902527</td>\n",
       "      <td>64.296662</td>\n",
       "      <td>0.313461</td>\n",
       "      <td>213.709586</td>\n",
       "      <td>72.248135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>RecursiveFeatureAddition(cv=5, estimator=Linea...</td>\n",
       "      <td>226.124928</td>\n",
       "      <td>65.388748</td>\n",
       "      <td>0.278546</td>\n",
       "      <td>211.484581</td>\n",
       "      <td>75.506314</td>\n",
       "      <td>207.409794</td>\n",
       "      <td>65.097856</td>\n",
       "      <td>0.316712</td>\n",
       "      <td>206.792642</td>\n",
       "      <td>74.919297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>RecursiveFeatureElimination(cv=5, estimator=Li...</td>\n",
       "      <td>204.186094</td>\n",
       "      <td>72.449690</td>\n",
       "      <td>0.411747</td>\n",
       "      <td>241.849609</td>\n",
       "      <td>91.509391</td>\n",
       "      <td>184.085227</td>\n",
       "      <td>71.531291</td>\n",
       "      <td>0.461751</td>\n",
       "      <td>236.197084</td>\n",
       "      <td>90.729653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>RecursiveFeatureAddition(cv=5, estimator=Linea...</td>\n",
       "      <td>205.230243</td>\n",
       "      <td>71.505661</td>\n",
       "      <td>0.405715</td>\n",
       "      <td>246.711975</td>\n",
       "      <td>89.072408</td>\n",
       "      <td>185.628697</td>\n",
       "      <td>70.796685</td>\n",
       "      <td>0.452687</td>\n",
       "      <td>241.980458</td>\n",
       "      <td>88.401634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>None</td>\n",
       "      <td>RecursiveFeatureElimination(cv=5, estimator=Li...</td>\n",
       "      <td>213.133294</td>\n",
       "      <td>76.652245</td>\n",
       "      <td>0.359064</td>\n",
       "      <td>319.699393</td>\n",
       "      <td>89.656746</td>\n",
       "      <td>193.940857</td>\n",
       "      <td>76.231181</td>\n",
       "      <td>0.402574</td>\n",
       "      <td>312.501802</td>\n",
       "      <td>89.230700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>None</td>\n",
       "      <td>RecursiveFeatureAddition(cv=5, estimator=Linea...</td>\n",
       "      <td>209.740468</td>\n",
       "      <td>72.671553</td>\n",
       "      <td>0.379308</td>\n",
       "      <td>296.792888</td>\n",
       "      <td>87.529662</td>\n",
       "      <td>189.311944</td>\n",
       "      <td>71.992520</td>\n",
       "      <td>0.430752</td>\n",
       "      <td>289.244281</td>\n",
       "      <td>86.952163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 MODEL                                        CATEGORICAL  \\\n",
       "0   LinearRegression()  CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "1   LinearRegression()  CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "2   LinearRegression()  CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "3   LinearRegression()  CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "4   LinearRegression()  CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "5   LinearRegression()  CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "6   LinearRegression()  CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "7   LinearRegression()  CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "8   LinearRegression()  CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "9   LinearRegression()  CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "10  LinearRegression()  CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "11  LinearRegression()  CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "12  LinearRegression()  CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "13  LinearRegression()  CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "14  LinearRegression()  CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "15  LinearRegression()  CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "16  LinearRegression()  CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "17  LinearRegression()  CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "18  LinearRegression()  CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "19  LinearRegression()  CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "20  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "21  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "22  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "23  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "24  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "25  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "26  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "27  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "28  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "29  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "30  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "31  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "32  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "33  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "34  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "35  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "36  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "37  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "38  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "39  LinearRegression()  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "\n",
       "                                              NUMERIC  \\\n",
       "0   YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "1   YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "2   YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "3   YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "4   YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "5   YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "6   YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "7   YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "8   YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "9   YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "10  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "11  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "12  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "13  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "14  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "15  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "16  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "17  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "18  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "19  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "20  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "21  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "22  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "23  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "24  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "25  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "26  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "27  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "28  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "29  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "30  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "31  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "32  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "33  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "34  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "35  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "36  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "37  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "38  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "39  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "\n",
       "                                              OUTLIER  \\\n",
       "0   Winsorizer(tail='both',\\n           variables=...   \n",
       "1   Winsorizer(tail='both',\\n           variables=...   \n",
       "2   Winsorizer(variables=['pop_est', 'pop_density'...   \n",
       "3   Winsorizer(variables=['pop_est', 'pop_density'...   \n",
       "4   Winsorizer(tail='left',\\n           variables=...   \n",
       "5   Winsorizer(tail='left',\\n           variables=...   \n",
       "6   Winsorizer(capping_method='iqr', tail='both',\\...   \n",
       "7   Winsorizer(capping_method='iqr', tail='both',\\...   \n",
       "8   Winsorizer(capping_method='iqr',\\n           v...   \n",
       "9   Winsorizer(capping_method='iqr',\\n           v...   \n",
       "10  Winsorizer(capping_method='iqr', tail='left',\\...   \n",
       "11  Winsorizer(capping_method='iqr', tail='left',\\...   \n",
       "12  Winsorizer(capping_method='quantiles', fold=0....   \n",
       "13  Winsorizer(capping_method='quantiles', fold=0....   \n",
       "14  Winsorizer(capping_method='quantiles', fold=0....   \n",
       "15  Winsorizer(capping_method='quantiles', fold=0....   \n",
       "16  Winsorizer(capping_method='quantiles', fold=0....   \n",
       "17  Winsorizer(capping_method='quantiles', fold=0....   \n",
       "18                                               None   \n",
       "19                                               None   \n",
       "20  Winsorizer(tail='both',\\n           variables=...   \n",
       "21  Winsorizer(tail='both',\\n           variables=...   \n",
       "22  Winsorizer(variables=['pop_est', 'pop_density'...   \n",
       "23  Winsorizer(variables=['pop_est', 'pop_density'...   \n",
       "24  Winsorizer(tail='left',\\n           variables=...   \n",
       "25  Winsorizer(tail='left',\\n           variables=...   \n",
       "26  Winsorizer(capping_method='iqr', tail='both',\\...   \n",
       "27  Winsorizer(capping_method='iqr', tail='both',\\...   \n",
       "28  Winsorizer(capping_method='iqr',\\n           v...   \n",
       "29  Winsorizer(capping_method='iqr',\\n           v...   \n",
       "30  Winsorizer(capping_method='iqr', tail='left',\\...   \n",
       "31  Winsorizer(capping_method='iqr', tail='left',\\...   \n",
       "32  Winsorizer(capping_method='quantiles', fold=0....   \n",
       "33  Winsorizer(capping_method='quantiles', fold=0....   \n",
       "34  Winsorizer(capping_method='quantiles', fold=0....   \n",
       "35  Winsorizer(capping_method='quantiles', fold=0....   \n",
       "36  Winsorizer(capping_method='quantiles', fold=0....   \n",
       "37  Winsorizer(capping_method='quantiles', fold=0....   \n",
       "38                                               None   \n",
       "39                                               None   \n",
       "\n",
       "                                    FEATURE_SELECTION     RMSE_TR     MAE_TR  \\\n",
       "0   RecursiveFeatureElimination(cv=5, estimator=Li...  213.333805  69.097560   \n",
       "1   RecursiveFeatureAddition(cv=5, estimator=Linea...  214.589194  66.131919   \n",
       "2   RecursiveFeatureElimination(cv=5, estimator=Li...  219.067884  74.578850   \n",
       "3   RecursiveFeatureAddition(cv=5, estimator=Linea...  218.046758  71.042300   \n",
       "4   RecursiveFeatureElimination(cv=5, estimator=Li...  205.661587  71.765056   \n",
       "5   RecursiveFeatureAddition(cv=5, estimator=Linea...  208.042839  72.078063   \n",
       "6   RecursiveFeatureElimination(cv=5, estimator=Li...  212.391621  76.656155   \n",
       "7   RecursiveFeatureAddition(cv=5, estimator=Linea...  214.365600  76.469467   \n",
       "8   RecursiveFeatureElimination(cv=5, estimator=Li...  214.636951  77.265728   \n",
       "9   RecursiveFeatureAddition(cv=5, estimator=Linea...  217.806657  75.834448   \n",
       "10  RecursiveFeatureElimination(cv=5, estimator=Li...  205.401630  71.351985   \n",
       "11  RecursiveFeatureAddition(cv=5, estimator=Linea...  208.095652  71.696693   \n",
       "12  RecursiveFeatureElimination(cv=5, estimator=Li...  225.901098  63.440737   \n",
       "13  RecursiveFeatureAddition(cv=5, estimator=Linea...  222.565546  61.189326   \n",
       "14  RecursiveFeatureElimination(cv=5, estimator=Li...  228.102432  65.346828   \n",
       "15  RecursiveFeatureAddition(cv=5, estimator=Linea...  226.263348  64.281400   \n",
       "16  RecursiveFeatureElimination(cv=5, estimator=Li...  204.186094  72.449690   \n",
       "17  RecursiveFeatureAddition(cv=5, estimator=Linea...  206.715031  73.126736   \n",
       "18  RecursiveFeatureElimination(cv=5, estimator=Li...  210.644282  75.626690   \n",
       "19  RecursiveFeatureAddition(cv=5, estimator=Linea...  210.047230  72.731595   \n",
       "20  RecursiveFeatureElimination(cv=5, estimator=Li...  212.804796  69.376900   \n",
       "21  RecursiveFeatureAddition(cv=5, estimator=Linea...  213.837169  66.205877   \n",
       "22  RecursiveFeatureElimination(cv=5, estimator=Li...  217.828343  73.531749   \n",
       "23  RecursiveFeatureAddition(cv=5, estimator=Linea...  217.609992  71.759175   \n",
       "24  RecursiveFeatureElimination(cv=5, estimator=Li...  205.661587  71.765056   \n",
       "25  RecursiveFeatureAddition(cv=5, estimator=Linea...  206.458801  70.061941   \n",
       "26  RecursiveFeatureElimination(cv=5, estimator=Li...  211.124682  75.796379   \n",
       "27  RecursiveFeatureAddition(cv=5, estimator=Linea...  213.510390  76.261198   \n",
       "28  RecursiveFeatureElimination(cv=5, estimator=Li...  213.522597  76.250809   \n",
       "29  RecursiveFeatureAddition(cv=5, estimator=Linea...  217.270727  74.748543   \n",
       "30  RecursiveFeatureElimination(cv=5, estimator=Li...  205.401630  71.351985   \n",
       "31  RecursiveFeatureAddition(cv=5, estimator=Linea...  206.605164  69.833968   \n",
       "32  RecursiveFeatureElimination(cv=5, estimator=Li...  224.578538  62.643086   \n",
       "33  RecursiveFeatureAddition(cv=5, estimator=Linea...  222.463897  61.714371   \n",
       "34  RecursiveFeatureElimination(cv=5, estimator=Li...  226.587668  64.591762   \n",
       "35  RecursiveFeatureAddition(cv=5, estimator=Linea...  226.124928  65.388748   \n",
       "36  RecursiveFeatureElimination(cv=5, estimator=Li...  204.186094  72.449690   \n",
       "37  RecursiveFeatureAddition(cv=5, estimator=Linea...  205.230243  71.505661   \n",
       "38  RecursiveFeatureElimination(cv=5, estimator=Li...  213.133294  76.652245   \n",
       "39  RecursiveFeatureAddition(cv=5, estimator=Linea...  209.740468  72.671553   \n",
       "\n",
       "       R2_TR     MAPE_TR   SMAPE_TR     RMSE_TE     MAE_TE     R2_TE  \\\n",
       "0   0.357858  266.012896  84.084324  194.077180  68.487129  0.401734   \n",
       "1   0.350278  254.369999  80.478846  195.442140  65.678253  0.393289   \n",
       "2   0.322874  297.981860  88.272291  200.365389  74.495753  0.362337   \n",
       "3   0.329172  285.672029  84.286898  199.206524  70.785163  0.369692   \n",
       "4   0.403214  272.092041  87.935817  185.660075  70.886692  0.452502   \n",
       "5   0.389315  276.327756  88.241395  188.758327  71.333312  0.434076   \n",
       "6   0.363517  304.456783  91.611917  193.496035  76.274386  0.405311   \n",
       "7   0.351631  317.083079  89.834068  195.516399  76.120018  0.392828   \n",
       "8   0.349989  323.954089  89.927583  195.780377  76.919811  0.391187   \n",
       "9   0.330648  319.313053  88.442508  199.233025  75.656892  0.369525   \n",
       "10  0.404722  275.323701  87.920568  185.342831  70.468037  0.454371   \n",
       "11  0.389004  280.654110  87.994709  188.760614  70.937885  0.434063   \n",
       "12  0.279973  170.437941  74.708390  207.566746  63.284543  0.315677   \n",
       "13  0.301079  159.238636  73.347522  203.972490  60.794477  0.339172   \n",
       "14  0.265872  221.726607  73.279170  209.895194  65.117390  0.300238   \n",
       "15  0.277662  199.472727  73.548395  207.962877  64.032941  0.313063   \n",
       "16  0.411747  241.849609  91.509391  184.085227  71.531291  0.461751   \n",
       "17  0.397085  248.361274  91.157006  187.377139  72.381267  0.442328   \n",
       "18  0.373947  299.279907  90.303215  191.433689  75.088070  0.417921   \n",
       "19  0.377491  291.566255  87.775410  189.910923  72.039263  0.427144   \n",
       "20  0.361038  271.710889  83.908912  193.263364  68.771062  0.406741   \n",
       "21  0.354824  258.091440  80.414687  194.364187  65.765404  0.399963   \n",
       "22  0.330515  293.287664  87.534241  198.694969  73.392149  0.372925   \n",
       "23  0.331857  294.153707  85.023646  198.440215  71.454400  0.374532   \n",
       "24  0.403214  272.092041  87.935817  185.660075  70.886692  0.452502   \n",
       "25  0.398579  274.301510  85.779317  186.891324  69.349257  0.445216   \n",
       "26  0.371088  300.085617  91.227241  191.787065  75.351922  0.415770   \n",
       "27  0.356794  319.255116  89.328931  194.236554  75.846501  0.400751   \n",
       "28  0.356721  319.283858  89.315218  194.247602  75.843067  0.400683   \n",
       "29  0.333938  315.932673  87.247586  198.314869  74.517953  0.375322   \n",
       "30  0.404722  275.323701  87.920568  185.342831  70.468037  0.454371   \n",
       "31  0.397726  279.757666  85.434851  186.999500  69.110885  0.444574   \n",
       "32  0.288379  167.508266  74.079120  205.848124  62.452469  0.326962   \n",
       "33  0.301718  169.385409  73.213921  203.492689  61.305884  0.342277   \n",
       "34  0.275590  218.743233  72.786353  207.902527  64.296662  0.313461   \n",
       "35  0.278546  211.484581  75.506314  207.409794  65.097856  0.316712   \n",
       "36  0.411747  241.849609  91.509391  184.085227  71.531291  0.461751   \n",
       "37  0.405715  246.711975  89.072408  185.628697  70.796685  0.452687   \n",
       "38  0.359064  319.699393  89.656746  193.940857  76.231181  0.402574   \n",
       "39  0.379308  296.792888  87.529662  189.311944  71.992520  0.430752   \n",
       "\n",
       "       MAPE_TE   SMAPE_TE  \n",
       "0   260.469342  83.636146  \n",
       "1   249.832034  80.029183  \n",
       "2   293.688644  88.052591  \n",
       "3   280.282836  83.875966  \n",
       "4   265.120055  87.235720  \n",
       "5   270.067993  87.716027  \n",
       "6   296.313589  91.011127  \n",
       "7   309.972563  89.421973  \n",
       "8   316.755502  89.512926  \n",
       "9   314.180914  88.028608  \n",
       "10  267.841519  87.225063  \n",
       "11  273.800577  87.473176  \n",
       "12  168.980106  74.352128  \n",
       "13  157.596471  72.889620  \n",
       "14  216.683302  72.748307  \n",
       "15  195.528333  73.093050  \n",
       "16  236.197084  90.729653  \n",
       "17  244.003248  90.613138  \n",
       "18  291.088843  89.602850  \n",
       "19  284.374571  87.221678  \n",
       "20  265.808330  83.361267  \n",
       "21  253.266379  79.895396  \n",
       "22  289.023115  87.320458  \n",
       "23  288.277307  84.544084  \n",
       "24  265.120055  87.235720  \n",
       "25  267.538467  85.178178  \n",
       "26  291.999421  90.611007  \n",
       "27  311.911579  88.888430  \n",
       "28  312.153142  88.889631  \n",
       "29  310.512044  86.762415  \n",
       "30  267.841519  87.225063  \n",
       "31  272.362794  84.829498  \n",
       "32  166.039783  73.712066  \n",
       "33  167.060599  72.637089  \n",
       "34  213.709586  72.248135  \n",
       "35  206.792642  74.919297  \n",
       "36  236.197084  90.729653  \n",
       "37  241.980458  88.401634  \n",
       "38  312.501802  89.230700  \n",
       "39  289.244281  86.952163  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3.to_csv('result8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge()\n",
      "YeoJohnsonTransformer(variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                 'avg_cluster_unit_sales',\n",
      "                                 'adjusted_avg_cluster_sales',\n",
      "                                 'avg_cluster_total_sales', 'sales_signal',\n",
      "                                 'failure_sales', 'lifecycle',\n",
      "                                 'adjusted_lifecycle',\n",
      "                                 'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                                 'projected_growth_pct',\n",
      "                                 'other_unit_pls_lost_sales_py',\n",
      "                                 'other_unit_pls_lost_sales',\n",
      "                                 'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                 'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                 'unadjusted_total_vio',\n",
      "                                 'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                 'pct_white', 'age', 'pct_college',\n",
      "                                 'pct_blue_collar', 'median_household_income',\n",
      "                                 'establishments', ...])\n",
      "MeanEncoder(variables=['bpg', 'store_number', 'sku_number', 'mpog_id'])\n",
      "Winsorizer(tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "True\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  17.7s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=   0.7s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=   0.0s\n",
      "Ridge()\n",
      "YeoJohnsonTransformer(variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                 'avg_cluster_unit_sales',\n",
      "                                 'adjusted_avg_cluster_sales',\n",
      "                                 'avg_cluster_total_sales', 'sales_signal',\n",
      "                                 'failure_sales', 'lifecycle',\n",
      "                                 'adjusted_lifecycle',\n",
      "                                 'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                                 'projected_growth_pct',\n",
      "                                 'other_unit_pls_lost_sales_py',\n",
      "                                 'other_unit_pls_lost_sales',\n",
      "                                 'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                 'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                 'unadjusted_total_vio',\n",
      "                                 'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                 'pct_white', 'age', 'pct_college',\n",
      "                                 'pct_blue_collar', 'median_household_income',\n",
      "                                 'establishments', ...])\n",
      "MeanEncoder(variables=['bpg', 'store_number', 'sku_number', 'mpog_id'])\n",
      "Winsorizer(tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "False\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  18.0s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=   0.7s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=   0.0s\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'StandardScaler' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-2ec79cce57de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcat\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# loop through the categorical encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutlier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m                     \u001b[0mX_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                     \u001b[0mX_te\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'StandardScaler' object is not iterable"
     ]
    }
   ],
   "source": [
    "cat = [#ce.OneHotEncoder(top_categories=None,drop_last=True),\n",
    "       #ce.CountFrequencyEncoder(encoding_method = \"count\"),\n",
    "      ce.MeanEncoder(variables = categories)\n",
    "      ]\n",
    "num = [#None,\n",
    "       tran.YeoJohnsonTransformer(variables= continuous),\n",
    "       #prep.FunctionTransformer(log_transform, kw_args={\"variables\":PosContinuous}),\n",
    "       #prep.FunctionTransformer(ratios, kw_args={\"variables\" : continuous, \"tuples\" : False}),\n",
    "       #prep.LogTransformer(base='10',variables=continuous)\n",
    "      ]\n",
    "mod = [Ridge()]\n",
    "outlier = [out.Winsorizer(capping_method = \"gaussian\", tail = \"both\",fold=3,variables=continuous),\n",
    "           out.Winsorizer(capping_method = \"gaussian\", tail = \"right\",fold=3,variables=continuous),\n",
    "           #out.Winsorizer(capping_method = \"gaussian\", tail = \"left\",fold=3,variables=continuous),\n",
    "           #out.Winsorizer(capping_method = \"iqr\", tail = \"both\",fold=3,variables=continuous),\n",
    "           #out.Winsorizer(capping_method = \"iqr\", tail = \"right\",fold=3,variables=continuous),\n",
    "           #out.Winsorizer(capping_method = \"iqr\", tail = \"left\",fold=3,variables=continuous),\n",
    "           #out.Winsorizer(capping_method = \"quantiles\", tail = \"both\",fold=.05,variables=continuous),\n",
    "           #out.Winsorizer(capping_method = \"quantiles\", tail = \"right\",fold=.05,variables=continuous),\n",
    "           #out.Winsorizer(capping_method = \"quantiles\", tail = \"left\",fold=.05,variables=continuous),\n",
    "           #None\n",
    "          ]\n",
    "\n",
    "scale = [True,False]\n",
    "\n",
    "MODEL = []\n",
    "CATEGORICAL = []\n",
    "NUMERIC = []\n",
    "OUTLIER = []\n",
    "SCALER = []\n",
    "FEATURE_SELECTION = []\n",
    "\n",
    "RMSE_TR = []\n",
    "MAE_TR = []\n",
    "R2_TR = []\n",
    "MAPE_TR = []\n",
    "SMAPE_TR = []\n",
    "\n",
    "RMSE_TE = []\n",
    "MAE_TE = []\n",
    "R2_TE = []\n",
    "MAPE_TE = []\n",
    "SMAPE_TE = []\n",
    "\n",
    "PVAL = []\n",
    "IMPORTANCE = []\n",
    "FEATURES = []\n",
    "\n",
    "\n",
    "for m in mod: # loop through the models\n",
    "    for n in num: # loop through the numeric transformations\n",
    "        for c in cat: # loop through the categorical encoding\n",
    "            for o in outlier:\n",
    "                X_tr = X_train.copy()\n",
    "                X_te = X_test.copy()\n",
    "                print(m)\n",
    "                print(n)\n",
    "                print(c)\n",
    "                print(o)\n",
    "                print(s)\n",
    "                pipe = Pipeline([\n",
    "                        (\"makePos\", prep.FunctionTransformer(MakePos, kw_args={\"negs\": NegContinuous})),\n",
    "                        (\"rare\", ce.RareLabelEncoder(tol=0.01, n_categories=7, max_n_categories = 6, variables= categories, replace_with='Rare')),\n",
    "                        (\"cat_encode\",c),\n",
    "                        (\"num_encode\",n),\n",
    "                        (\"outlier\", o),\n",
    "                        (\"filter_corr\", prep.FunctionTransformer(highCorr,kw_args={\"keep\":[],\"cutOff\":0.84}))\n",
    "                    ],verbose=True)\n",
    "                try:\n",
    "                    pipe.fit(X_tr,y_train)\n",
    "                    X_tr = pipe.transform(X_tr)\n",
    "                    X_te = pipe.transform(X_te)\n",
    "                    names = X_te.columns\n",
    "                    if s:\n",
    "                            scale = prep.StandardScaler()\n",
    "                            scale.fit(X_tr,y_train)\n",
    "                            X_tr = scale.transform(X_tr)\n",
    "                            X_te = scale.transform(X_te)\n",
    "                        model = m.copy()\n",
    "                        model.fit(X_tr,y_train)\n",
    "                        print(\"Fit\")\n",
    "                        y_tr_pred = model.predict(X_tr)\n",
    "                        y_te_pred = model.predict(X_te)\n",
    "                        try:\n",
    "                            importance = model.feature_importance_\n",
    "                            IMPORTANCE.append(importance)\n",
    "                            PVAL.append(\".\")\n",
    "                        except:\n",
    "                            pvalue_array = stats.coef_pval(model, X_test, y_test)\n",
    "                            pvalue_array = np.delete(pvalue_array, 0)\n",
    "                            PVAL.append(pvalue_array)\n",
    "                            IMPORTANCE.append(\".\")\n",
    "\n",
    "                        MODEL.append(m)\n",
    "                        CATEGORICAL.append(c)\n",
    "                        NUMERIC.append(n)\n",
    "                        OUTLIER.append(o)\n",
    "                        SCALER.append(s)\n",
    "                        RMSE_TR.append(math.sqrt(mean_squared_error(y_train,y_tr_pred)))\n",
    "                        MAE_TR.append(mean_absolute_error(y_train,y_tr_pred))\n",
    "                        R2_TR.append(r2_score(y_train,y_tr_pred))\n",
    "                        MAPE_TR.append(MAPE(y_train,y_tr_pred))\n",
    "                        SMAPE_TR.append(SMAPE(y_train,y_tr_pred))\n",
    "                        RMSE_TE.append(math.sqrt(mean_squared_error(y_test,y_te_pred)))\n",
    "                        MAE_TE.append(mean_absolute_error(y_test,y_te_pred))\n",
    "                        R2_TE.append(r2_score(y_test,y_te_pred))\n",
    "                        MAPE_TE.append(MAPE(y_test,y_te_pred))\n",
    "                        SMAPE_TE.append(SMAPE(y_test,y_te_pred))\n",
    "                        FEATURES.append(names)\n",
    "\n",
    "                        \n",
    "                    except:\n",
    "                        MODEL.append(m)\n",
    "                        CATEGORICAL.append(c)\n",
    "                        NUMERIC.append(n)\n",
    "                        OUTLIER.append(o)\n",
    "                        SCALER.append(s)\n",
    "                        RMSE_TR.append(\".\")\n",
    "                        MAE_TR.append(\".\")\n",
    "                        R2_TR.append(\".\")\n",
    "                        MAPE_TR.append(\".\")\n",
    "                        SMAPE_TR.append(\".\")\n",
    "                        RMSE_TE.append(\".\")\n",
    "                        MAE_TE.append(\".\")\n",
    "                        R2_TE.append(\".\")\n",
    "                        MAPE_TE.append(\".\")\n",
    "                        SMAPE_TE.append(\".\")\n",
    "                        FEATURES.append(\".\")\n",
    "                        PVAL.append(\".\")\n",
    "                        IMPORTANCE.append(\".\")\n",
    "                        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = pd.DataFrame({\"MODEL\":MODEL,\n",
    "                       \"NUMERIC\":NUMERIC,\n",
    "                        \"CATEGORICAL\":CATEGORICAL,\n",
    "                        \"OUTLIER\":OUTLIER,\n",
    "                        \"SCALER\":SCALER,\n",
    "                       \"RMSE_TR\":RMSE_TR,\n",
    "                       \"MAE_TR\":MAE_TR,\n",
    "                       \"R2_TR\":R2_TR,\n",
    "                       \"MAPE_TR\":MAPE_TR,\n",
    "                       \"SMAPE_TR\":SMAPE_TR,\n",
    "                       \"RMSE_TE\":RMSE_TE,\n",
    "                       \"MAE_TE\":MAE_TE,\n",
    "                       \"R2_TE\":R2_TE,\n",
    "                       \"MAPE_TE\":MAPE_TE,\n",
    "                       \"SMAPE_TE\":SMAPE_TE,\n",
    "                       \"FEATURES\":FEATURES,\n",
    "                       \"PVAL\":PVAL,\n",
    "                       \"IMPORTANCE\":IMPORTANCE})      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\"MODEL\":MODEL,\n",
    "                       \"NUMERIC\":NUMERIC,\n",
    "                        \"CATEGORICAL\":CATEGORICAL,\n",
    "                        \"OUTLIER\":OUTLIER,\n",
    "                        \"SCALER\":SCALER,\n",
    "                       \"RMSE_TR\":RMSE_TR,\n",
    "                       \"MAE_TR\":MAE_TR,\n",
    "                       \"R2_TR\":R2_TR,\n",
    "                       \"MAPE_TR\":MAPE_TR,\n",
    "                       \"SMAPE_TR\":SMAPE_TR,\n",
    "                       \"RMSE_TE\":RMSE_TE,\n",
    "                       \"MAE_TE\":MAE_TE,\n",
    "                       \"R2_TE\":R2_TE,\n",
    "                       \"MAPE_TE\":MAPE_TE,\n",
    "                       \"SMAPE_TE\":SMAPE_TE,\n",
    "                       \"FEATURES\":FEATURES,\n",
    "                       \"PVAL\":PVAL,\n",
    "                       \"IMPORTANCE\":IMPORTANCE})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>NUMERIC</th>\n",
       "      <th>CATEGORICAL</th>\n",
       "      <th>OUTLIER</th>\n",
       "      <th>SCALER</th>\n",
       "      <th>RMSE_TR</th>\n",
       "      <th>MAE_TR</th>\n",
       "      <th>R2_TR</th>\n",
       "      <th>MAPE_TR</th>\n",
       "      <th>SMAPE_TR</th>\n",
       "      <th>RMSE_TE</th>\n",
       "      <th>MAE_TE</th>\n",
       "      <th>R2_TE</th>\n",
       "      <th>MAPE_TE</th>\n",
       "      <th>SMAPE_TE</th>\n",
       "      <th>FEATURES</th>\n",
       "      <th>PVAL</th>\n",
       "      <th>IMPORTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge()</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>Winsorizer(tail='both',\\n           variables=...</td>\n",
       "      <td>True</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge()</td>\n",
       "      <td>YeoJohnsonTransformer(variables=['pop_est', 'p...</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>Winsorizer(tail='both',\\n           variables=...</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MODEL                                            NUMERIC  \\\n",
       "0  Ridge()  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "1  Ridge()  YeoJohnsonTransformer(variables=['pop_est', 'p...   \n",
       "\n",
       "                                         CATEGORICAL  \\\n",
       "0  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "1  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "\n",
       "                                             OUTLIER  SCALER RMSE_TR MAE_TR  \\\n",
       "0  Winsorizer(tail='both',\\n           variables=...    True       .      .   \n",
       "1  Winsorizer(tail='both',\\n           variables=...   False       .      .   \n",
       "\n",
       "  R2_TR MAPE_TR SMAPE_TR RMSE_TE MAE_TE R2_TE MAPE_TE SMAPE_TE FEATURES PVAL  \\\n",
       "0     .       .        .       .      .     .       .        .        .    .   \n",
       "1     .       .        .       .      .     .       .        .        .    .   \n",
       "\n",
       "  IMPORTANCE  \n",
       "0          .  \n",
       "1          .  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge()\n",
      "YeoJohnsonTransformer(variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                 'avg_cluster_unit_sales',\n",
      "                                 'adjusted_avg_cluster_sales',\n",
      "                                 'avg_cluster_total_sales', 'sales_signal',\n",
      "                                 'failure_sales', 'lifecycle',\n",
      "                                 'adjusted_lifecycle',\n",
      "                                 'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                                 'projected_growth_pct',\n",
      "                                 'other_unit_pls_lost_sales_py',\n",
      "                                 'other_unit_pls_lost_sales',\n",
      "                                 'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                 'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                 'unadjusted_total_vio',\n",
      "                                 'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                 'pct_white', 'age', 'pct_college',\n",
      "                                 'pct_blue_collar', 'median_household_income',\n",
      "                                 'establishments', ...])\n",
      "MeanEncoder(variables=['bpg', 'store_number', 'sku_number', 'mpog_id'])\n",
      "Winsorizer(tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "True\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  14.7s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=   0.6s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=   0.0s\n",
      "Ridge()\n",
      "YeoJohnsonTransformer(variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                                 'avg_cluster_unit_sales',\n",
      "                                 'adjusted_avg_cluster_sales',\n",
      "                                 'avg_cluster_total_sales', 'sales_signal',\n",
      "                                 'failure_sales', 'lifecycle',\n",
      "                                 'adjusted_lifecycle',\n",
      "                                 'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                                 'projected_growth_pct',\n",
      "                                 'other_unit_pls_lost_sales_py',\n",
      "                                 'other_unit_pls_lost_sales',\n",
      "                                 'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                 'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                 'unadjusted_total_vio',\n",
      "                                 'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                 'pct_white', 'age', 'pct_college',\n",
      "                                 'pct_blue_collar', 'median_household_income',\n",
      "                                 'establishments', ...])\n",
      "MeanEncoder(variables=['bpg', 'store_number', 'sku_number', 'mpog_id'])\n",
      "Winsorizer(tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "False\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  14.6s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=   0.6s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=   0.0s\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'StandardScaler' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-2ec79cce57de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcat\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# loop through the categorical encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutlier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m                     \u001b[0mX_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                     \u001b[0mX_te\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'StandardScaler' object is not iterable"
     ]
    }
   ],
   "source": [
    "cat = [#ce.OneHotEncoder(top_categories=None,drop_last=True),\n",
    "       #ce.CountFrequencyEncoder(encoding_method = \"count\"),\n",
    "      ce.MeanEncoder(variables = categories)\n",
    "      ]\n",
    "num = [#None,\n",
    "       tran.YeoJohnsonTransformer(variables= continuous),\n",
    "       #prep.FunctionTransformer(log_transform, kw_args={\"variables\":PosContinuous}),\n",
    "       #prep.FunctionTransformer(ratios, kw_args={\"variables\" : continuous, \"tuples\" : False}),\n",
    "       #prep.LogTransformer(base='10',variables=continuous)\n",
    "      ]\n",
    "mod = [Ridge()]\n",
    "outlier = [out.Winsorizer(capping_method = \"gaussian\", tail = \"both\",fold=3,variables=continuous),\n",
    "           out.Winsorizer(capping_method = \"gaussian\", tail = \"right\",fold=3,variables=continuous),\n",
    "           #out.Winsorizer(capping_method = \"gaussian\", tail = \"left\",fold=3,variables=continuous),\n",
    "           #out.Winsorizer(capping_method = \"iqr\", tail = \"both\",fold=3,variables=continuous),\n",
    "           #out.Winsorizer(capping_method = \"iqr\", tail = \"right\",fold=3,variables=continuous),\n",
    "           #out.Winsorizer(capping_method = \"iqr\", tail = \"left\",fold=3,variables=continuous),\n",
    "           #out.Winsorizer(capping_method = \"quantiles\", tail = \"both\",fold=.05,variables=continuous),\n",
    "           #out.Winsorizer(capping_method = \"quantiles\", tail = \"right\",fold=.05,variables=continuous),\n",
    "           #out.Winsorizer(capping_method = \"quantiles\", tail = \"left\",fold=.05,variables=continuous),\n",
    "           #None\n",
    "          ]\n",
    "\n",
    "scale = [True,False]\n",
    "\n",
    "MODEL = []\n",
    "CATEGORICAL = []\n",
    "NUMERIC = []\n",
    "OUTLIER = []\n",
    "SCALER = []\n",
    "FEATURE_SELECTION = []\n",
    "\n",
    "RMSE_TR = []\n",
    "MAE_TR = []\n",
    "R2_TR = []\n",
    "MAPE_TR = []\n",
    "SMAPE_TR = []\n",
    "\n",
    "RMSE_TE = []\n",
    "MAE_TE = []\n",
    "R2_TE = []\n",
    "MAPE_TE = []\n",
    "SMAPE_TE = []\n",
    "\n",
    "PVAL = []\n",
    "IMPORTANCE = []\n",
    "FEATURES = []\n",
    "\n",
    "\n",
    "for m in mod: # loop through the models\n",
    "    for n in num: # loop through the numeric transformations\n",
    "        for c in cat: # loop through the categorical encoding\n",
    "            for o in outlier:\n",
    "                for s in scale:\n",
    "                    X_tr = X_train.copy()\n",
    "                    X_te = X_test.copy()\n",
    "                    print(m)\n",
    "                    print(n)\n",
    "                    print(c)\n",
    "                    print(o)\n",
    "                    print(s)\n",
    "                    pipe = Pipeline([\n",
    "                        (\"makePos\", prep.FunctionTransformer(MakePos, kw_args={\"negs\": NegContinuous})),\n",
    "                        (\"rare\", ce.RareLabelEncoder(tol=0.01, n_categories=7, max_n_categories = 6, variables= categories, replace_with='Rare')),\n",
    "                        (\"cat_encode\",c),\n",
    "                        (\"num_encode\",n),\n",
    "                        (\"outlier\", o),\n",
    "                        (\"filter_corr\", prep.FunctionTransformer(highCorr,kw_args={\"keep\":[],\"cutOff\":0.84}))\n",
    "                    ],verbose=True)\n",
    "                    try:\n",
    "                        pipe.fit(X_tr,y_train)\n",
    "                        X_tr = pipe.transform(X_tr)\n",
    "                        X_te = pipe.transform(X_te)\n",
    "                        names = X_te.columns\n",
    "                        if s:\n",
    "                            scale = prep.StandardScaler()\n",
    "                            scale.fit(X_tr,y_train)\n",
    "                            X_tr = scale.transform(X_tr)\n",
    "                            X_te = scale.transform(X_te)\n",
    "                        model = m.copy()\n",
    "                        model.fit(X_tr,y_train)\n",
    "                        print(\"Fit\")\n",
    "                        y_tr_pred = model.predict(X_tr)\n",
    "                        y_te_pred = model.predict(X_te)\n",
    "                        try:\n",
    "                            importance = model.feature_importance_\n",
    "                            IMPORTANCE.append(importance)\n",
    "                            PVAL.append(\".\")\n",
    "                        except:\n",
    "                            pvalue_array = stats.coef_pval(model, X_test, y_test)\n",
    "                            pvalue_array = np.delete(pvalue_array, 0)\n",
    "                            PVAL.append(pvalue_array)\n",
    "                            IMPORTANCE.append(\".\")\n",
    "\n",
    "                        MODEL.append(m)\n",
    "                        CATEGORICAL.append(c)\n",
    "                        NUMERIC.append(n)\n",
    "                        OUTLIER.append(o)\n",
    "                        SCALER.append(s)\n",
    "                        RMSE_TR.append(math.sqrt(mean_squared_error(y_train,y_tr_pred)))\n",
    "                        MAE_TR.append(mean_absolute_error(y_train,y_tr_pred))\n",
    "                        R2_TR.append(r2_score(y_train,y_tr_pred))\n",
    "                        MAPE_TR.append(MAPE(y_train,y_tr_pred))\n",
    "                        SMAPE_TR.append(SMAPE(y_train,y_tr_pred))\n",
    "                        RMSE_TE.append(math.sqrt(mean_squared_error(y_test,y_te_pred)))\n",
    "                        MAE_TE.append(mean_absolute_error(y_test,y_te_pred))\n",
    "                        R2_TE.append(r2_score(y_test,y_te_pred))\n",
    "                        MAPE_TE.append(MAPE(y_test,y_te_pred))\n",
    "                        SMAPE_TE.append(SMAPE(y_test,y_te_pred))\n",
    "                        FEATURES.append(names)\n",
    "\n",
    "                        \n",
    "                    except:\n",
    "                        MODEL.append(m)\n",
    "                        CATEGORICAL.append(c)\n",
    "                        NUMERIC.append(n)\n",
    "                        OUTLIER.append(o)\n",
    "                        SCALER.append(s)\n",
    "                        RMSE_TR.append(\".\")\n",
    "                        MAE_TR.append(\".\")\n",
    "                        R2_TR.append(\".\")\n",
    "                        MAPE_TR.append(\".\")\n",
    "                        SMAPE_TR.append(\".\")\n",
    "                        RMSE_TE.append(\".\")\n",
    "                        MAE_TE.append(\".\")\n",
    "                        R2_TE.append(\".\")\n",
    "                        MAPE_TE.append(\".\")\n",
    "                        SMAPE_TE.append(\".\")\n",
    "                        FEATURES.append(\".\")\n",
    "                        PVAL.append(\".\")\n",
    "                        IMPORTANCE.append(\".\")\n",
    "                        \n",
    "\n",
    "results = pd.DataFrame({\"MODEL\":MODEL,\n",
    "                       \"NUMERIC\":NUMERIC,\n",
    "                        \"CATEGORICAL\":CATEGORICAL,\n",
    "                        \"OUTLIER\":OUTLIER,\n",
    "                        \"SCALER\":SCALER,\n",
    "                       \"RMSE_TR\":RMSE_TR,\n",
    "                       \"MAE_TR\":MAE_TR,\n",
    "                       \"R2_TR\":R2_TR,\n",
    "                       \"MAPE_TR\":MAPE_TR,\n",
    "                       \"SMAPE_TR\":SMAPE_TR,\n",
    "                       \"RMSE_TE\":RMSE_TE,\n",
    "                       \"MAE_TE\":MAE_TE,\n",
    "                       \"R2_TE\":R2_TE,\n",
    "                       \"MAPE_TE\":MAPE_TE,\n",
    "                       \"SMAPE_TE\":SMAPE_TE,\n",
    "                       \"FEATURES\":FEATURES,\n",
    "                       \"PVAL\":PVAL,\n",
    "                       \"IMPORTANCE\":IMPORTANCE})            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(random_state=0)\n",
      "FunctionTransformer(func=<function ratios at 0x00000293189A8D30>,\n",
      "                    kw_args={'tuples': False,\n",
      "                             'variables': ['pop_est', 'pop_density',\n",
      "                                           'total_vio',\n",
      "                                           'avg_cluster_unit_sales',\n",
      "                                           'adjusted_avg_cluster_sales',\n",
      "                                           'avg_cluster_total_sales',\n",
      "                                           'sales_signal', 'failure_sales',\n",
      "                                           'lifecycle', 'adjusted_lifecycle',\n",
      "                                           'adj_avg_cluster_total_sales',\n",
      "                                           'unit_sales', 'projected_growth_pct',\n",
      "                                           'other_unit_pls_lost_sales_py',\n",
      "                                           'other_unit_pls_lost_sales',\n",
      "                                           'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                           'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                           'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                           'unadjusted_total_vio',\n",
      "                                           'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                           'pct_white', 'age', 'pct_college',\n",
      "                                           'pct_blue_collar',\n",
      "                                           'median_household_income',\n",
      "                                           'establishments', ...]})\n",
      "CountFrequencyEncoder()\n",
      "Winsorizer(tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.3s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  24.9s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=  37.6s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=14.0min\n",
      "Fit\n",
      "44.932656570000105\n",
      "GradientBoostingRegressor(random_state=0)\n",
      "FunctionTransformer(func=<function ratios at 0x00000293189A8D30>,\n",
      "                    kw_args={'tuples': False,\n",
      "                             'variables': ['pop_est', 'pop_density',\n",
      "                                           'total_vio',\n",
      "                                           'avg_cluster_unit_sales',\n",
      "                                           'adjusted_avg_cluster_sales',\n",
      "                                           'avg_cluster_total_sales',\n",
      "                                           'sales_signal', 'failure_sales',\n",
      "                                           'lifecycle', 'adjusted_lifecycle',\n",
      "                                           'adj_avg_cluster_total_sales',\n",
      "                                           'unit_sales', 'projected_growth_pct',\n",
      "                                           'other_unit_pls_lost_sales_py',\n",
      "                                           'other_unit_pls_lost_sales',\n",
      "                                           'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                           'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                           'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                           'unadjusted_total_vio',\n",
      "                                           'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                           'pct_white', 'age', 'pct_college',\n",
      "                                           'pct_blue_collar',\n",
      "                                           'median_household_income',\n",
      "                                           'establishments', ...]})\n",
      "CountFrequencyEncoder(variables=['bpg', 'store_number', 'sku_number',\n",
      "                                 'mpog_id'])\n",
      "Winsorizer(variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  22.2s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=  35.3s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=12.0min\n",
      "Fit\n",
      "41.73898174499991\n",
      "GradientBoostingRegressor(random_state=0)\n",
      "FunctionTransformer(func=<function ratios at 0x00000293189A8D30>,\n",
      "                    kw_args={'tuples': False,\n",
      "                             'variables': ['pop_est', 'pop_density',\n",
      "                                           'total_vio',\n",
      "                                           'avg_cluster_unit_sales',\n",
      "                                           'adjusted_avg_cluster_sales',\n",
      "                                           'avg_cluster_total_sales',\n",
      "                                           'sales_signal', 'failure_sales',\n",
      "                                           'lifecycle', 'adjusted_lifecycle',\n",
      "                                           'adj_avg_cluster_total_sales',\n",
      "                                           'unit_sales', 'projected_growth_pct',\n",
      "                                           'other_unit_pls_lost_sales_py',\n",
      "                                           'other_unit_pls_lost_sales',\n",
      "                                           'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                           'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                           'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                           'unadjusted_total_vio',\n",
      "                                           'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                           'pct_white', 'age', 'pct_college',\n",
      "                                           'pct_blue_collar',\n",
      "                                           'median_household_income',\n",
      "                                           'establishments', ...]})\n",
      "CountFrequencyEncoder(variables=['bpg', 'store_number', 'sku_number',\n",
      "                                 'mpog_id'])\n",
      "Winsorizer(tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.3s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  19.9s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=  34.6s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=12.1min\n",
      "Fit\n",
      "41.5147519266667\n",
      "GradientBoostingRegressor(random_state=0)\n",
      "FunctionTransformer(func=<function ratios at 0x00000293189A8D30>,\n",
      "                    kw_args={'tuples': False,\n",
      "                             'variables': ['pop_est', 'pop_density',\n",
      "                                           'total_vio',\n",
      "                                           'avg_cluster_unit_sales',\n",
      "                                           'adjusted_avg_cluster_sales',\n",
      "                                           'avg_cluster_total_sales',\n",
      "                                           'sales_signal', 'failure_sales',\n",
      "                                           'lifecycle', 'adjusted_lifecycle',\n",
      "                                           'adj_avg_cluster_total_sales',\n",
      "                                           'unit_sales', 'projected_growth_pct',\n",
      "                                           'other_unit_pls_lost_sales_py',\n",
      "                                           'other_unit_pls_lost_sales',\n",
      "                                           'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                           'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                           'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                           'unadjusted_total_vio',\n",
      "                                           'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                           'pct_white', 'age', 'pct_college',\n",
      "                                           'pct_blue_collar',\n",
      "                                           'median_household_income',\n",
      "                                           'establishments', ...]})\n",
      "CountFrequencyEncoder(variables=['bpg', 'store_number', 'sku_number',\n",
      "                                 'mpog_id'])\n",
      "Winsorizer(capping_method='iqr', tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.3s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  20.2s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=  31.7s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=12.2min\n",
      "Fit\n",
      "42.17443846833315\n",
      "GradientBoostingRegressor(random_state=0)\n",
      "FunctionTransformer(func=<function ratios at 0x00000293189A8D30>,\n",
      "                    kw_args={'tuples': False,\n",
      "                             'variables': ['pop_est', 'pop_density',\n",
      "                                           'total_vio',\n",
      "                                           'avg_cluster_unit_sales',\n",
      "                                           'adjusted_avg_cluster_sales',\n",
      "                                           'avg_cluster_total_sales',\n",
      "                                           'sales_signal', 'failure_sales',\n",
      "                                           'lifecycle', 'adjusted_lifecycle',\n",
      "                                           'adj_avg_cluster_total_sales',\n",
      "                                           'unit_sales', 'projected_growth_pct',\n",
      "                                           'other_unit_pls_lost_sales_py',\n",
      "                                           'other_unit_pls_lost_sales',\n",
      "                                           'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                           'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                           'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                           'unadjusted_total_vio',\n",
      "                                           'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                           'pct_white', 'age', 'pct_college',\n",
      "                                           'pct_blue_collar',\n",
      "                                           'median_household_income',\n",
      "                                           'establishments', ...]})\n",
      "CountFrequencyEncoder(variables=['bpg', 'store_number', 'sku_number',\n",
      "                                 'mpog_id'])\n",
      "Winsorizer(capping_method='iqr',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.3s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  21.2s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=  38.3s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=12.2min\n",
      "Fit\n",
      "42.299866613333144\n",
      "GradientBoostingRegressor(random_state=0)\n",
      "FunctionTransformer(func=<function ratios at 0x00000293189A8D30>,\n",
      "                    kw_args={'tuples': False,\n",
      "                             'variables': ['pop_est', 'pop_density',\n",
      "                                           'total_vio',\n",
      "                                           'avg_cluster_unit_sales',\n",
      "                                           'adjusted_avg_cluster_sales',\n",
      "                                           'avg_cluster_total_sales',\n",
      "                                           'sales_signal', 'failure_sales',\n",
      "                                           'lifecycle', 'adjusted_lifecycle',\n",
      "                                           'adj_avg_cluster_total_sales',\n",
      "                                           'unit_sales', 'projected_growth_pct',\n",
      "                                           'other_unit_pls_lost_sales_py',\n",
      "                                           'other_unit_pls_lost_sales',\n",
      "                                           'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                           'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                           'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                           'unadjusted_total_vio',\n",
      "                                           'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                           'pct_white', 'age', 'pct_college',\n",
      "                                           'pct_blue_collar',\n",
      "                                           'median_household_income',\n",
      "                                           'establishments', ...]})\n",
      "CountFrequencyEncoder(variables=['bpg', 'store_number', 'sku_number',\n",
      "                                 'mpog_id'])\n",
      "Winsorizer(capping_method='iqr', tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.3s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  20.6s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=  32.2s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=12.1min\n",
      "Fit\n",
      "41.63765726833323\n",
      "GradientBoostingRegressor(random_state=0)\n",
      "FunctionTransformer(func=<function ratios at 0x00000293189A8D30>,\n",
      "                    kw_args={'tuples': False,\n",
      "                             'variables': ['pop_est', 'pop_density',\n",
      "                                           'total_vio',\n",
      "                                           'avg_cluster_unit_sales',\n",
      "                                           'adjusted_avg_cluster_sales',\n",
      "                                           'avg_cluster_total_sales',\n",
      "                                           'sales_signal', 'failure_sales',\n",
      "                                           'lifecycle', 'adjusted_lifecycle',\n",
      "                                           'adj_avg_cluster_total_sales',\n",
      "                                           'unit_sales', 'projected_growth_pct',\n",
      "                                           'other_unit_pls_lost_sales_py',\n",
      "                                           'other_unit_pls_lost_sales',\n",
      "                                           'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                           'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                           'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                           'unadjusted_total_vio',\n",
      "                                           'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                           'pct_white', 'age', 'pct_college',\n",
      "                                           'pct_blue_collar',\n",
      "                                           'median_household_income',\n",
      "                                           'establishments', ...]})\n",
      "CountFrequencyEncoder(variables=['bpg', 'store_number', 'sku_number',\n",
      "                                 'mpog_id'])\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.7s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  20.0s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=  38.6s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=12.0min\n",
      "Fit\n",
      "42.71746296666679\n",
      "GradientBoostingRegressor(random_state=0)\n",
      "FunctionTransformer(func=<function ratios at 0x00000293189A8D30>,\n",
      "                    kw_args={'tuples': False,\n",
      "                             'variables': ['pop_est', 'pop_density',\n",
      "                                           'total_vio',\n",
      "                                           'avg_cluster_unit_sales',\n",
      "                                           'adjusted_avg_cluster_sales',\n",
      "                                           'avg_cluster_total_sales',\n",
      "                                           'sales_signal', 'failure_sales',\n",
      "                                           'lifecycle', 'adjusted_lifecycle',\n",
      "                                           'adj_avg_cluster_total_sales',\n",
      "                                           'unit_sales', 'projected_growth_pct',\n",
      "                                           'other_unit_pls_lost_sales_py',\n",
      "                                           'other_unit_pls_lost_sales',\n",
      "                                           'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                           'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                           'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                           'unadjusted_total_vio',\n",
      "                                           'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                           'pct_white', 'age', 'pct_college',\n",
      "                                           'pct_blue_collar',\n",
      "                                           'median_household_income',\n",
      "                                           'establishments', ...]})\n",
      "CountFrequencyEncoder(variables=['bpg', 'store_number', 'sku_number',\n",
      "                                 'mpog_id'])\n",
      "Winsorizer(capping_method='quantiles', fold=0.05,\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  20.1s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=  33.7s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=12.3min\n",
      "Fit\n",
      "43.19172202166665\n",
      "GradientBoostingRegressor(random_state=0)\n",
      "FunctionTransformer(func=<function ratios at 0x00000293189A8D30>,\n",
      "                    kw_args={'tuples': False,\n",
      "                             'variables': ['pop_est', 'pop_density',\n",
      "                                           'total_vio',\n",
      "                                           'avg_cluster_unit_sales',\n",
      "                                           'adjusted_avg_cluster_sales',\n",
      "                                           'avg_cluster_total_sales',\n",
      "                                           'sales_signal', 'failure_sales',\n",
      "                                           'lifecycle', 'adjusted_lifecycle',\n",
      "                                           'adj_avg_cluster_total_sales',\n",
      "                                           'unit_sales', 'projected_growth_pct',\n",
      "                                           'other_unit_pls_lost_sales_py',\n",
      "                                           'other_unit_pls_lost_sales',\n",
      "                                           'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                           'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                           'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                           'unadjusted_total_vio',\n",
      "                                           'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                           'pct_white', 'age', 'pct_college',\n",
      "                                           'pct_blue_collar',\n",
      "                                           'median_household_income',\n",
      "                                           'establishments', ...]})\n",
      "CountFrequencyEncoder(variables=['bpg', 'store_number', 'sku_number',\n",
      "                                 'mpog_id'])\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.3s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  20.1s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=  34.3s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=12.5min\n",
      "Fit\n",
      "42.352251119999956\n",
      "GradientBoostingRegressor(random_state=0)\n",
      "FunctionTransformer(func=<function ratios at 0x00000293189A8D30>,\n",
      "                    kw_args={'tuples': False,\n",
      "                             'variables': ['pop_est', 'pop_density',\n",
      "                                           'total_vio',\n",
      "                                           'avg_cluster_unit_sales',\n",
      "                                           'adjusted_avg_cluster_sales',\n",
      "                                           'avg_cluster_total_sales',\n",
      "                                           'sales_signal', 'failure_sales',\n",
      "                                           'lifecycle', 'adjusted_lifecycle',\n",
      "                                           'adj_avg_cluster_total_sales',\n",
      "                                           'unit_sales', 'projected_growth_pct',\n",
      "                                           'other_unit_pls_lost_sales_py',\n",
      "                                           'other_unit_pls_lost_sales',\n",
      "                                           'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                           'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                           'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                           'unadjusted_total_vio',\n",
      "                                           'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                           'pct_white', 'age', 'pct_college',\n",
      "                                           'pct_blue_collar',\n",
      "                                           'median_household_income',\n",
      "                                           'establishments', ...]})\n",
      "CountFrequencyEncoder(variables=['bpg', 'store_number', 'sku_number',\n",
      "                                 'mpog_id'])\n",
      "None\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.4s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  20.6s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=   0.0s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=12.2min\n",
      "Fit\n",
      "41.42785014666661\n",
      "GradientBoostingRegressor(random_state=0)\n",
      "FunctionTransformer(func=<function ratios at 0x00000293189A8D30>,\n",
      "                    kw_args={'tuples': False,\n",
      "                             'variables': ['pop_est', 'pop_density',\n",
      "                                           'total_vio',\n",
      "                                           'avg_cluster_unit_sales',\n",
      "                                           'adjusted_avg_cluster_sales',\n",
      "                                           'avg_cluster_total_sales',\n",
      "                                           'sales_signal', 'failure_sales',\n",
      "                                           'lifecycle', 'adjusted_lifecycle',\n",
      "                                           'adj_avg_cluster_total_sales',\n",
      "                                           'unit_sales', 'projected_growth_pct',\n",
      "                                           'other_unit_pls_lost_sales_py',\n",
      "                                           'other_unit_pls_lost_sales',\n",
      "                                           'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                           'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                           'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                           'unadjusted_total_vio',\n",
      "                                           'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                           'pct_white', 'age', 'pct_college',\n",
      "                                           'pct_blue_collar',\n",
      "                                           'median_household_income',\n",
      "                                           'establishments', ...]})\n",
      "MeanEncoder(variables=['bpg', 'store_number', 'sku_number', 'mpog_id'])\n",
      "Winsorizer(tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  21.4s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=  29.1s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=12.4min\n",
      "Fit\n",
      "43.405981048333345\n",
      "GradientBoostingRegressor(random_state=0)\n",
      "FunctionTransformer(func=<function ratios at 0x00000293189A8D30>,\n",
      "                    kw_args={'tuples': False,\n",
      "                             'variables': ['pop_est', 'pop_density',\n",
      "                                           'total_vio',\n",
      "                                           'avg_cluster_unit_sales',\n",
      "                                           'adjusted_avg_cluster_sales',\n",
      "                                           'avg_cluster_total_sales',\n",
      "                                           'sales_signal', 'failure_sales',\n",
      "                                           'lifecycle', 'adjusted_lifecycle',\n",
      "                                           'adj_avg_cluster_total_sales',\n",
      "                                           'unit_sales', 'projected_growth_pct',\n",
      "                                           'other_unit_pls_lost_sales_py',\n",
      "                                           'other_unit_pls_lost_sales',\n",
      "                                           'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                           'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                           'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                           'unadjusted_total_vio',\n",
      "                                           'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                           'pct_white', 'age', 'pct_college',\n",
      "                                           'pct_blue_collar',\n",
      "                                           'median_household_income',\n",
      "                                           'establishments', ...]})\n",
      "MeanEncoder(variables=['bpg', 'store_number', 'sku_number', 'mpog_id'])\n",
      "Winsorizer(variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  21.7s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=  49.7s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=12.1min\n",
      "Fit\n",
      "42.99053868500002\n",
      "GradientBoostingRegressor(random_state=0)\n",
      "FunctionTransformer(func=<function ratios at 0x00000293189A8D30>,\n",
      "                    kw_args={'tuples': False,\n",
      "                             'variables': ['pop_est', 'pop_density',\n",
      "                                           'total_vio',\n",
      "                                           'avg_cluster_unit_sales',\n",
      "                                           'adjusted_avg_cluster_sales',\n",
      "                                           'avg_cluster_total_sales',\n",
      "                                           'sales_signal', 'failure_sales',\n",
      "                                           'lifecycle', 'adjusted_lifecycle',\n",
      "                                           'adj_avg_cluster_total_sales',\n",
      "                                           'unit_sales', 'projected_growth_pct',\n",
      "                                           'other_unit_pls_lost_sales_py',\n",
      "                                           'other_unit_pls_lost_sales',\n",
      "                                           'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                           'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                           'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                           'unadjusted_total_vio',\n",
      "                                           'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                           'pct_white', 'age', 'pct_college',\n",
      "                                           'pct_blue_collar',\n",
      "                                           'median_household_income',\n",
      "                                           'establishments', ...]})\n",
      "MeanEncoder(variables=['bpg', 'store_number', 'sku_number', 'mpog_id'])\n",
      "Winsorizer(tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  20.8s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=  39.6s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=12.3min\n",
      "Fit\n",
      "42.26499348500001\n",
      "GradientBoostingRegressor(random_state=0)\n",
      "FunctionTransformer(func=<function ratios at 0x00000293189A8D30>,\n",
      "                    kw_args={'tuples': False,\n",
      "                             'variables': ['pop_est', 'pop_density',\n",
      "                                           'total_vio',\n",
      "                                           'avg_cluster_unit_sales',\n",
      "                                           'adjusted_avg_cluster_sales',\n",
      "                                           'avg_cluster_total_sales',\n",
      "                                           'sales_signal', 'failure_sales',\n",
      "                                           'lifecycle', 'adjusted_lifecycle',\n",
      "                                           'adj_avg_cluster_total_sales',\n",
      "                                           'unit_sales', 'projected_growth_pct',\n",
      "                                           'other_unit_pls_lost_sales_py',\n",
      "                                           'other_unit_pls_lost_sales',\n",
      "                                           'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                           'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                           'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                           'unadjusted_total_vio',\n",
      "                                           'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                           'pct_white', 'age', 'pct_college',\n",
      "                                           'pct_blue_collar',\n",
      "                                           'median_household_income',\n",
      "                                           'establishments', ...]})\n",
      "MeanEncoder(variables=['bpg', 'store_number', 'sku_number', 'mpog_id'])\n",
      "Winsorizer(capping_method='iqr', tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  20.6s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=  47.4s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=12.6min\n",
      "Fit\n",
      "43.27206169666655\n",
      "GradientBoostingRegressor(random_state=0)\n",
      "FunctionTransformer(func=<function ratios at 0x00000293189A8D30>,\n",
      "                    kw_args={'tuples': False,\n",
      "                             'variables': ['pop_est', 'pop_density',\n",
      "                                           'total_vio',\n",
      "                                           'avg_cluster_unit_sales',\n",
      "                                           'adjusted_avg_cluster_sales',\n",
      "                                           'avg_cluster_total_sales',\n",
      "                                           'sales_signal', 'failure_sales',\n",
      "                                           'lifecycle', 'adjusted_lifecycle',\n",
      "                                           'adj_avg_cluster_total_sales',\n",
      "                                           'unit_sales', 'projected_growth_pct',\n",
      "                                           'other_unit_pls_lost_sales_py',\n",
      "                                           'other_unit_pls_lost_sales',\n",
      "                                           'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                           'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                           'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                           'unadjusted_total_vio',\n",
      "                                           'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                           'pct_white', 'age', 'pct_college',\n",
      "                                           'pct_blue_collar',\n",
      "                                           'median_household_income',\n",
      "                                           'establishments', ...]})\n",
      "MeanEncoder(variables=['bpg', 'store_number', 'sku_number', 'mpog_id'])\n",
      "Winsorizer(capping_method='iqr',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  21.1s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=  37.1s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=12.4min\n",
      "Fit\n",
      "43.40420518499983\n",
      "GradientBoostingRegressor(random_state=0)\n",
      "FunctionTransformer(func=<function ratios at 0x00000293189A8D30>,\n",
      "                    kw_args={'tuples': False,\n",
      "                             'variables': ['pop_est', 'pop_density',\n",
      "                                           'total_vio',\n",
      "                                           'avg_cluster_unit_sales',\n",
      "                                           'adjusted_avg_cluster_sales',\n",
      "                                           'avg_cluster_total_sales',\n",
      "                                           'sales_signal', 'failure_sales',\n",
      "                                           'lifecycle', 'adjusted_lifecycle',\n",
      "                                           'adj_avg_cluster_total_sales',\n",
      "                                           'unit_sales', 'projected_growth_pct',\n",
      "                                           'other_unit_pls_lost_sales_py',\n",
      "                                           'other_unit_pls_lost_sales',\n",
      "                                           'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                           'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                           'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                           'unadjusted_total_vio',\n",
      "                                           'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                           'pct_white', 'age', 'pct_college',\n",
      "                                           'pct_blue_collar',\n",
      "                                           'median_household_income',\n",
      "                                           'establishments', ...]})\n",
      "MeanEncoder(variables=['bpg', 'store_number', 'sku_number', 'mpog_id'])\n",
      "Winsorizer(capping_method='iqr', tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  20.6s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=  39.9s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=12.4min\n",
      "Fit\n",
      "42.73817415500016\n",
      "GradientBoostingRegressor(random_state=0)\n",
      "FunctionTransformer(func=<function ratios at 0x00000293189A8D30>,\n",
      "                    kw_args={'tuples': False,\n",
      "                             'variables': ['pop_est', 'pop_density',\n",
      "                                           'total_vio',\n",
      "                                           'avg_cluster_unit_sales',\n",
      "                                           'adjusted_avg_cluster_sales',\n",
      "                                           'avg_cluster_total_sales',\n",
      "                                           'sales_signal', 'failure_sales',\n",
      "                                           'lifecycle', 'adjusted_lifecycle',\n",
      "                                           'adj_avg_cluster_total_sales',\n",
      "                                           'unit_sales', 'projected_growth_pct',\n",
      "                                           'other_unit_pls_lost_sales_py',\n",
      "                                           'other_unit_pls_lost_sales',\n",
      "                                           'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                           'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                           'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                           'unadjusted_total_vio',\n",
      "                                           'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                           'pct_white', 'age', 'pct_college',\n",
      "                                           'pct_blue_collar',\n",
      "                                           'median_household_income',\n",
      "                                           'establishments', ...]})\n",
      "MeanEncoder(variables=['bpg', 'store_number', 'sku_number', 'mpog_id'])\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='both',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  20.2s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=  33.3s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=12.2min\n",
      "Fit\n",
      "43.20134275666666\n",
      "GradientBoostingRegressor(random_state=0)\n",
      "FunctionTransformer(func=<function ratios at 0x00000293189A8D30>,\n",
      "                    kw_args={'tuples': False,\n",
      "                             'variables': ['pop_est', 'pop_density',\n",
      "                                           'total_vio',\n",
      "                                           'avg_cluster_unit_sales',\n",
      "                                           'adjusted_avg_cluster_sales',\n",
      "                                           'avg_cluster_total_sales',\n",
      "                                           'sales_signal', 'failure_sales',\n",
      "                                           'lifecycle', 'adjusted_lifecycle',\n",
      "                                           'adj_avg_cluster_total_sales',\n",
      "                                           'unit_sales', 'projected_growth_pct',\n",
      "                                           'other_unit_pls_lost_sales_py',\n",
      "                                           'other_unit_pls_lost_sales',\n",
      "                                           'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                           'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                           'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                           'unadjusted_total_vio',\n",
      "                                           'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                           'pct_white', 'age', 'pct_college',\n",
      "                                           'pct_blue_collar',\n",
      "                                           'median_household_income',\n",
      "                                           'establishments', ...]})\n",
      "MeanEncoder(variables=['bpg', 'store_number', 'sku_number', 'mpog_id'])\n",
      "Winsorizer(capping_method='quantiles', fold=0.05,\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  21.1s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=  29.3s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=12.4min\n",
      "Fit\n",
      "43.493519991666595\n",
      "GradientBoostingRegressor(random_state=0)\n",
      "FunctionTransformer(func=<function ratios at 0x00000293189A8D30>,\n",
      "                    kw_args={'tuples': False,\n",
      "                             'variables': ['pop_est', 'pop_density',\n",
      "                                           'total_vio',\n",
      "                                           'avg_cluster_unit_sales',\n",
      "                                           'adjusted_avg_cluster_sales',\n",
      "                                           'avg_cluster_total_sales',\n",
      "                                           'sales_signal', 'failure_sales',\n",
      "                                           'lifecycle', 'adjusted_lifecycle',\n",
      "                                           'adj_avg_cluster_total_sales',\n",
      "                                           'unit_sales', 'projected_growth_pct',\n",
      "                                           'other_unit_pls_lost_sales_py',\n",
      "                                           'other_unit_pls_lost_sales',\n",
      "                                           'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                           'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                           'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                           'unadjusted_total_vio',\n",
      "                                           'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                           'pct_white', 'age', 'pct_college',\n",
      "                                           'pct_blue_collar',\n",
      "                                           'median_household_income',\n",
      "                                           'establishments', ...]})\n",
      "MeanEncoder(variables=['bpg', 'store_number', 'sku_number', 'mpog_id'])\n",
      "Winsorizer(capping_method='quantiles', fold=0.05, tail='left',\n",
      "           variables=['pop_est', 'pop_density', 'total_vio',\n",
      "                      'avg_cluster_unit_sales', 'adjusted_avg_cluster_sales',\n",
      "                      'avg_cluster_total_sales', 'sales_signal',\n",
      "                      'failure_sales', 'lifecycle', 'adjusted_lifecycle',\n",
      "                      'adj_avg_cluster_total_sales', 'unit_sales',\n",
      "                      'projected_growth_pct', 'other_unit_pls_lost_sales_py',\n",
      "                      'other_unit_pls_lost_sales', 'weighted_lookup_cnt',\n",
      "                      'qty_wt0_ppy', 'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                      'ntrans_wt0_py', 'ntrans_wt0', 'unadjusted_total_vio',\n",
      "                      'vio_compared_to_cluster', 'qty_wt0', 'pct_white', 'age',\n",
      "                      'pct_college', 'pct_blue_collar',\n",
      "                      'median_household_income', 'establishments', ...])\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  20.9s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=  38.0s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=12.3min\n",
      "Fit\n",
      "42.19859878999996\n",
      "GradientBoostingRegressor(random_state=0)\n",
      "FunctionTransformer(func=<function ratios at 0x00000293189A8D30>,\n",
      "                    kw_args={'tuples': False,\n",
      "                             'variables': ['pop_est', 'pop_density',\n",
      "                                           'total_vio',\n",
      "                                           'avg_cluster_unit_sales',\n",
      "                                           'adjusted_avg_cluster_sales',\n",
      "                                           'avg_cluster_total_sales',\n",
      "                                           'sales_signal', 'failure_sales',\n",
      "                                           'lifecycle', 'adjusted_lifecycle',\n",
      "                                           'adj_avg_cluster_total_sales',\n",
      "                                           'unit_sales', 'projected_growth_pct',\n",
      "                                           'other_unit_pls_lost_sales_py',\n",
      "                                           'other_unit_pls_lost_sales',\n",
      "                                           'weighted_lookup_cnt', 'qty_wt0_ppy',\n",
      "                                           'ntrans_wt0_ppy', 'qty_wt0_py',\n",
      "                                           'ntrans_wt0_py', 'ntrans_wt0',\n",
      "                                           'unadjusted_total_vio',\n",
      "                                           'vio_compared_to_cluster', 'qty_wt0',\n",
      "                                           'pct_white', 'age', 'pct_college',\n",
      "                                           'pct_blue_collar',\n",
      "                                           'median_household_income',\n",
      "                                           'establishments', ...]})\n",
      "MeanEncoder(variables=['bpg', 'store_number', 'sku_number', 'mpog_id'])\n",
      "None\n",
      "[Pipeline] ........... (step 1 of 6) Processing makePos, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 6) Processing rare, total=   0.6s\n",
      "[Pipeline] ........ (step 3 of 6) Processing cat_encode, total=   0.5s\n",
      "[Pipeline] ........ (step 4 of 6) Processing num_encode, total=  20.9s\n",
      "[Pipeline] ........... (step 5 of 6) Processing outlier, total=   0.0s\n",
      "[Pipeline] ....... (step 6 of 6) Processing filter_corr, total=12.6min\n",
      "Fit\n",
      "41.77900111000005\n"
     ]
    }
   ],
   "source": [
    "cat = [#ce.OneHotEncoder(top_categories=None,drop_last=True),\n",
    "       ce.CountFrequencyEncoder(encoding_method = \"count\"),\n",
    "      ce.MeanEncoder(variables = categories)\n",
    "      ]\n",
    "num = [#None,\n",
    "       #tran.YeoJohnsonTransformer(variables= continuous),\n",
    "       #prep.FunctionTransformer(log_transform, kw_args={\"variables\":PosContinuous}),\n",
    "       prep.FunctionTransformer(ratios, kw_args={\"variables\" : continuous, \"tuples\" : False}),\n",
    "       #prep.LogTransformer(base='10',variables=continuous)\n",
    "      ]\n",
    "mod = [#Ridge(), \n",
    "       #LinearRegression(),\n",
    "       #LassoLars(alpha=0.1),\n",
    "       #BayesianRidge(),\n",
    "       GradientBoostingRegressor(random_state=0),\n",
    "      ]\n",
    "outlier = [out.Winsorizer(capping_method = \"gaussian\", tail = \"both\",fold=3,variables=continuous),\n",
    "           out.Winsorizer(capping_method = \"gaussian\", tail = \"right\",fold=3,variables=continuous),\n",
    "           out.Winsorizer(capping_method = \"gaussian\", tail = \"left\",fold=3,variables=continuous),\n",
    "           out.Winsorizer(capping_method = \"iqr\", tail = \"both\",fold=3,variables=continuous),\n",
    "           out.Winsorizer(capping_method = \"iqr\", tail = \"right\",fold=3,variables=continuous),\n",
    "           out.Winsorizer(capping_method = \"iqr\", tail = \"left\",fold=3,variables=continuous),\n",
    "           out.Winsorizer(capping_method = \"quantiles\", tail = \"both\",fold=.05,variables=continuous),\n",
    "           out.Winsorizer(capping_method = \"quantiles\", tail = \"right\",fold=.05,variables=continuous),\n",
    "           out.Winsorizer(capping_method = \"quantiles\", tail = \"left\",fold=.05,variables=continuous),\n",
    "           None\n",
    "          ]\n",
    "\n",
    "scale = [True]\n",
    "\n",
    "d = pd.DataFrame()\n",
    "TYPE = []\n",
    "MODEL = []\n",
    "CATEGORICAL = []\n",
    "NUMERIC = []\n",
    "OUTLIER = []\n",
    "SCALER = []\n",
    "FEATURE_SELECTION = []\n",
    "\n",
    "RMSE_TR = []\n",
    "MAE_TR = []\n",
    "R2_TR = []\n",
    "MAPE_TR = []\n",
    "SMAPE_TR = []\n",
    "\n",
    "RMSE_TE = []\n",
    "MAE_TE = []\n",
    "R2_TE = []\n",
    "MAPE_TE = []\n",
    "SMAPE_TE = []\n",
    "\n",
    "PVAL = []\n",
    "IMPORTANCE = []\n",
    "FEATURES = []\n",
    "TIME = []\n",
    "ID = []\n",
    "i=1\n",
    "\n",
    "for m in mod: # loop through the models\n",
    "    for n in num: # loop through the numeric transformations\n",
    "        for c in cat: # loop through the categorical encoding\n",
    "            for o in outlier:\n",
    "                for s in [True]:\n",
    "                    id = \"G\"+str(i)\n",
    "                    time_start = time.perf_counter()\n",
    "                    X_tr = X_train.copy()\n",
    "                    X_te = X_test.copy()\n",
    "                    print(m)\n",
    "                    print(n)\n",
    "                    print(c)\n",
    "                    print(o)\n",
    "                    #print(s)\n",
    "                    pipe = Pipeline([\n",
    "                            (\"makePos\", prep.FunctionTransformer(MakePos, kw_args={\"negs\": NegContinuous})),\n",
    "                            (\"rare\", ce.RareLabelEncoder(tol=0.01, n_categories=7, max_n_categories = 6, variables= categories, replace_with='Rare')),\n",
    "                            (\"cat_encode\",c),\n",
    "                            (\"num_encode\",n),\n",
    "                            (\"outlier\", o),\n",
    "                            (\"filter_corr\", select.DropCorrelatedFeatures(threshold=0.84))\n",
    "                        ],verbose=True)\n",
    "                        #try:\n",
    "                    pipe.fit(X_tr,y_train)\n",
    "                    X_tr = pipe.transform(X_tr)\n",
    "                    X_te = pipe.transform(X_te)\n",
    "                    names = X_te.columns\n",
    "                    if s:\n",
    "                        scale = prep.StandardScaler()\n",
    "                        scale.fit(X_tr,y_train)\n",
    "                        X_tr = scale.transform(X_tr)\n",
    "                        X_te = scale.transform(X_te)\n",
    "                    model = m\n",
    "                    model.fit(X_tr,y_train)\n",
    "                    print(\"Fit\")\n",
    "                    y_tr_pred = model.predict(X_tr)\n",
    "                    y_te_pred = model.predict(X_te)\n",
    "                    try:\n",
    "                        importance = model.feature_importances_\n",
    "                        TYPE.append(\"Tree\")\n",
    "                        importance = np.append(importance,id)\n",
    "                        names = np.append(names,\"ID\")\n",
    "                        d2 = pd.DataFrame([importance],columns = names)\n",
    "                        d=pd.concat([d,d2]) \n",
    "                    except:\n",
    "                        try:\n",
    "                            importance = stats.coef_pval(model, X_tr, y_train)\n",
    "                            importance = np.delete(importance, 0)\n",
    "                            importance = np.append(importance,id)\n",
    "                            names = np.append(names,\"ID\")\n",
    "                            TYPE.append(\"Linear\")\n",
    "                            d2 = pd.DataFrame([importance],columns = names)\n",
    "                            d=pd.concat([d,d2]) \n",
    "                        except:\n",
    "                            TYPE.append(\"Not Sure\")\n",
    "\n",
    "                    time_stop = time.perf_counter()\n",
    "                    MODEL.append(m)\n",
    "                    CATEGORICAL.append(c)\n",
    "                    NUMERIC.append(n)\n",
    "                    OUTLIER.append(o)\n",
    "                    #SCALER.append(s)\n",
    "                    RMSE_TR.append(math.sqrt(mean_squared_error(y_train,y_tr_pred)))\n",
    "                    MAE_TR.append(mean_absolute_error(y_train,y_tr_pred))\n",
    "                    R2_TR.append(r2_score(y_train,y_tr_pred))\n",
    "                    MAPE_TR.append(MAPE(y_train,y_tr_pred))\n",
    "                    SMAPE_TR.append(SMAPE(y_train,y_tr_pred))\n",
    "                    RMSE_TE.append(math.sqrt(mean_squared_error(y_test,y_te_pred)))\n",
    "                    MAE_TE.append(mean_absolute_error(y_test,y_te_pred))\n",
    "                    R2_TE.append(r2_score(y_test,y_te_pred))\n",
    "                    MAPE_TE.append(MAPE(y_test,y_te_pred))\n",
    "                    SMAPE_TE.append(SMAPE(y_test,y_te_pred))\n",
    "                    FEATURES.append(names)\n",
    "                    TIME.append((time_stop-time_start)/60)\n",
    "                    ID.append(id)\n",
    "                    i+=1\n",
    "                    print((time_stop-time_start)/60)\n",
    "                        \n",
    "#                     except:\n",
    "#                         time_stop = time.perf_counter()\n",
    "#                         MODEL.append(m)\n",
    "#                         CATEGORICAL.append(c)\n",
    "#                         NUMERIC.append(n)\n",
    "#                         OUTLIER.append(o)\n",
    "#                         SCALER.append(s)\n",
    "#                         RMSE_TR.append(\".\")\n",
    "#                         MAE_TR.append(\".\")\n",
    "#                         R2_TR.append(\".\")\n",
    "#                         MAPE_TR.append(\".\")\n",
    "#                         RMSE_TE.append(\".\")\n",
    "#                         MAE_TE.append(\".\")\n",
    "#                         R2_TE.append(\".\")\n",
    "#                         MAPE_TE.append(\".\")\n",
    "#                         TIME.append((time_stop-time_start)/60)\n",
    "#                         ID.append(id)\n",
    "#                         TYPE.append(\".\")\n",
    "#                         i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\"ID\":ID,\n",
    "                        \"TYPE\":TYPE,\n",
    "                       \"TIME\":TIME,\n",
    "                        \"MODEL\":MODEL,\n",
    "                       \"NUMERIC\":NUMERIC,\n",
    "                        \"CATEGORICAL\":CATEGORICAL,\n",
    "                        \"OUTLIER\":OUTLIER,\n",
    "                        #\"SCALER\":SCALER,\n",
    "                       \"RMSE_TR\":RMSE_TR,\n",
    "                       \"MAE_TR\":MAE_TR,\n",
    "                       \"R2_TR\":R2_TR,\n",
    "                       \"MAPE_TR\":MAPE_TR,\n",
    "                       \"SMAPE_TR\":SMAPE_TR,\n",
    "                       \"RMSE_TE\":RMSE_TE,\n",
    "                       \"MAE_TE\":MAE_TE,\n",
    "                       \"R2_TE\":R2_TE,\n",
    "                       \"MAPE_TE\":MAPE_TE,\n",
    "                       \"SMAPE_TE\":SMAPE_TE,\n",
    "                       #\"P_value\":PVAL,\n",
    "                       #\"IMPORTANCE\":IMPORTANCE,\n",
    "                       #\"FEATURES\":FEATURES\n",
    "                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SCALER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>MODEL</th>\n",
       "      <th>NUMERIC</th>\n",
       "      <th>CATEGORICAL</th>\n",
       "      <th>OUTLIER</th>\n",
       "      <th>RMSE_TR</th>\n",
       "      <th>MAE_TR</th>\n",
       "      <th>R2_TR</th>\n",
       "      <th>MAPE_TR</th>\n",
       "      <th>SMAPE_TR</th>\n",
       "      <th>RMSE_TE</th>\n",
       "      <th>MAE_TE</th>\n",
       "      <th>R2_TE</th>\n",
       "      <th>MAPE_TE</th>\n",
       "      <th>SMAPE_TE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G1</td>\n",
       "      <td>Tree</td>\n",
       "      <td>44.932657</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>Winsorizer(tail='both',\\n           variables=...</td>\n",
       "      <td>16.572329</td>\n",
       "      <td>6.101647</td>\n",
       "      <td>0.996125</td>\n",
       "      <td>13.933462</td>\n",
       "      <td>11.722541</td>\n",
       "      <td>23.122964</td>\n",
       "      <td>6.457400</td>\n",
       "      <td>0.991508</td>\n",
       "      <td>13.848780</td>\n",
       "      <td>11.660515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G2</td>\n",
       "      <td>Tree</td>\n",
       "      <td>41.738982</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>Winsorizer(variables=['pop_est', 'pop_density'...</td>\n",
       "      <td>16.572329</td>\n",
       "      <td>6.101647</td>\n",
       "      <td>0.996125</td>\n",
       "      <td>13.933462</td>\n",
       "      <td>11.722541</td>\n",
       "      <td>23.025225</td>\n",
       "      <td>6.452838</td>\n",
       "      <td>0.991579</td>\n",
       "      <td>13.848675</td>\n",
       "      <td>11.660400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G3</td>\n",
       "      <td>Tree</td>\n",
       "      <td>41.514752</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>Winsorizer(tail='left',\\n           variables=...</td>\n",
       "      <td>18.534062</td>\n",
       "      <td>7.010501</td>\n",
       "      <td>0.995153</td>\n",
       "      <td>17.525006</td>\n",
       "      <td>14.913661</td>\n",
       "      <td>27.621946</td>\n",
       "      <td>7.351739</td>\n",
       "      <td>0.987881</td>\n",
       "      <td>17.416507</td>\n",
       "      <td>14.872277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G4</td>\n",
       "      <td>Tree</td>\n",
       "      <td>42.174438</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>Winsorizer(capping_method='iqr', tail='both',\\...</td>\n",
       "      <td>16.914867</td>\n",
       "      <td>6.272864</td>\n",
       "      <td>0.995963</td>\n",
       "      <td>14.259008</td>\n",
       "      <td>12.079943</td>\n",
       "      <td>24.860569</td>\n",
       "      <td>6.691039</td>\n",
       "      <td>0.990183</td>\n",
       "      <td>14.208052</td>\n",
       "      <td>12.020935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G5</td>\n",
       "      <td>Tree</td>\n",
       "      <td>42.299867</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>Winsorizer(capping_method='iqr',\\n           v...</td>\n",
       "      <td>16.914867</td>\n",
       "      <td>6.272864</td>\n",
       "      <td>0.995963</td>\n",
       "      <td>14.259008</td>\n",
       "      <td>12.079943</td>\n",
       "      <td>25.493483</td>\n",
       "      <td>6.701166</td>\n",
       "      <td>0.989677</td>\n",
       "      <td>14.207684</td>\n",
       "      <td>12.021054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>G6</td>\n",
       "      <td>Tree</td>\n",
       "      <td>41.637657</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>Winsorizer(capping_method='iqr', tail='left',\\...</td>\n",
       "      <td>18.534062</td>\n",
       "      <td>7.010501</td>\n",
       "      <td>0.995153</td>\n",
       "      <td>17.525006</td>\n",
       "      <td>14.913661</td>\n",
       "      <td>27.546615</td>\n",
       "      <td>7.350187</td>\n",
       "      <td>0.987947</td>\n",
       "      <td>17.416532</td>\n",
       "      <td>14.872286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G7</td>\n",
       "      <td>Tree</td>\n",
       "      <td>42.717463</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>16.282727</td>\n",
       "      <td>6.045598</td>\n",
       "      <td>0.996259</td>\n",
       "      <td>14.011106</td>\n",
       "      <td>11.747227</td>\n",
       "      <td>22.997536</td>\n",
       "      <td>6.428045</td>\n",
       "      <td>0.991599</td>\n",
       "      <td>13.960318</td>\n",
       "      <td>11.696850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>G8</td>\n",
       "      <td>Tree</td>\n",
       "      <td>43.191722</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>16.246071</td>\n",
       "      <td>6.061748</td>\n",
       "      <td>0.996276</td>\n",
       "      <td>14.214878</td>\n",
       "      <td>11.767608</td>\n",
       "      <td>22.660778</td>\n",
       "      <td>6.434329</td>\n",
       "      <td>0.991844</td>\n",
       "      <td>14.168637</td>\n",
       "      <td>11.719842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>G9</td>\n",
       "      <td>Tree</td>\n",
       "      <td>42.352251</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>18.257186</td>\n",
       "      <td>7.032869</td>\n",
       "      <td>0.995297</td>\n",
       "      <td>16.967901</td>\n",
       "      <td>14.571964</td>\n",
       "      <td>27.103720</td>\n",
       "      <td>7.374269</td>\n",
       "      <td>0.988332</td>\n",
       "      <td>16.869672</td>\n",
       "      <td>14.527226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>G10</td>\n",
       "      <td>Tree</td>\n",
       "      <td>41.427850</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>None</td>\n",
       "      <td>18.534062</td>\n",
       "      <td>7.010501</td>\n",
       "      <td>0.995153</td>\n",
       "      <td>17.525006</td>\n",
       "      <td>14.913661</td>\n",
       "      <td>27.567561</td>\n",
       "      <td>7.354435</td>\n",
       "      <td>0.987929</td>\n",
       "      <td>17.417060</td>\n",
       "      <td>14.872483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>G11</td>\n",
       "      <td>Tree</td>\n",
       "      <td>43.405981</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>Winsorizer(tail='both',\\n           variables=...</td>\n",
       "      <td>16.572329</td>\n",
       "      <td>6.101647</td>\n",
       "      <td>0.996125</td>\n",
       "      <td>13.933462</td>\n",
       "      <td>11.722541</td>\n",
       "      <td>22.989497</td>\n",
       "      <td>6.452943</td>\n",
       "      <td>0.991605</td>\n",
       "      <td>13.848560</td>\n",
       "      <td>11.660360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>G12</td>\n",
       "      <td>Tree</td>\n",
       "      <td>42.990539</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>Winsorizer(variables=['pop_est', 'pop_density'...</td>\n",
       "      <td>16.572329</td>\n",
       "      <td>6.101647</td>\n",
       "      <td>0.996125</td>\n",
       "      <td>13.933462</td>\n",
       "      <td>11.722541</td>\n",
       "      <td>23.122641</td>\n",
       "      <td>6.456195</td>\n",
       "      <td>0.991508</td>\n",
       "      <td>13.849094</td>\n",
       "      <td>11.660522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>G13</td>\n",
       "      <td>Tree</td>\n",
       "      <td>42.264993</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>Winsorizer(tail='left',\\n           variables=...</td>\n",
       "      <td>18.534062</td>\n",
       "      <td>7.010501</td>\n",
       "      <td>0.995153</td>\n",
       "      <td>17.525006</td>\n",
       "      <td>14.913661</td>\n",
       "      <td>27.609588</td>\n",
       "      <td>7.353755</td>\n",
       "      <td>0.987892</td>\n",
       "      <td>17.416745</td>\n",
       "      <td>14.872516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>G14</td>\n",
       "      <td>Tree</td>\n",
       "      <td>43.272062</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>Winsorizer(capping_method='iqr', tail='both',\\...</td>\n",
       "      <td>16.914867</td>\n",
       "      <td>6.272864</td>\n",
       "      <td>0.995963</td>\n",
       "      <td>14.259008</td>\n",
       "      <td>12.079943</td>\n",
       "      <td>25.152629</td>\n",
       "      <td>6.696709</td>\n",
       "      <td>0.989951</td>\n",
       "      <td>14.209740</td>\n",
       "      <td>12.021207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>G15</td>\n",
       "      <td>Tree</td>\n",
       "      <td>43.404205</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>Winsorizer(capping_method='iqr',\\n           v...</td>\n",
       "      <td>16.914867</td>\n",
       "      <td>6.272864</td>\n",
       "      <td>0.995963</td>\n",
       "      <td>14.259008</td>\n",
       "      <td>12.079943</td>\n",
       "      <td>25.607490</td>\n",
       "      <td>6.702787</td>\n",
       "      <td>0.989585</td>\n",
       "      <td>14.207811</td>\n",
       "      <td>12.021264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>G16</td>\n",
       "      <td>Tree</td>\n",
       "      <td>42.738174</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>Winsorizer(capping_method='iqr', tail='left',\\...</td>\n",
       "      <td>18.534062</td>\n",
       "      <td>7.010501</td>\n",
       "      <td>0.995153</td>\n",
       "      <td>17.525006</td>\n",
       "      <td>14.913661</td>\n",
       "      <td>27.578814</td>\n",
       "      <td>7.350324</td>\n",
       "      <td>0.987919</td>\n",
       "      <td>17.416448</td>\n",
       "      <td>14.872205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>G17</td>\n",
       "      <td>Tree</td>\n",
       "      <td>43.201343</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>16.282727</td>\n",
       "      <td>6.045598</td>\n",
       "      <td>0.996259</td>\n",
       "      <td>14.011106</td>\n",
       "      <td>11.747227</td>\n",
       "      <td>22.836837</td>\n",
       "      <td>6.424935</td>\n",
       "      <td>0.991716</td>\n",
       "      <td>13.960271</td>\n",
       "      <td>11.696743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>G18</td>\n",
       "      <td>Tree</td>\n",
       "      <td>43.493520</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>16.246071</td>\n",
       "      <td>6.061748</td>\n",
       "      <td>0.996276</td>\n",
       "      <td>14.214878</td>\n",
       "      <td>11.767608</td>\n",
       "      <td>22.543956</td>\n",
       "      <td>6.426870</td>\n",
       "      <td>0.991928</td>\n",
       "      <td>14.168214</td>\n",
       "      <td>11.719534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>G19</td>\n",
       "      <td>Tree</td>\n",
       "      <td>42.198599</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>18.257186</td>\n",
       "      <td>7.032869</td>\n",
       "      <td>0.995297</td>\n",
       "      <td>16.967901</td>\n",
       "      <td>14.571964</td>\n",
       "      <td>27.738762</td>\n",
       "      <td>7.380962</td>\n",
       "      <td>0.987779</td>\n",
       "      <td>16.872138</td>\n",
       "      <td>14.527588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>G20</td>\n",
       "      <td>Tree</td>\n",
       "      <td>41.779001</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>None</td>\n",
       "      <td>18.534062</td>\n",
       "      <td>7.010501</td>\n",
       "      <td>0.995153</td>\n",
       "      <td>17.525006</td>\n",
       "      <td>14.913661</td>\n",
       "      <td>27.449713</td>\n",
       "      <td>7.351064</td>\n",
       "      <td>0.988032</td>\n",
       "      <td>17.416580</td>\n",
       "      <td>14.872318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  TYPE       TIME                                              MODEL  \\\n",
       "0    G1  Tree  44.932657  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "1    G2  Tree  41.738982  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "2    G3  Tree  41.514752  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "3    G4  Tree  42.174438  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "4    G5  Tree  42.299867  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "5    G6  Tree  41.637657  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "6    G7  Tree  42.717463  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "7    G8  Tree  43.191722  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "8    G9  Tree  42.352251  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "9   G10  Tree  41.427850  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "10  G11  Tree  43.405981  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "11  G12  Tree  42.990539  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "12  G13  Tree  42.264993  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "13  G14  Tree  43.272062  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "14  G15  Tree  43.404205  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "15  G16  Tree  42.738174  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "16  G17  Tree  43.201343  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "17  G18  Tree  43.493520  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "18  G19  Tree  42.198599  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "19  G20  Tree  41.779001  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "\n",
       "                                              NUMERIC  \\\n",
       "0   FunctionTransformer(func=<function ratios at 0...   \n",
       "1   FunctionTransformer(func=<function ratios at 0...   \n",
       "2   FunctionTransformer(func=<function ratios at 0...   \n",
       "3   FunctionTransformer(func=<function ratios at 0...   \n",
       "4   FunctionTransformer(func=<function ratios at 0...   \n",
       "5   FunctionTransformer(func=<function ratios at 0...   \n",
       "6   FunctionTransformer(func=<function ratios at 0...   \n",
       "7   FunctionTransformer(func=<function ratios at 0...   \n",
       "8   FunctionTransformer(func=<function ratios at 0...   \n",
       "9   FunctionTransformer(func=<function ratios at 0...   \n",
       "10  FunctionTransformer(func=<function ratios at 0...   \n",
       "11  FunctionTransformer(func=<function ratios at 0...   \n",
       "12  FunctionTransformer(func=<function ratios at 0...   \n",
       "13  FunctionTransformer(func=<function ratios at 0...   \n",
       "14  FunctionTransformer(func=<function ratios at 0...   \n",
       "15  FunctionTransformer(func=<function ratios at 0...   \n",
       "16  FunctionTransformer(func=<function ratios at 0...   \n",
       "17  FunctionTransformer(func=<function ratios at 0...   \n",
       "18  FunctionTransformer(func=<function ratios at 0...   \n",
       "19  FunctionTransformer(func=<function ratios at 0...   \n",
       "\n",
       "                                          CATEGORICAL  \\\n",
       "0   CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "1   CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "2   CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "3   CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "4   CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "5   CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "6   CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "7   CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "8   CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "9   CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "10  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "11  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "12  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "13  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "14  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "15  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "16  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "17  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "18  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "19  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "\n",
       "                                              OUTLIER    RMSE_TR    MAE_TR  \\\n",
       "0   Winsorizer(tail='both',\\n           variables=...  16.572329  6.101647   \n",
       "1   Winsorizer(variables=['pop_est', 'pop_density'...  16.572329  6.101647   \n",
       "2   Winsorizer(tail='left',\\n           variables=...  18.534062  7.010501   \n",
       "3   Winsorizer(capping_method='iqr', tail='both',\\...  16.914867  6.272864   \n",
       "4   Winsorizer(capping_method='iqr',\\n           v...  16.914867  6.272864   \n",
       "5   Winsorizer(capping_method='iqr', tail='left',\\...  18.534062  7.010501   \n",
       "6   Winsorizer(capping_method='quantiles', fold=0....  16.282727  6.045598   \n",
       "7   Winsorizer(capping_method='quantiles', fold=0....  16.246071  6.061748   \n",
       "8   Winsorizer(capping_method='quantiles', fold=0....  18.257186  7.032869   \n",
       "9                                                None  18.534062  7.010501   \n",
       "10  Winsorizer(tail='both',\\n           variables=...  16.572329  6.101647   \n",
       "11  Winsorizer(variables=['pop_est', 'pop_density'...  16.572329  6.101647   \n",
       "12  Winsorizer(tail='left',\\n           variables=...  18.534062  7.010501   \n",
       "13  Winsorizer(capping_method='iqr', tail='both',\\...  16.914867  6.272864   \n",
       "14  Winsorizer(capping_method='iqr',\\n           v...  16.914867  6.272864   \n",
       "15  Winsorizer(capping_method='iqr', tail='left',\\...  18.534062  7.010501   \n",
       "16  Winsorizer(capping_method='quantiles', fold=0....  16.282727  6.045598   \n",
       "17  Winsorizer(capping_method='quantiles', fold=0....  16.246071  6.061748   \n",
       "18  Winsorizer(capping_method='quantiles', fold=0....  18.257186  7.032869   \n",
       "19                                               None  18.534062  7.010501   \n",
       "\n",
       "       R2_TR    MAPE_TR   SMAPE_TR    RMSE_TE    MAE_TE     R2_TE    MAPE_TE  \\\n",
       "0   0.996125  13.933462  11.722541  23.122964  6.457400  0.991508  13.848780   \n",
       "1   0.996125  13.933462  11.722541  23.025225  6.452838  0.991579  13.848675   \n",
       "2   0.995153  17.525006  14.913661  27.621946  7.351739  0.987881  17.416507   \n",
       "3   0.995963  14.259008  12.079943  24.860569  6.691039  0.990183  14.208052   \n",
       "4   0.995963  14.259008  12.079943  25.493483  6.701166  0.989677  14.207684   \n",
       "5   0.995153  17.525006  14.913661  27.546615  7.350187  0.987947  17.416532   \n",
       "6   0.996259  14.011106  11.747227  22.997536  6.428045  0.991599  13.960318   \n",
       "7   0.996276  14.214878  11.767608  22.660778  6.434329  0.991844  14.168637   \n",
       "8   0.995297  16.967901  14.571964  27.103720  7.374269  0.988332  16.869672   \n",
       "9   0.995153  17.525006  14.913661  27.567561  7.354435  0.987929  17.417060   \n",
       "10  0.996125  13.933462  11.722541  22.989497  6.452943  0.991605  13.848560   \n",
       "11  0.996125  13.933462  11.722541  23.122641  6.456195  0.991508  13.849094   \n",
       "12  0.995153  17.525006  14.913661  27.609588  7.353755  0.987892  17.416745   \n",
       "13  0.995963  14.259008  12.079943  25.152629  6.696709  0.989951  14.209740   \n",
       "14  0.995963  14.259008  12.079943  25.607490  6.702787  0.989585  14.207811   \n",
       "15  0.995153  17.525006  14.913661  27.578814  7.350324  0.987919  17.416448   \n",
       "16  0.996259  14.011106  11.747227  22.836837  6.424935  0.991716  13.960271   \n",
       "17  0.996276  14.214878  11.767608  22.543956  6.426870  0.991928  14.168214   \n",
       "18  0.995297  16.967901  14.571964  27.738762  7.380962  0.987779  16.872138   \n",
       "19  0.995153  17.525006  14.913661  27.449713  7.351064  0.988032  17.416580   \n",
       "\n",
       "     SMAPE_TE  \n",
       "0   11.660515  \n",
       "1   11.660400  \n",
       "2   14.872277  \n",
       "3   12.020935  \n",
       "4   12.021054  \n",
       "5   14.872286  \n",
       "6   11.696850  \n",
       "7   11.719842  \n",
       "8   14.527226  \n",
       "9   14.872483  \n",
       "10  11.660360  \n",
       "11  11.660522  \n",
       "12  14.872516  \n",
       "13  12.021207  \n",
       "14  12.021264  \n",
       "15  14.872205  \n",
       "16  11.696743  \n",
       "17  11.719534  \n",
       "18  14.527588  \n",
       "19  14.872318  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.merge(results,d,how = \"left\",on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>MODEL</th>\n",
       "      <th>NUMERIC</th>\n",
       "      <th>CATEGORICAL</th>\n",
       "      <th>OUTLIER</th>\n",
       "      <th>RMSE_TR</th>\n",
       "      <th>MAE_TR</th>\n",
       "      <th>R2_TR</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_white/total_vio</th>\n",
       "      <th>adjusted_avg_cluster_sales/projected_growth_pct</th>\n",
       "      <th>other_unit_pls_lost_sales_py/projected_growth_pct</th>\n",
       "      <th>pct_blue_collar/ntrans_wt0_ppy</th>\n",
       "      <th>road_quality_index/ntrans_wt0_ppy</th>\n",
       "      <th>road_quality_index/ntrans_wt0</th>\n",
       "      <th>establishments/vio_compared_to_cluster</th>\n",
       "      <th>road_quality_index/vio_compared_to_cluster</th>\n",
       "      <th>age/pct_college</th>\n",
       "      <th>other_unit_pls_lost_sales/projected_growth_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G1</td>\n",
       "      <td>Tree</td>\n",
       "      <td>44.932657</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>Winsorizer(tail='both',\\n           variables=...</td>\n",
       "      <td>16.572329</td>\n",
       "      <td>6.101647</td>\n",
       "      <td>0.996125</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G2</td>\n",
       "      <td>Tree</td>\n",
       "      <td>41.738982</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>Winsorizer(variables=['pop_est', 'pop_density'...</td>\n",
       "      <td>16.572329</td>\n",
       "      <td>6.101647</td>\n",
       "      <td>0.996125</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G3</td>\n",
       "      <td>Tree</td>\n",
       "      <td>41.514752</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>Winsorizer(tail='left',\\n           variables=...</td>\n",
       "      <td>18.534062</td>\n",
       "      <td>7.010501</td>\n",
       "      <td>0.995153</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G4</td>\n",
       "      <td>Tree</td>\n",
       "      <td>42.174438</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>Winsorizer(capping_method='iqr', tail='both',\\...</td>\n",
       "      <td>16.914867</td>\n",
       "      <td>6.272864</td>\n",
       "      <td>0.995963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0009461892646678628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.680596695723603e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G5</td>\n",
       "      <td>Tree</td>\n",
       "      <td>42.299867</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>Winsorizer(capping_method='iqr',\\n           v...</td>\n",
       "      <td>16.914867</td>\n",
       "      <td>6.272864</td>\n",
       "      <td>0.995963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0009456776253194917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.680596695723825e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>G6</td>\n",
       "      <td>Tree</td>\n",
       "      <td>41.637657</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>Winsorizer(capping_method='iqr', tail='left',\\...</td>\n",
       "      <td>18.534062</td>\n",
       "      <td>7.010501</td>\n",
       "      <td>0.995153</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G7</td>\n",
       "      <td>Tree</td>\n",
       "      <td>42.717463</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>16.282727</td>\n",
       "      <td>6.045598</td>\n",
       "      <td>0.996259</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0007147279172536552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>G8</td>\n",
       "      <td>Tree</td>\n",
       "      <td>43.191722</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>16.246071</td>\n",
       "      <td>6.061748</td>\n",
       "      <td>0.996276</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0007147158478485993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>G9</td>\n",
       "      <td>Tree</td>\n",
       "      <td>42.352251</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>18.257186</td>\n",
       "      <td>7.032869</td>\n",
       "      <td>0.995297</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.953912885906334e-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>G10</td>\n",
       "      <td>Tree</td>\n",
       "      <td>41.427850</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>CountFrequencyEncoder(variables=['bpg', 'store...</td>\n",
       "      <td>None</td>\n",
       "      <td>18.534062</td>\n",
       "      <td>7.010501</td>\n",
       "      <td>0.995153</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>G11</td>\n",
       "      <td>Tree</td>\n",
       "      <td>43.405981</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>Winsorizer(tail='both',\\n           variables=...</td>\n",
       "      <td>16.572329</td>\n",
       "      <td>6.101647</td>\n",
       "      <td>0.996125</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>G12</td>\n",
       "      <td>Tree</td>\n",
       "      <td>42.990539</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>Winsorizer(variables=['pop_est', 'pop_density'...</td>\n",
       "      <td>16.572329</td>\n",
       "      <td>6.101647</td>\n",
       "      <td>0.996125</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>G13</td>\n",
       "      <td>Tree</td>\n",
       "      <td>42.264993</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>Winsorizer(tail='left',\\n           variables=...</td>\n",
       "      <td>18.534062</td>\n",
       "      <td>7.010501</td>\n",
       "      <td>0.995153</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>G14</td>\n",
       "      <td>Tree</td>\n",
       "      <td>43.272062</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>Winsorizer(capping_method='iqr', tail='both',\\...</td>\n",
       "      <td>16.914867</td>\n",
       "      <td>6.272864</td>\n",
       "      <td>0.995963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0009461892646678899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.680596695723619e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>G15</td>\n",
       "      <td>Tree</td>\n",
       "      <td>43.404205</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>Winsorizer(capping_method='iqr',\\n           v...</td>\n",
       "      <td>16.914867</td>\n",
       "      <td>6.272864</td>\n",
       "      <td>0.995963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0009456776253194746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.680596695723821e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>G16</td>\n",
       "      <td>Tree</td>\n",
       "      <td>42.738174</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>Winsorizer(capping_method='iqr', tail='left',\\...</td>\n",
       "      <td>18.534062</td>\n",
       "      <td>7.010501</td>\n",
       "      <td>0.995153</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>G17</td>\n",
       "      <td>Tree</td>\n",
       "      <td>43.201343</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>16.282727</td>\n",
       "      <td>6.045598</td>\n",
       "      <td>0.996259</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0007147279172536431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>G18</td>\n",
       "      <td>Tree</td>\n",
       "      <td>43.493520</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>16.246071</td>\n",
       "      <td>6.061748</td>\n",
       "      <td>0.996276</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0007147158478485877</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>G19</td>\n",
       "      <td>Tree</td>\n",
       "      <td>42.198599</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>Winsorizer(capping_method='quantiles', fold=0....</td>\n",
       "      <td>18.257186</td>\n",
       "      <td>7.032869</td>\n",
       "      <td>0.995297</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.953912885904692e-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>G20</td>\n",
       "      <td>Tree</td>\n",
       "      <td>41.779001</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>FunctionTransformer(func=&lt;function ratios at 0...</td>\n",
       "      <td>MeanEncoder(variables=['bpg', 'store_number', ...</td>\n",
       "      <td>None</td>\n",
       "      <td>18.534062</td>\n",
       "      <td>7.010501</td>\n",
       "      <td>0.995153</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 404 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  TYPE       TIME                                              MODEL  \\\n",
       "0    G1  Tree  44.932657  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "1    G2  Tree  41.738982  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "2    G3  Tree  41.514752  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "3    G4  Tree  42.174438  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "4    G5  Tree  42.299867  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "5    G6  Tree  41.637657  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "6    G7  Tree  42.717463  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "7    G8  Tree  43.191722  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "8    G9  Tree  42.352251  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "9   G10  Tree  41.427850  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "10  G11  Tree  43.405981  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "11  G12  Tree  42.990539  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "12  G13  Tree  42.264993  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "13  G14  Tree  43.272062  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "14  G15  Tree  43.404205  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "15  G16  Tree  42.738174  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "16  G17  Tree  43.201343  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "17  G18  Tree  43.493520  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "18  G19  Tree  42.198599  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "19  G20  Tree  41.779001  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "\n",
       "                                              NUMERIC  \\\n",
       "0   FunctionTransformer(func=<function ratios at 0...   \n",
       "1   FunctionTransformer(func=<function ratios at 0...   \n",
       "2   FunctionTransformer(func=<function ratios at 0...   \n",
       "3   FunctionTransformer(func=<function ratios at 0...   \n",
       "4   FunctionTransformer(func=<function ratios at 0...   \n",
       "5   FunctionTransformer(func=<function ratios at 0...   \n",
       "6   FunctionTransformer(func=<function ratios at 0...   \n",
       "7   FunctionTransformer(func=<function ratios at 0...   \n",
       "8   FunctionTransformer(func=<function ratios at 0...   \n",
       "9   FunctionTransformer(func=<function ratios at 0...   \n",
       "10  FunctionTransformer(func=<function ratios at 0...   \n",
       "11  FunctionTransformer(func=<function ratios at 0...   \n",
       "12  FunctionTransformer(func=<function ratios at 0...   \n",
       "13  FunctionTransformer(func=<function ratios at 0...   \n",
       "14  FunctionTransformer(func=<function ratios at 0...   \n",
       "15  FunctionTransformer(func=<function ratios at 0...   \n",
       "16  FunctionTransformer(func=<function ratios at 0...   \n",
       "17  FunctionTransformer(func=<function ratios at 0...   \n",
       "18  FunctionTransformer(func=<function ratios at 0...   \n",
       "19  FunctionTransformer(func=<function ratios at 0...   \n",
       "\n",
       "                                          CATEGORICAL  \\\n",
       "0   CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "1   CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "2   CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "3   CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "4   CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "5   CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "6   CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "7   CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "8   CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "9   CountFrequencyEncoder(variables=['bpg', 'store...   \n",
       "10  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "11  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "12  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "13  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "14  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "15  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "16  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "17  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "18  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "19  MeanEncoder(variables=['bpg', 'store_number', ...   \n",
       "\n",
       "                                              OUTLIER    RMSE_TR    MAE_TR  \\\n",
       "0   Winsorizer(tail='both',\\n           variables=...  16.572329  6.101647   \n",
       "1   Winsorizer(variables=['pop_est', 'pop_density'...  16.572329  6.101647   \n",
       "2   Winsorizer(tail='left',\\n           variables=...  18.534062  7.010501   \n",
       "3   Winsorizer(capping_method='iqr', tail='both',\\...  16.914867  6.272864   \n",
       "4   Winsorizer(capping_method='iqr',\\n           v...  16.914867  6.272864   \n",
       "5   Winsorizer(capping_method='iqr', tail='left',\\...  18.534062  7.010501   \n",
       "6   Winsorizer(capping_method='quantiles', fold=0....  16.282727  6.045598   \n",
       "7   Winsorizer(capping_method='quantiles', fold=0....  16.246071  6.061748   \n",
       "8   Winsorizer(capping_method='quantiles', fold=0....  18.257186  7.032869   \n",
       "9                                                None  18.534062  7.010501   \n",
       "10  Winsorizer(tail='both',\\n           variables=...  16.572329  6.101647   \n",
       "11  Winsorizer(variables=['pop_est', 'pop_density'...  16.572329  6.101647   \n",
       "12  Winsorizer(tail='left',\\n           variables=...  18.534062  7.010501   \n",
       "13  Winsorizer(capping_method='iqr', tail='both',\\...  16.914867  6.272864   \n",
       "14  Winsorizer(capping_method='iqr',\\n           v...  16.914867  6.272864   \n",
       "15  Winsorizer(capping_method='iqr', tail='left',\\...  18.534062  7.010501   \n",
       "16  Winsorizer(capping_method='quantiles', fold=0....  16.282727  6.045598   \n",
       "17  Winsorizer(capping_method='quantiles', fold=0....  16.246071  6.061748   \n",
       "18  Winsorizer(capping_method='quantiles', fold=0....  18.257186  7.032869   \n",
       "19                                               None  18.534062  7.010501   \n",
       "\n",
       "       R2_TR  ...  pct_white/total_vio  \\\n",
       "0   0.996125  ...                  NaN   \n",
       "1   0.996125  ...                  NaN   \n",
       "2   0.995153  ...                  NaN   \n",
       "3   0.995963  ...                  0.0   \n",
       "4   0.995963  ...                  0.0   \n",
       "5   0.995153  ...                  NaN   \n",
       "6   0.996259  ...                  NaN   \n",
       "7   0.996276  ...                  NaN   \n",
       "8   0.995297  ...                  NaN   \n",
       "9   0.995153  ...                  NaN   \n",
       "10  0.996125  ...                  NaN   \n",
       "11  0.996125  ...                  NaN   \n",
       "12  0.995153  ...                  NaN   \n",
       "13  0.995963  ...                  0.0   \n",
       "14  0.995963  ...                  0.0   \n",
       "15  0.995153  ...                  NaN   \n",
       "16  0.996259  ...                  NaN   \n",
       "17  0.996276  ...                  NaN   \n",
       "18  0.995297  ...                  NaN   \n",
       "19  0.995153  ...                  NaN   \n",
       "\n",
       "    adjusted_avg_cluster_sales/projected_growth_pct  \\\n",
       "0                                               NaN   \n",
       "1                                               NaN   \n",
       "2                                               NaN   \n",
       "3                             0.0009461892646678628   \n",
       "4                             0.0009456776253194917   \n",
       "5                                               NaN   \n",
       "6                             0.0007147279172536552   \n",
       "7                             0.0007147158478485993   \n",
       "8                                               NaN   \n",
       "9                                               NaN   \n",
       "10                                              NaN   \n",
       "11                                              NaN   \n",
       "12                                              NaN   \n",
       "13                            0.0009461892646678899   \n",
       "14                            0.0009456776253194746   \n",
       "15                                              NaN   \n",
       "16                            0.0007147279172536431   \n",
       "17                            0.0007147158478485877   \n",
       "18                                              NaN   \n",
       "19                                              NaN   \n",
       "\n",
       "    other_unit_pls_lost_sales_py/projected_growth_pct  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 0.0   \n",
       "4                                                 0.0   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "\n",
       "    pct_blue_collar/ntrans_wt0_ppy  road_quality_index/ntrans_wt0_ppy  \\\n",
       "0                              NaN                                NaN   \n",
       "1                              NaN                                NaN   \n",
       "2                              NaN                                NaN   \n",
       "3            6.680596695723603e-06                                NaN   \n",
       "4            6.680596695723825e-06                                NaN   \n",
       "5                              NaN                                NaN   \n",
       "6                              NaN                                0.0   \n",
       "7                              NaN                                0.0   \n",
       "8                              NaN                                NaN   \n",
       "9                              NaN                                NaN   \n",
       "10                             NaN                                NaN   \n",
       "11                             NaN                                NaN   \n",
       "12                             NaN                                NaN   \n",
       "13           6.680596695723619e-06                                NaN   \n",
       "14           6.680596695723821e-06                                NaN   \n",
       "15                             NaN                                NaN   \n",
       "16                             NaN                                0.0   \n",
       "17                             NaN                                0.0   \n",
       "18                             NaN                                NaN   \n",
       "19                             NaN                                NaN   \n",
       "\n",
       "    road_quality_index/ntrans_wt0  establishments/vio_compared_to_cluster  \\\n",
       "0                             NaN                                     NaN   \n",
       "1                             NaN                                     NaN   \n",
       "2                             NaN                                     NaN   \n",
       "3                             NaN                                     NaN   \n",
       "4                             NaN                                     NaN   \n",
       "5                             NaN                                     NaN   \n",
       "6                             0.0                                     0.0   \n",
       "7                             0.0                                     0.0   \n",
       "8                             NaN                                     NaN   \n",
       "9                             NaN                                     NaN   \n",
       "10                            NaN                                     NaN   \n",
       "11                            NaN                                     NaN   \n",
       "12                            NaN                                     NaN   \n",
       "13                            NaN                                     NaN   \n",
       "14                            NaN                                     NaN   \n",
       "15                            NaN                                     NaN   \n",
       "16                            0.0                                     0.0   \n",
       "17                            0.0                                     0.0   \n",
       "18                            NaN                                     NaN   \n",
       "19                            NaN                                     NaN   \n",
       "\n",
       "   road_quality_index/vio_compared_to_cluster        age/pct_college  \\\n",
       "0                                         NaN                    NaN   \n",
       "1                                         NaN                    NaN   \n",
       "2                                         NaN                    NaN   \n",
       "3                                         NaN                    NaN   \n",
       "4                                         NaN                    NaN   \n",
       "5                                         NaN                    NaN   \n",
       "6                                         0.0                    0.0   \n",
       "7                                         0.0                    NaN   \n",
       "8                                         NaN  6.953912885906334e-06   \n",
       "9                                         NaN                    NaN   \n",
       "10                                        NaN                    NaN   \n",
       "11                                        NaN                    NaN   \n",
       "12                                        NaN                    NaN   \n",
       "13                                        NaN                    NaN   \n",
       "14                                        NaN                    NaN   \n",
       "15                                        NaN                    NaN   \n",
       "16                                        0.0                    0.0   \n",
       "17                                        0.0                    NaN   \n",
       "18                                        NaN  6.953912885904692e-06   \n",
       "19                                        NaN                    NaN   \n",
       "\n",
       "   other_unit_pls_lost_sales/projected_growth_pct  \n",
       "0                                             NaN  \n",
       "1                                             NaN  \n",
       "2                                             NaN  \n",
       "3                                             NaN  \n",
       "4                                             NaN  \n",
       "5                                             NaN  \n",
       "6                                             NaN  \n",
       "7                                             NaN  \n",
       "8                                             NaN  \n",
       "9                                             NaN  \n",
       "10                                            NaN  \n",
       "11                                            NaN  \n",
       "12                                            NaN  \n",
       "13                                            0.0  \n",
       "14                                            0.0  \n",
       "15                                            NaN  \n",
       "16                                            NaN  \n",
       "17                                            NaN  \n",
       "18                                            NaN  \n",
       "19                                            NaN  \n",
       "\n",
       "[20 rows x 404 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('final_8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
